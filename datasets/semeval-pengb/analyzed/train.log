2021-12-14 01:45:09 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 10, 'log_format': None, 'log_file': None, 'tensorboard_logdir': '/home/drrndrrnprn/nlp/ABST/datasets/semeval-pengb/analyzed/tensorboard', 'wandb_project': None, 'azureml_logging': False, 'seed': 42, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/drrndrrnprn/nlp/ABST/bartabst/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 8192, 'batch_size': 32, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 5000, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 12288, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 500000, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [1], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'bartabst/checkpoints/bart.abst', 'restore_file': 'bartabst/checkpoints/bart.mlm/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 10, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='bart_abst', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='bart_abst', attention_dropout=0.1, azureml_logging=False, batch_size=32, batch_size_valid=32, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.1, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/home/drrndrrnprn/nlp/ABST/datasets/semeval-pengb/analyzed/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layers=6, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0.0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, insert=0.0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', mask=0.2, mask_length='span-poisson', mask_random=0.1, max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=8192, max_tokens_valid='12288', max_update=500000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=10, permute=0.0, permute_sentences=1.0, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', poisson_lambda=3.5, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, replace_length=1, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='bartabst/checkpoints/bart.mlm/checkpoint_best.pt', rotate=0.0, sample_break_mode='eos', save_dir='bartabst/checkpoints/bart.abst', save_interval=1, save_interval_updates=5000, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, shorten_data_split_list='', shorten_method='none', simul_type=None, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='aspect_base_denoising', tensorboard_logdir='/home/drrndrrnprn/nlp/ABST/datasets/semeval-pengb/analyzed/tensorboard', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, total_num_update='20000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[1], use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir='/home/drrndrrnprn/nlp/ABST/bartabst/', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=5000, wandb_project=None, warmup_updates=500, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': Namespace(_name='aspect_base_denoising', activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='bart_abst', attention_dropout=0.1, azureml_logging=False, batch_size=32, batch_size_valid=32, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.1, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/home/drrndrrnprn/nlp/ABST/datasets/semeval-pengb/analyzed/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layers=6, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0.0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eos=2, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, insert=0.0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', mask=0.2, mask_length='span-poisson', mask_random=0.1, max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=8192, max_tokens_valid='12288', max_update=500000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=10, permute=0.0, permute_sentences=1.0, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', poisson_lambda=3.5, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, replace_length=1, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='bartabst/checkpoints/bart.mlm/checkpoint_best.pt', rotate=0.0, sample_break_mode='eos', save_dir='bartabst/checkpoints/bart.abst', save_interval=1, save_interval_updates=5000, scoring='bleu', seed=42, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, shorten_data_split_list='', shorten_method='none', simul_type=None, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='aspect_base_denoising', tensorboard_logdir='/home/drrndrrnprn/nlp/ABST/datasets/semeval-pengb/analyzed/tensorboard', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=512, total_num_update='20000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_freq=[1], use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir='/home/drrndrrnprn/nlp/ABST/bartabst/', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=5000, wandb_project=None, warmup_updates=500, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 500, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 20000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2021-12-14 01:45:09 | INFO | bartabst.tasks.aspect_base_denoising | dictionary: 51200 types
2021-12-14 01:45:11 | INFO | fairseq_cli.train | BARTMLModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51205, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51205, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=51205, bias=False)
  )
  (classification_heads): ModuleDict()
  (lm_head): BARTEncoderLMHead(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
2021-12-14 01:45:11 | INFO | fairseq_cli.train | task: AspectBaseDenoisingTask
2021-12-14 01:45:11 | INFO | fairseq_cli.train | model: BARTMLModel
2021-12-14 01:45:11 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2021-12-14 01:45:11 | INFO | fairseq_cli.train | num. shared model params: 140,785,669 (num. trained: 140,785,669)
2021-12-14 01:45:11 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2021-12-14 01:45:11 | INFO | bartabst.data.data_utils | loaded 907 examples from: /home/drrndrrnprn/nlp/ABST/datasets/semeval-pengb/analyzed/data-bin/valid
2021-12-14 01:45:11 | INFO | bartabst.tasks.aspect_base_denoising | Split: valid, Loaded 907 samples of denoising_dataset
2021-12-14 01:45:15 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-12-14 01:45:15 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-12-14 01:45:15 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- lm_head.weight
2021-12-14 01:45:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-12-14 01:45:15 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 24.000 GB ; name = NVIDIA GeForce RTX 3090                 
2021-12-14 01:45:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-12-14 01:45:15 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-12-14 01:45:15 | INFO | fairseq_cli.train | max tokens per device = 8192 and max sentences per device = 32
2021-12-14 01:45:15 | INFO | fairseq.trainer | Preparing to load checkpoint bartabst/checkpoints/bart.mlm/checkpoint_best.pt
2021-12-14 01:45:17 | INFO | fairseq.trainer | Loaded checkpoint bartabst/checkpoints/bart.mlm/checkpoint_best.pt (epoch 87 @ 0 updates)
2021-12-14 01:45:17 | INFO | fairseq.trainer | loading train data for epoch 1
2021-12-14 01:45:18 | INFO | bartabst.data.data_utils | loaded 3,163 examples from: /home/drrndrrnprn/nlp/ABST/datasets/semeval-pengb/analyzed/data-bin/train
2021-12-14 01:45:18 | INFO | bartabst.tasks.aspect_base_denoising | Split: train, Loaded 3163 samples of denoising_dataset
2021-12-14 01:45:18 | INFO | fairseq.trainer | begin training epoch 1
2021-12-14 01:45:18 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:45:19 | INFO | train_inner | epoch 001:     10 / 99 loss=16.013, ppl=66137.6, wps=6845.3, ups=11.85, wpb=556.6, bsz=32, num_updates=10, lr=6e-07, gnorm=11.465, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=4
2021-12-14 01:45:20 | INFO | train_inner | epoch 001:     20 / 99 loss=15.835, ppl=58438.5, wps=7327.5, ups=12.51, wpb=585.5, bsz=32, num_updates=20, lr=1.2e-06, gnorm=12.235, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=5
2021-12-14 01:45:21 | INFO | train_inner | epoch 001:     30 / 99 loss=15.325, ppl=41033.8, wps=10279, ups=13.23, wpb=776.8, bsz=32, num_updates=30, lr=1.8e-06, gnorm=10.183, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=5
2021-12-14 01:45:21 | INFO | train_inner | epoch 001:     40 / 99 loss=14.289, ppl=20016, wps=6769.3, ups=13.35, wpb=506.9, bsz=32, num_updates=40, lr=2.4e-06, gnorm=11.778, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=6
2021-12-14 01:45:22 | INFO | train_inner | epoch 001:     50 / 99 loss=13.207, ppl=9455.24, wps=7436.5, ups=13.27, wpb=560.2, bsz=32, num_updates=50, lr=3e-06, gnorm=10.976, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=7
2021-12-14 01:45:23 | INFO | train_inner | epoch 001:     60 / 99 loss=12.133, ppl=4490.97, wps=8837.2, ups=13.06, wpb=676.9, bsz=32, num_updates=60, lr=3.6e-06, gnorm=9.025, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=8
2021-12-14 01:45:24 | INFO | train_inner | epoch 001:     70 / 99 loss=10.904, ppl=1916.21, wps=8796.4, ups=12.82, wpb=686.4, bsz=31.5, num_updates=70, lr=4.2e-06, gnorm=6.936, clip=100, loss_scale=128, train_wall=1, gb_free=19.1, wall=9
2021-12-14 01:45:24 | INFO | train_inner | epoch 001:     80 / 99 loss=9.885, ppl=945.5, wps=8140.7, ups=12.92, wpb=630.3, bsz=32, num_updates=80, lr=4.8e-06, gnorm=4.274, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=9
2021-12-14 01:45:25 | INFO | train_inner | epoch 001:     90 / 99 loss=9.848, ppl=921.87, wps=10240, ups=13.27, wpb=771.8, bsz=32, num_updates=90, lr=5.4e-06, gnorm=2.703, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=10
2021-12-14 01:45:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:45:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.539 | ppl 744.05 | wps 23926 | wpb 586.4 | bsz 31.3 | num_updates 99
2021-12-14 01:45:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 99 updates
2021-12-14 01:45:27 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:45:31 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:45:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 1 @ 99 updates, score 9.539) (writing took 5.184797910042107 seconds)
2021-12-14 01:45:32 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-12-14 01:45:32 | INFO | train | epoch 001 | loss 12.619 | ppl 6290.88 | wps 4546 | ups 7.18 | wpb 630.8 | bsz 31.9 | num_updates 99 | lr 5.94e-06 | gnorm 8.287 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 17
2021-12-14 01:45:32 | INFO | fairseq.trainer | begin training epoch 2
2021-12-14 01:45:32 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:45:32 | INFO | train_inner | epoch 002:      1 / 99 loss=9.189, ppl=583.65, wps=789.9, ups=1.45, wpb=544.4, bsz=32, num_updates=100, lr=6e-06, gnorm=2.709, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=17
2021-12-14 01:45:33 | INFO | train_inner | epoch 002:     11 / 99 loss=9.285, ppl=623.89, wps=8431.3, ups=13.77, wpb=612.1, bsz=32, num_updates=110, lr=6.6e-06, gnorm=2.677, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=18
2021-12-14 01:45:34 | INFO | train_inner | epoch 002:     21 / 99 loss=9.641, ppl=798.44, wps=10853.1, ups=13.85, wpb=783.4, bsz=31.5, num_updates=120, lr=7.2e-06, gnorm=2.322, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=18
2021-12-14 01:45:34 | INFO | train_inner | epoch 002:     31 / 99 loss=9.4, ppl=675.77, wps=11993.7, ups=14.94, wpb=802.7, bsz=32, num_updates=130, lr=7.8e-06, gnorm=2.241, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=19
2021-12-14 01:45:35 | INFO | train_inner | epoch 002:     41 / 99 loss=9.206, ppl=590.72, wps=9878.6, ups=15.37, wpb=642.9, bsz=32, num_updates=140, lr=8.4e-06, gnorm=3.262, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=20
2021-12-14 01:45:36 | INFO | train_inner | epoch 002:     51 / 99 loss=8.443, ppl=347.97, wps=7332.7, ups=15.78, wpb=464.7, bsz=32, num_updates=150, lr=9e-06, gnorm=2.814, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=20
2021-12-14 01:45:36 | INFO | train_inner | epoch 002:     61 / 99 loss=8.363, ppl=329.15, wps=7523.3, ups=15.82, wpb=475.7, bsz=32, num_updates=160, lr=9.6e-06, gnorm=3.033, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=21
2021-12-14 01:45:37 | INFO | train_inner | epoch 002:     71 / 99 loss=8.985, ppl=506.66, wps=9908.7, ups=14.7, wpb=674, bsz=32, num_updates=170, lr=1.02e-05, gnorm=2.85, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=22
2021-12-14 01:45:38 | INFO | train_inner | epoch 002:     81 / 99 loss=8.742, ppl=428.15, wps=7958.4, ups=12.05, wpb=660.2, bsz=32, num_updates=180, lr=1.08e-05, gnorm=2.31, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=23
2021-12-14 01:45:39 | INFO | train_inner | epoch 002:     91 / 99 loss=8.507, ppl=363.8, wps=7132.4, ups=12.06, wpb=591.4, bsz=32, num_updates=190, lr=1.14e-05, gnorm=2.833, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=23
2021-12-14 01:45:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:45:40 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.714 | ppl 419.81 | wps 19034 | wpb 586.4 | bsz 31.3 | num_updates 198 | best_loss 8.714
2021-12-14 01:45:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 198 updates
2021-12-14 01:45:40 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:45:43 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:45:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 2 @ 198 updates, score 8.714) (writing took 3.8050690840464085 seconds)
2021-12-14 01:45:44 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-12-14 01:45:44 | INFO | train | epoch 002 | loss 8.977 | ppl 504.02 | wps 5203.7 | ups 8.25 | wpb 630.8 | bsz 31.9 | num_updates 198 | lr 1.188e-05 | gnorm 2.708 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 29
2021-12-14 01:45:44 | INFO | fairseq.trainer | begin training epoch 3
2021-12-14 01:45:44 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:45:44 | INFO | train_inner | epoch 003:      2 / 99 loss=8.363, ppl=329.34, wps=914.6, ups=1.75, wpb=522.1, bsz=32, num_updates=200, lr=1.2e-05, gnorm=3.674, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=29
2021-12-14 01:45:45 | INFO | train_inner | epoch 003:     12 / 99 loss=8.814, ppl=450.02, wps=8367.2, ups=11.54, wpb=725.3, bsz=31.5, num_updates=210, lr=1.26e-05, gnorm=2.374, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=30
2021-12-14 01:45:46 | INFO | train_inner | epoch 003:     22 / 99 loss=8.061, ppl=267.05, wps=6292.3, ups=11.76, wpb=534.9, bsz=32, num_updates=220, lr=1.32e-05, gnorm=2.721, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=31
2021-12-14 01:45:47 | INFO | train_inner | epoch 003:     32 / 99 loss=8.423, ppl=343.31, wps=6834.9, ups=10.8, wpb=632.8, bsz=32, num_updates=230, lr=1.38e-05, gnorm=2.389, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=32
2021-12-14 01:45:48 | INFO | train_inner | epoch 003:     42 / 99 loss=8.041, ppl=263.32, wps=8014.2, ups=13.87, wpb=577.9, bsz=32, num_updates=240, lr=1.44e-05, gnorm=2.324, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=32
2021-12-14 01:45:48 | INFO | train_inner | epoch 003:     52 / 99 loss=8.343, ppl=324.64, wps=9807.5, ups=14.77, wpb=664, bsz=32, num_updates=250, lr=1.5e-05, gnorm=2.156, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=33
2021-12-14 01:45:49 | INFO | train_inner | epoch 003:     62 / 99 loss=7.974, ppl=251.43, wps=9740.7, ups=15.63, wpb=623.3, bsz=32, num_updates=260, lr=1.56e-05, gnorm=2.214, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=34
2021-12-14 01:45:50 | INFO | train_inner | epoch 003:     72 / 99 loss=8.289, ppl=312.78, wps=11205.5, ups=15.44, wpb=725.8, bsz=32, num_updates=270, lr=1.62e-05, gnorm=2.298, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=34
2021-12-14 01:45:50 | INFO | train_inner | epoch 003:     82 / 99 loss=8.345, ppl=325.13, wps=11038.4, ups=15.16, wpb=728.1, bsz=32, num_updates=280, lr=1.68e-05, gnorm=2.182, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=35
2021-12-14 01:45:51 | INFO | train_inner | epoch 003:     92 / 99 loss=7.783, ppl=220.18, wps=7404.5, ups=12.48, wpb=593.3, bsz=32, num_updates=290, lr=1.74e-05, gnorm=2.405, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=36
2021-12-14 01:45:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:45:53 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.008 | ppl 257.48 | wps 22317.2 | wpb 586.4 | bsz 31.3 | num_updates 297 | best_loss 8.008
2021-12-14 01:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 297 updates
2021-12-14 01:45:53 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:45:55 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:45:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 3 @ 297 updates, score 8.008) (writing took 3.9279340570792556 seconds)
2021-12-14 01:45:57 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-12-14 01:45:57 | INFO | train | epoch 003 | loss 8.201 | ppl 294.36 | wps 4968.5 | ups 7.88 | wpb 630.8 | bsz 31.9 | num_updates 297 | lr 1.782e-05 | gnorm 2.45 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 41
2021-12-14 01:45:57 | INFO | fairseq.trainer | begin training epoch 4
2021-12-14 01:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:45:57 | INFO | train_inner | epoch 004:      3 / 99 loss=7.623, ppl=197.12, wps=973.3, ups=1.7, wpb=573.8, bsz=32, num_updates=300, lr=1.8e-05, gnorm=2.416, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=42
2021-12-14 01:45:58 | INFO | train_inner | epoch 004:     13 / 99 loss=7.816, ppl=225.33, wps=7642.8, ups=12, wpb=637, bsz=32, num_updates=310, lr=1.86e-05, gnorm=2.371, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=43
2021-12-14 01:45:59 | INFO | train_inner | epoch 004:     23 / 99 loss=8.075, ppl=269.71, wps=8912.6, ups=12.31, wpb=723.8, bsz=32, num_updates=320, lr=1.92e-05, gnorm=2.175, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=43
2021-12-14 01:45:59 | INFO | train_inner | epoch 004:     33 / 99 loss=6.736, ppl=106.63, wps=5721.5, ups=12.93, wpb=442.5, bsz=32, num_updates=330, lr=1.98e-05, gnorm=2.68, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=44
2021-12-14 01:46:00 | INFO | train_inner | epoch 004:     43 / 99 loss=7.383, ppl=166.91, wps=6725.7, ups=12.45, wpb=540.4, bsz=32, num_updates=340, lr=2.04e-05, gnorm=2.556, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=45
2021-12-14 01:46:01 | INFO | train_inner | epoch 004:     53 / 99 loss=7.253, ppl=152.52, wps=7328.3, ups=12.91, wpb=567.6, bsz=32, num_updates=350, lr=2.1e-05, gnorm=2.614, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=46
2021-12-14 01:46:02 | INFO | train_inner | epoch 004:     63 / 99 loss=7.699, ppl=207.74, wps=8730, ups=12.44, wpb=701.9, bsz=32, num_updates=360, lr=2.16e-05, gnorm=2.631, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=47
2021-12-14 01:46:03 | INFO | train_inner | epoch 004:     73 / 99 loss=7.926, ppl=243.22, wps=9295.4, ups=13.19, wpb=704.6, bsz=31.5, num_updates=370, lr=2.22e-05, gnorm=2.44, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=47
2021-12-14 01:46:03 | INFO | train_inner | epoch 004:     83 / 99 loss=8.14, ppl=282.15, wps=10611.1, ups=12.25, wpb=866.2, bsz=32, num_updates=380, lr=2.28e-05, gnorm=1.958, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=48
2021-12-14 01:46:04 | INFO | train_inner | epoch 004:     93 / 99 loss=6.983, ppl=126.47, wps=6264.9, ups=11.12, wpb=563.3, bsz=32, num_updates=390, lr=2.34e-05, gnorm=2.346, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=49
2021-12-14 01:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:46:06 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.481 | ppl 178.63 | wps 23936 | wpb 586.4 | bsz 31.3 | num_updates 396 | best_loss 7.481
2021-12-14 01:46:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 396 updates
2021-12-14 01:46:06 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:46:08 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:46:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 4 @ 396 updates, score 7.481) (writing took 3.7422087071463466 seconds)
2021-12-14 01:46:09 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-12-14 01:46:09 | INFO | train | epoch 004 | loss 7.592 | ppl 192.88 | wps 4889.6 | ups 7.75 | wpb 630.8 | bsz 31.9 | num_updates 396 | lr 2.376e-05 | gnorm 2.412 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 54
2021-12-14 01:46:09 | INFO | fairseq.trainer | begin training epoch 5
2021-12-14 01:46:09 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:46:10 | INFO | train_inner | epoch 005:      4 / 99 loss=7.368, ppl=165.22, wps=1212.7, ups=1.82, wpb=665.1, bsz=32, num_updates=400, lr=2.4e-05, gnorm=2.216, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=55
2021-12-14 01:46:11 | INFO | train_inner | epoch 005:     14 / 99 loss=7.148, ppl=141.83, wps=6428, ups=10.8, wpb=595.4, bsz=32, num_updates=410, lr=2.46e-05, gnorm=2.748, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=55
2021-12-14 01:46:12 | INFO | train_inner | epoch 005:     24 / 99 loss=7.759, ppl=216.58, wps=8474.2, ups=11.48, wpb=738.3, bsz=32, num_updates=420, lr=2.52e-05, gnorm=2.708, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=56
2021-12-14 01:46:12 | INFO | train_inner | epoch 005:     34 / 99 loss=7.149, ppl=141.94, wps=7302.9, ups=11.95, wpb=611, bsz=32, num_updates=430, lr=2.58e-05, gnorm=2.368, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=57
2021-12-14 01:46:13 | INFO | train_inner | epoch 005:     44 / 99 loss=6.823, ppl=113.26, wps=5587.4, ups=9.97, wpb=560.4, bsz=32, num_updates=440, lr=2.64e-05, gnorm=2.653, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=58
2021-12-14 01:46:15 | INFO | train_inner | epoch 005:     54 / 99 loss=6.314, ppl=79.55, wps=4431.6, ups=9.07, wpb=488.4, bsz=32, num_updates=450, lr=2.7e-05, gnorm=2.712, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=59
2021-12-14 01:46:16 | INFO | train_inner | epoch 005:     64 / 99 loss=6.963, ppl=124.75, wps=6005.4, ups=9.55, wpb=629, bsz=32, num_updates=460, lr=2.76e-05, gnorm=2.368, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=60
2021-12-14 01:46:17 | INFO | train_inner | epoch 005:     74 / 99 loss=6.443, ppl=86.98, wps=4572.6, ups=9.37, wpb=488, bsz=32, num_updates=470, lr=2.82e-05, gnorm=2.612, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=61
2021-12-14 01:46:18 | INFO | train_inner | epoch 005:     84 / 99 loss=7.245, ppl=151.69, wps=6710.1, ups=9.44, wpb=711, bsz=32, num_updates=480, lr=2.88e-05, gnorm=2.174, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=63
2021-12-14 01:46:19 | INFO | train_inner | epoch 005:     94 / 99 loss=7.785, ppl=220.52, wps=9533.2, ups=11.18, wpb=852.4, bsz=31.5, num_updates=490, lr=2.94e-05, gnorm=2.171, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=63
2021-12-14 01:46:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:46:20 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.124 | ppl 139.48 | wps 23205.4 | wpb 586.4 | bsz 31.3 | num_updates 495 | best_loss 7.124
2021-12-14 01:46:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 495 updates
2021-12-14 01:46:20 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:46:22 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:46:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 5 @ 495 updates, score 7.124) (writing took 3.615608681924641 seconds)
2021-12-14 01:46:23 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-12-14 01:46:24 | INFO | train | epoch 005 | loss 7.156 | ppl 142.6 | wps 4414.8 | ups 7 | wpb 630.8 | bsz 31.9 | num_updates 495 | lr 2.97e-05 | gnorm 2.501 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 68
2021-12-14 01:46:24 | INFO | fairseq.trainer | begin training epoch 6
2021-12-14 01:46:24 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:46:24 | INFO | train_inner | epoch 006:      5 / 99 loss=6.519, ppl=91.73, wps=891.2, ups=1.75, wpb=509.8, bsz=32, num_updates=500, lr=3e-05, gnorm=2.836, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=69
2021-12-14 01:46:25 | INFO | train_inner | epoch 006:     15 / 99 loss=6.912, ppl=120.4, wps=7498.4, ups=10.92, wpb=686.5, bsz=32, num_updates=510, lr=2.99846e-05, gnorm=2.247, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=70
2021-12-14 01:46:26 | INFO | train_inner | epoch 006:     25 / 99 loss=7.125, ppl=139.56, wps=7436.3, ups=11.07, wpb=671.9, bsz=32, num_updates=520, lr=2.99692e-05, gnorm=2.336, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=71
2021-12-14 01:46:27 | INFO | train_inner | epoch 006:     35 / 99 loss=6.923, ppl=121.31, wps=5762.2, ups=9.56, wpb=602.5, bsz=32, num_updates=530, lr=2.99538e-05, gnorm=2.605, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=72
2021-12-14 01:46:28 | INFO | train_inner | epoch 006:     45 / 99 loss=7.409, ppl=169.93, wps=7143.9, ups=9.6, wpb=744.5, bsz=31.5, num_updates=540, lr=2.99385e-05, gnorm=2.498, clip=100, loss_scale=128, train_wall=1, gb_free=19.1, wall=73
2021-12-14 01:46:29 | INFO | train_inner | epoch 006:     55 / 99 loss=6.472, ppl=88.77, wps=4998.4, ups=9.23, wpb=541.7, bsz=32, num_updates=550, lr=2.99231e-05, gnorm=2.603, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=74
2021-12-14 01:46:30 | INFO | train_inner | epoch 006:     65 / 99 loss=6.399, ppl=84.39, wps=5339, ups=9.35, wpb=571.2, bsz=32, num_updates=560, lr=2.99077e-05, gnorm=2.458, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=75
2021-12-14 01:46:31 | INFO | train_inner | epoch 006:     75 / 99 loss=6.525, ppl=92.08, wps=6945.7, ups=11.34, wpb=612.7, bsz=32, num_updates=570, lr=2.98923e-05, gnorm=2.385, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=76
2021-12-14 01:46:32 | INFO | train_inner | epoch 006:     85 / 99 loss=6.578, ppl=95.56, wps=8005, ups=13.1, wpb=611, bsz=32, num_updates=580, lr=2.98769e-05, gnorm=2.41, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=77
2021-12-14 01:46:33 | INFO | train_inner | epoch 006:     95 / 99 loss=6.829, ppl=113.69, wps=8637.3, ups=12.55, wpb=688.3, bsz=32, num_updates=590, lr=2.98615e-05, gnorm=2.513, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=78
2021-12-14 01:46:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:46:34 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.789 | ppl 110.58 | wps 23696.2 | wpb 586.4 | bsz 31.3 | num_updates 594 | best_loss 6.789
2021-12-14 01:46:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 594 updates
2021-12-14 01:46:34 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:46:37 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:46:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 6 @ 594 updates, score 6.789) (writing took 3.6817472830880433 seconds)
2021-12-14 01:46:38 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-12-14 01:46:38 | INFO | train | epoch 006 | loss 6.811 | ppl 112.27 | wps 4466.5 | ups 7.08 | wpb 630.8 | bsz 31.9 | num_updates 594 | lr 2.98554e-05 | gnorm 2.489 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 83
2021-12-14 01:46:38 | INFO | fairseq.trainer | begin training epoch 7
2021-12-14 01:46:38 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:46:38 | INFO | train_inner | epoch 007:      6 / 99 loss=6.615, ppl=98, wps=1164.3, ups=1.85, wpb=630.8, bsz=32, num_updates=600, lr=2.98462e-05, gnorm=2.585, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=83
2021-12-14 01:46:39 | INFO | train_inner | epoch 007:     16 / 99 loss=6.144, ppl=70.74, wps=6871.1, ups=13.11, wpb=524, bsz=32, num_updates=610, lr=2.98308e-05, gnorm=2.868, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=84
2021-12-14 01:46:40 | INFO | train_inner | epoch 007:     26 / 99 loss=6.947, ppl=123.37, wps=9635.1, ups=13.51, wpb=713.1, bsz=31.5, num_updates=620, lr=2.98154e-05, gnorm=2.357, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=85
2021-12-14 01:46:41 | INFO | train_inner | epoch 007:     36 / 99 loss=6.671, ppl=101.91, wps=9067.3, ups=13.58, wpb=667.6, bsz=32, num_updates=630, lr=2.98e-05, gnorm=2.413, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=85
2021-12-14 01:46:41 | INFO | train_inner | epoch 007:     46 / 99 loss=6.777, ppl=109.68, wps=8563.3, ups=11.79, wpb=726.6, bsz=32, num_updates=640, lr=2.97846e-05, gnorm=2.452, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=86
2021-12-14 01:46:42 | INFO | train_inner | epoch 007:     56 / 99 loss=6.364, ppl=82.39, wps=6782.2, ups=12.64, wpb=536.4, bsz=32, num_updates=650, lr=2.97692e-05, gnorm=3.067, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=87
2021-12-14 01:46:43 | INFO | train_inner | epoch 007:     66 / 99 loss=6.284, ppl=77.93, wps=7682.2, ups=13.62, wpb=564.2, bsz=32, num_updates=660, lr=2.97538e-05, gnorm=2.712, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=88
2021-12-14 01:46:44 | INFO | train_inner | epoch 007:     76 / 99 loss=6.507, ppl=90.93, wps=7868, ups=11.52, wpb=683.1, bsz=32, num_updates=670, lr=2.97385e-05, gnorm=2.332, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=89
2021-12-14 01:46:45 | INFO | train_inner | epoch 007:     86 / 99 loss=6.697, ppl=103.77, wps=8113.2, ups=11.8, wpb=687.5, bsz=32, num_updates=680, lr=2.97231e-05, gnorm=2.377, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=89
2021-12-14 01:46:46 | INFO | train_inner | epoch 007:     96 / 99 loss=6.233, ppl=75.24, wps=6000, ups=10.14, wpb=591.5, bsz=32, num_updates=690, lr=2.97077e-05, gnorm=2.692, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=90
2021-12-14 01:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:46:47 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.574 | ppl 95.27 | wps 21988.2 | wpb 586.4 | bsz 31.3 | num_updates 693 | best_loss 6.574
2021-12-14 01:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 693 updates
2021-12-14 01:46:47 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:46:49 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:46:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 7 @ 693 updates, score 6.574) (writing took 3.7094087479636073 seconds)
2021-12-14 01:46:50 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-12-14 01:46:50 | INFO | train | epoch 007 | loss 6.524 | ppl 92.04 | wps 4885.6 | ups 7.75 | wpb 630.8 | bsz 31.9 | num_updates 693 | lr 2.97031e-05 | gnorm 2.563 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 95
2021-12-14 01:46:51 | INFO | fairseq.trainer | begin training epoch 8
2021-12-14 01:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:46:51 | INFO | train_inner | epoch 008:      7 / 99 loss=6.023, ppl=65.01, wps=1082.9, ups=1.8, wpb=603, bsz=32, num_updates=700, lr=2.96923e-05, gnorm=2.376, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=96
2021-12-14 01:46:52 | INFO | train_inner | epoch 008:     17 / 99 loss=6.681, ppl=102.63, wps=7849.1, ups=11.68, wpb=672, bsz=31.5, num_updates=710, lr=2.96769e-05, gnorm=2.552, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=97
2021-12-14 01:46:53 | INFO | train_inner | epoch 008:     27 / 99 loss=6.353, ppl=81.75, wps=7224.1, ups=12.03, wpb=600.5, bsz=32, num_updates=720, lr=2.96615e-05, gnorm=2.491, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=98
2021-12-14 01:46:54 | INFO | train_inner | epoch 008:     37 / 99 loss=6.485, ppl=89.55, wps=8389.8, ups=11.6, wpb=723.5, bsz=32, num_updates=730, lr=2.96462e-05, gnorm=2.303, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=99
2021-12-14 01:46:54 | INFO | train_inner | epoch 008:     47 / 99 loss=5.972, ppl=62.75, wps=7909.8, ups=14.22, wpb=556.2, bsz=32, num_updates=740, lr=2.96308e-05, gnorm=2.631, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=99
2021-12-14 01:46:55 | INFO | train_inner | epoch 008:     57 / 99 loss=5.757, ppl=54.08, wps=8421, ups=15.61, wpb=539.5, bsz=32, num_updates=750, lr=2.96154e-05, gnorm=2.571, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=100
2021-12-14 01:46:56 | INFO | train_inner | epoch 008:     67 / 99 loss=6.489, ppl=89.85, wps=9247.6, ups=13.81, wpb=669.7, bsz=32, num_updates=760, lr=2.96e-05, gnorm=2.782, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=101
2021-12-14 01:46:57 | INFO | train_inner | epoch 008:     77 / 99 loss=6.45, ppl=87.42, wps=9854.2, ups=13.41, wpb=734.7, bsz=32, num_updates=770, lr=2.95846e-05, gnorm=2.47, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=101
2021-12-14 01:46:57 | INFO | train_inner | epoch 008:     87 / 99 loss=5.649, ppl=50.16, wps=6177.6, ups=11.91, wpb=518.9, bsz=32, num_updates=780, lr=2.95692e-05, gnorm=2.7, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=102
2021-12-14 01:46:58 | INFO | train_inner | epoch 008:     97 / 99 loss=6.085, ppl=67.9, wps=6795.6, ups=11.71, wpb=580.2, bsz=32, num_updates=790, lr=2.95538e-05, gnorm=2.754, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=103
2021-12-14 01:46:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:46:59 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.364 | ppl 82.36 | wps 20397.4 | wpb 586.4 | bsz 31.3 | num_updates 792 | best_loss 6.364
2021-12-14 01:46:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 792 updates
2021-12-14 01:46:59 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:47:02 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:47:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 8 @ 792 updates, score 6.364) (writing took 3.632510638097301 seconds)
2021-12-14 01:47:03 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-12-14 01:47:03 | INFO | train | epoch 008 | loss 6.284 | ppl 77.93 | wps 5000 | ups 7.93 | wpb 630.8 | bsz 31.9 | num_updates 792 | lr 2.95508e-05 | gnorm 2.56 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 108
2021-12-14 01:47:03 | INFO | fairseq.trainer | begin training epoch 9
2021-12-14 01:47:03 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:47:04 | INFO | train_inner | epoch 009:      8 / 99 loss=6.388, ppl=83.78, wps=1271.4, ups=1.87, wpb=679.1, bsz=32, num_updates=800, lr=2.95385e-05, gnorm=2.578, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=108
2021-12-14 01:47:04 | INFO | train_inner | epoch 009:     18 / 99 loss=6.055, ppl=66.49, wps=9133.9, ups=14.01, wpb=652, bsz=32, num_updates=810, lr=2.95231e-05, gnorm=2.438, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=109
2021-12-14 01:47:05 | INFO | train_inner | epoch 009:     28 / 99 loss=6.141, ppl=70.57, wps=9415.7, ups=14.95, wpb=629.8, bsz=32, num_updates=820, lr=2.95077e-05, gnorm=2.714, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=110
2021-12-14 01:47:06 | INFO | train_inner | epoch 009:     38 / 99 loss=6.601, ppl=97.11, wps=11233.7, ups=14.76, wpb=761.1, bsz=32, num_updates=830, lr=2.94923e-05, gnorm=2.487, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=110
2021-12-14 01:47:06 | INFO | train_inner | epoch 009:     48 / 99 loss=6.292, ppl=78.33, wps=10213, ups=14.09, wpb=724.8, bsz=32, num_updates=840, lr=2.94769e-05, gnorm=2.255, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=111
2021-12-14 01:47:07 | INFO | train_inner | epoch 009:     58 / 99 loss=4.891, ppl=29.67, wps=6798.1, ups=15.71, wpb=432.7, bsz=32, num_updates=850, lr=2.94615e-05, gnorm=2.793, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=112
2021-12-14 01:47:08 | INFO | train_inner | epoch 009:     68 / 99 loss=5.306, ppl=39.55, wps=7970.8, ups=15.87, wpb=502.4, bsz=32, num_updates=860, lr=2.94462e-05, gnorm=2.811, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=112
2021-12-14 01:47:08 | INFO | train_inner | epoch 009:     78 / 99 loss=6.783, ppl=110.09, wps=11586.4, ups=14.9, wpb=777.7, bsz=31.5, num_updates=870, lr=2.94308e-05, gnorm=2.527, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=113
2021-12-14 01:47:09 | INFO | train_inner | epoch 009:     88 / 99 loss=5.512, ppl=45.63, wps=7825.4, ups=14.82, wpb=528.1, bsz=32, num_updates=880, lr=2.94154e-05, gnorm=2.705, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=114
2021-12-14 01:47:10 | INFO | train_inner | epoch 009:     98 / 99 loss=6.221, ppl=74.61, wps=8703.8, ups=12.5, wpb=696.5, bsz=32, num_updates=890, lr=2.94e-05, gnorm=2.602, clip=100, loss_scale=128, train_wall=1, gb_free=20, wall=115
2021-12-14 01:47:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:47:11 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.223 | ppl 74.68 | wps 19783 | wpb 586.4 | bsz 31.3 | num_updates 891 | best_loss 6.223
2021-12-14 01:47:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 891 updates
2021-12-14 01:47:11 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 9 @ 891 updates, score 6.223) (writing took 3.648312635952607 seconds)
2021-12-14 01:47:15 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-12-14 01:47:15 | INFO | train | epoch 009 | loss 6.068 | ppl 67.08 | wps 5407 | ups 8.57 | wpb 630.8 | bsz 31.9 | num_updates 891 | lr 2.93985e-05 | gnorm 2.599 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 119
2021-12-14 01:47:15 | INFO | fairseq.trainer | begin training epoch 10
2021-12-14 01:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:47:15 | INFO | train_inner | epoch 010:      9 / 99 loss=5.355, ppl=40.93, wps=982, ups=1.83, wpb=537.2, bsz=32, num_updates=900, lr=2.93846e-05, gnorm=2.694, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=120
2021-12-14 01:47:16 | INFO | train_inner | epoch 010:     19 / 99 loss=5.467, ppl=44.24, wps=8240.9, ups=14.79, wpb=557.1, bsz=32, num_updates=910, lr=2.93692e-05, gnorm=2.827, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=121
2021-12-14 01:47:17 | INFO | train_inner | epoch 010:     29 / 99 loss=6.338, ppl=80.9, wps=9333.4, ups=11.59, wpb=805.3, bsz=32, num_updates=920, lr=2.93538e-05, gnorm=2.717, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=122
2021-12-14 01:47:18 | INFO | train_inner | epoch 010:     39 / 99 loss=6.354, ppl=81.79, wps=9160.1, ups=11.14, wpb=822.1, bsz=32, num_updates=930, lr=2.93385e-05, gnorm=2.289, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=123
2021-12-14 01:47:19 | INFO | train_inner | epoch 010:     49 / 99 loss=6.254, ppl=76.32, wps=7803.4, ups=11.59, wpb=673.4, bsz=32, num_updates=940, lr=2.93231e-05, gnorm=2.453, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=123
2021-12-14 01:47:20 | INFO | train_inner | epoch 010:     59 / 99 loss=4.983, ppl=31.63, wps=4983.9, ups=11.01, wpb=452.6, bsz=32, num_updates=950, lr=2.93077e-05, gnorm=3.129, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=124
2021-12-14 01:47:21 | INFO | train_inner | epoch 010:     69 / 99 loss=5.187, ppl=36.43, wps=4472.5, ups=9.08, wpb=492.5, bsz=32, num_updates=960, lr=2.92923e-05, gnorm=2.974, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=125
2021-12-14 01:47:22 | INFO | train_inner | epoch 010:     79 / 99 loss=5.803, ppl=55.85, wps=5953.6, ups=9.36, wpb=636.2, bsz=32, num_updates=970, lr=2.92769e-05, gnorm=2.514, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=127
2021-12-14 01:47:23 | INFO | train_inner | epoch 010:     89 / 99 loss=5.545, ppl=46.7, wps=6505.7, ups=11.01, wpb=590.7, bsz=32, num_updates=980, lr=2.92615e-05, gnorm=2.622, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=127
2021-12-14 01:47:24 | INFO | train_inner | epoch 010:     99 / 99 loss=6.5, ppl=90.54, wps=7613.7, ups=10.27, wpb=741.1, bsz=31.5, num_updates=990, lr=2.92462e-05, gnorm=2.542, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=128
2021-12-14 01:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:47:24 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.068 | ppl 67.07 | wps 23108.7 | wpb 586.4 | bsz 31.3 | num_updates 990 | best_loss 6.068
2021-12-14 01:47:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 990 updates
2021-12-14 01:47:24 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:47:27 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:47:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 10 @ 990 updates, score 6.068) (writing took 3.696515874005854 seconds)
2021-12-14 01:47:28 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-12-14 01:47:28 | INFO | train | epoch 010 | loss 5.875 | ppl 58.67 | wps 4599 | ups 7.29 | wpb 630.8 | bsz 31.9 | num_updates 990 | lr 2.92462e-05 | gnorm 2.676 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 133
2021-12-14 01:47:28 | INFO | fairseq.trainer | begin training epoch 11
2021-12-14 01:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:47:29 | INFO | train_inner | epoch 011:     10 / 99 loss=5.827, ppl=56.75, wps=1218.1, ups=1.84, wpb=663.5, bsz=32, num_updates=1000, lr=2.92308e-05, gnorm=2.636, clip=100, loss_scale=128, train_wall=1, gb_free=20, wall=134
2021-12-14 01:47:30 | INFO | train_inner | epoch 011:     20 / 99 loss=5.704, ppl=52.11, wps=7969.4, ups=11.92, wpb=668.5, bsz=32, num_updates=1010, lr=2.92154e-05, gnorm=2.486, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=135
2021-12-14 01:47:31 | INFO | train_inner | epoch 011:     30 / 99 loss=5.304, ppl=39.52, wps=6789.7, ups=12.73, wpb=533.2, bsz=32, num_updates=1020, lr=2.92e-05, gnorm=3.075, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=135
2021-12-14 01:47:31 | INFO | train_inner | epoch 011:     40 / 99 loss=5.894, ppl=59.45, wps=7645.3, ups=12.69, wpb=602.5, bsz=31.5, num_updates=1030, lr=2.91846e-05, gnorm=2.695, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=136
2021-12-14 01:47:32 | INFO | train_inner | epoch 011:     50 / 99 loss=5.772, ppl=54.63, wps=9501, ups=13.92, wpb=682.4, bsz=32, num_updates=1040, lr=2.91692e-05, gnorm=2.432, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=137
2021-12-14 01:47:33 | INFO | train_inner | epoch 011:     60 / 99 loss=6.43, ppl=86.25, wps=10528.7, ups=13.29, wpb=792.5, bsz=32, num_updates=1050, lr=2.91538e-05, gnorm=2.606, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=138
2021-12-14 01:47:34 | INFO | train_inner | epoch 011:     70 / 99 loss=5.48, ppl=44.63, wps=9101.5, ups=15.07, wpb=604, bsz=32, num_updates=1060, lr=2.91385e-05, gnorm=2.729, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=138
2021-12-14 01:47:34 | INFO | train_inner | epoch 011:     80 / 99 loss=5.302, ppl=39.45, wps=8164.3, ups=14.63, wpb=558.2, bsz=32, num_updates=1070, lr=2.91231e-05, gnorm=2.971, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=139
2021-12-14 01:47:35 | INFO | train_inner | epoch 011:     90 / 99 loss=5.58, ppl=47.84, wps=7812.5, ups=12.84, wpb=608.6, bsz=32, num_updates=1080, lr=2.91077e-05, gnorm=2.551, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=140
2021-12-14 01:47:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:47:37 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.882 | ppl 58.98 | wps 25258.4 | wpb 586.4 | bsz 31.3 | num_updates 1089 | best_loss 5.882
2021-12-14 01:47:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1089 updates
2021-12-14 01:47:37 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:47:39 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:47:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 11 @ 1089 updates, score 5.882) (writing took 3.718389994930476 seconds)
2021-12-14 01:47:40 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-12-14 01:47:41 | INFO | train | epoch 011 | loss 5.704 | ppl 52.13 | wps 5073.4 | ups 8.04 | wpb 630.8 | bsz 31.9 | num_updates 1089 | lr 2.90938e-05 | gnorm 2.68 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 145
2021-12-14 01:47:41 | INFO | fairseq.trainer | begin training epoch 12
2021-12-14 01:47:41 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:47:42 | INFO | train_inner | epoch 012:      1 / 99 loss=5.293, ppl=39.2, wps=889.9, ups=1.54, wpb=579.2, bsz=32, num_updates=1090, lr=2.90923e-05, gnorm=2.608, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=146
2021-12-14 01:47:42 | INFO | train_inner | epoch 012:     11 / 99 loss=5.514, ppl=45.7, wps=8227.6, ups=12.32, wpb=667.8, bsz=32, num_updates=1100, lr=2.90769e-05, gnorm=2.652, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=147
2021-12-14 01:47:43 | INFO | train_inner | epoch 012:     21 / 99 loss=6.041, ppl=65.86, wps=9642.4, ups=13.33, wpb=723.3, bsz=32, num_updates=1110, lr=2.90615e-05, gnorm=3.311, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=148
2021-12-14 01:47:44 | INFO | train_inner | epoch 012:     31 / 99 loss=6.155, ppl=71.26, wps=11337, ups=14.53, wpb=780.5, bsz=32, num_updates=1120, lr=2.90462e-05, gnorm=2.659, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=149
2021-12-14 01:47:45 | INFO | train_inner | epoch 012:     41 / 99 loss=6.046, ppl=66.07, wps=8180.4, ups=11.75, wpb=696, bsz=31.5, num_updates=1130, lr=2.90308e-05, gnorm=2.694, clip=100, loss_scale=128, train_wall=1, gb_free=19.1, wall=149
2021-12-14 01:47:45 | INFO | train_inner | epoch 012:     51 / 99 loss=6.048, ppl=66.17, wps=10540.8, ups=13.58, wpb=776.1, bsz=32, num_updates=1140, lr=2.90154e-05, gnorm=2.332, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=150
2021-12-14 01:47:46 | INFO | train_inner | epoch 012:     61 / 99 loss=5.259, ppl=38.29, wps=7414.3, ups=12.31, wpb=602.5, bsz=32, num_updates=1150, lr=2.9e-05, gnorm=2.525, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=151
2021-12-14 01:47:47 | INFO | train_inner | epoch 012:     71 / 99 loss=4.985, ppl=31.66, wps=7568.9, ups=14.18, wpb=533.8, bsz=32, num_updates=1160, lr=2.89846e-05, gnorm=2.737, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=152
2021-12-14 01:47:48 | INFO | train_inner | epoch 012:     81 / 99 loss=5.317, ppl=39.87, wps=7482, ups=13.43, wpb=557.1, bsz=32, num_updates=1170, lr=2.89692e-05, gnorm=3.014, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=153
2021-12-14 01:47:49 | INFO | train_inner | epoch 012:     91 / 99 loss=4.586, ppl=24.02, wps=6041.2, ups=12.05, wpb=501.2, bsz=32, num_updates=1180, lr=2.89538e-05, gnorm=3.315, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=153
2021-12-14 01:47:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:47:50 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.744 | ppl 53.59 | wps 23082.5 | wpb 586.4 | bsz 31.3 | num_updates 1188 | best_loss 5.744
2021-12-14 01:47:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1188 updates
2021-12-14 01:47:50 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:47:54 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:47:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 12 @ 1188 updates, score 5.744) (writing took 8.255495707970113 seconds)
2021-12-14 01:47:58 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-12-14 01:47:58 | INFO | train | epoch 012 | loss 5.541 | ppl 46.57 | wps 3706 | ups 5.88 | wpb 630.8 | bsz 31.9 | num_updates 1188 | lr 2.89415e-05 | gnorm 2.826 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 163
2021-12-14 01:47:58 | INFO | fairseq.trainer | begin training epoch 13
2021-12-14 01:47:58 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:47:59 | INFO | train_inner | epoch 013:      2 / 99 loss=4.827, ppl=28.39, wps=513.8, ups=1, wpb=512.9, bsz=32, num_updates=1190, lr=2.89385e-05, gnorm=3.039, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=163
2021-12-14 01:47:59 | INFO | train_inner | epoch 013:     12 / 99 loss=6.088, ppl=68.01, wps=10402.1, ups=12.82, wpb=811.4, bsz=32, num_updates=1200, lr=2.89231e-05, gnorm=2.658, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=164
2021-12-14 01:48:00 | INFO | train_inner | epoch 013:     22 / 99 loss=4.898, ppl=29.82, wps=7358.4, ups=13.52, wpb=544.2, bsz=32, num_updates=1210, lr=2.89077e-05, gnorm=2.868, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=165
2021-12-14 01:48:01 | INFO | train_inner | epoch 013:     32 / 99 loss=5.412, ppl=42.58, wps=7835.4, ups=12.21, wpb=641.6, bsz=32, num_updates=1220, lr=2.88923e-05, gnorm=2.576, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=166
2021-12-14 01:48:02 | INFO | train_inner | epoch 013:     42 / 99 loss=5.123, ppl=34.84, wps=6440.4, ups=11.37, wpb=566.6, bsz=32, num_updates=1230, lr=2.88769e-05, gnorm=2.751, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=167
2021-12-14 01:48:03 | INFO | train_inner | epoch 013:     52 / 99 loss=4.87, ppl=29.24, wps=5933.9, ups=11.56, wpb=513.5, bsz=32, num_updates=1240, lr=2.88615e-05, gnorm=3.025, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=167
2021-12-14 01:48:04 | INFO | train_inner | epoch 013:     62 / 99 loss=5.165, ppl=35.87, wps=6866.4, ups=11.07, wpb=620, bsz=32, num_updates=1250, lr=2.88462e-05, gnorm=2.823, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=168
2021-12-14 01:48:04 | INFO | train_inner | epoch 013:     72 / 99 loss=4.934, ppl=30.57, wps=7187.1, ups=12.29, wpb=584.8, bsz=32, num_updates=1260, lr=2.88308e-05, gnorm=2.943, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=169
2021-12-14 01:48:05 | INFO | train_inner | epoch 013:     82 / 99 loss=5.693, ppl=51.74, wps=6531, ups=9.55, wpb=684.1, bsz=32, num_updates=1270, lr=2.88154e-05, gnorm=2.972, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=170
2021-12-14 01:48:06 | INFO | train_inner | epoch 013:     92 / 99 loss=5.877, ppl=58.76, wps=6925.2, ups=9.92, wpb=698.2, bsz=31.5, num_updates=1280, lr=2.88e-05, gnorm=2.717, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=171
2021-12-14 01:48:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:48:08 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 5.554 | ppl 46.97 | wps 23755.4 | wpb 586.4 | bsz 31.3 | num_updates 1287 | best_loss 5.554
2021-12-14 01:48:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1287 updates
2021-12-14 01:48:08 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:48:11 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:48:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 13 @ 1287 updates, score 5.554) (writing took 4.150844123912975 seconds)
2021-12-14 01:48:12 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-12-14 01:48:12 | INFO | train | epoch 013 | loss 5.373 | ppl 41.45 | wps 4541.7 | ups 7.2 | wpb 630.8 | bsz 31.9 | num_updates 1287 | lr 2.87892e-05 | gnorm 2.792 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 177
2021-12-14 01:48:13 | INFO | fairseq.trainer | begin training epoch 14
2021-12-14 01:48:13 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:48:13 | INFO | train_inner | epoch 014:      3 / 99 loss=4.835, ppl=28.55, wps=932.9, ups=1.55, wpb=600.4, bsz=32, num_updates=1290, lr=2.87846e-05, gnorm=2.588, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=178
2021-12-14 01:48:14 | INFO | train_inner | epoch 014:     13 / 99 loss=5.027, ppl=32.61, wps=8503.5, ups=13.67, wpb=622, bsz=32, num_updates=1300, lr=2.87692e-05, gnorm=2.897, clip=100, loss_scale=128, train_wall=1, gb_free=20.3, wall=178
2021-12-14 01:48:14 | INFO | train_inner | epoch 014:     23 / 99 loss=3.939, ppl=15.34, wps=7084.1, ups=15.23, wpb=465.1, bsz=32, num_updates=1310, lr=2.87538e-05, gnorm=2.851, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=179
2021-12-14 01:48:15 | INFO | train_inner | epoch 014:     33 / 99 loss=5.184, ppl=36.35, wps=8866.7, ups=14.41, wpb=615.1, bsz=32, num_updates=1320, lr=2.87385e-05, gnorm=3.08, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=180
2021-12-14 01:48:16 | INFO | train_inner | epoch 014:     43 / 99 loss=6.338, ppl=80.89, wps=12904.8, ups=14.22, wpb=907.3, bsz=31.5, num_updates=1330, lr=2.87231e-05, gnorm=2.517, clip=100, loss_scale=128, train_wall=1, gb_free=19.1, wall=180
2021-12-14 01:48:16 | INFO | train_inner | epoch 014:     53 / 99 loss=5.147, ppl=35.43, wps=9303.8, ups=15.39, wpb=604.6, bsz=32, num_updates=1340, lr=2.87077e-05, gnorm=2.747, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=181
2021-12-14 01:48:17 | INFO | train_inner | epoch 014:     63 / 99 loss=5.23, ppl=37.53, wps=9451.4, ups=13.71, wpb=689.3, bsz=32, num_updates=1350, lr=2.86923e-05, gnorm=2.549, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=182
2021-12-14 01:48:18 | INFO | train_inner | epoch 014:     73 / 99 loss=4.386, ppl=20.9, wps=7477.2, ups=15.01, wpb=498.3, bsz=32, num_updates=1360, lr=2.86769e-05, gnorm=2.839, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=182
2021-12-14 01:48:18 | INFO | train_inner | epoch 014:     83 / 99 loss=5.662, ppl=50.64, wps=10353.2, ups=14.75, wpb=701.8, bsz=32, num_updates=1370, lr=2.86615e-05, gnorm=2.758, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=183
2021-12-14 01:48:19 | INFO | train_inner | epoch 014:     93 / 99 loss=4.81, ppl=28.05, wps=6996.6, ups=11.9, wpb=587.9, bsz=32, num_updates=1380, lr=2.86462e-05, gnorm=2.767, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=184
2021-12-14 01:48:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:48:21 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 5.363 | ppl 41.15 | wps 23160.9 | wpb 586.4 | bsz 31.3 | num_updates 1386 | best_loss 5.363
2021-12-14 01:48:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1386 updates
2021-12-14 01:48:21 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:48:23 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:48:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 14 @ 1386 updates, score 5.363) (writing took 15.60812191804871 seconds)
2021-12-14 01:48:36 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-12-14 01:48:36 | INFO | train | epoch 014 | loss 5.18 | ppl 36.26 | wps 2629.5 | ups 4.17 | wpb 630.8 | bsz 31.9 | num_updates 1386 | lr 2.86369e-05 | gnorm 2.775 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.6 | wall 201
2021-12-14 01:48:36 | INFO | fairseq.trainer | begin training epoch 15
2021-12-14 01:48:36 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:48:37 | INFO | train_inner | epoch 015:      4 / 99 loss=4.618, ppl=24.56, wps=313.5, ups=0.57, wpb=545.8, bsz=32, num_updates=1390, lr=2.86308e-05, gnorm=3.001, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=201
2021-12-14 01:48:37 | INFO | train_inner | epoch 015:     14 / 99 loss=5.461, ppl=44.05, wps=8326.1, ups=12.11, wpb=687.7, bsz=32, num_updates=1400, lr=2.86154e-05, gnorm=2.732, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=202
2021-12-14 01:48:38 | INFO | train_inner | epoch 015:     24 / 99 loss=5.033, ppl=32.73, wps=10323.2, ups=15.12, wpb=682.9, bsz=32, num_updates=1410, lr=2.86e-05, gnorm=2.529, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=203
2021-12-14 01:48:39 | INFO | train_inner | epoch 015:     34 / 99 loss=4.582, ppl=23.94, wps=8816.5, ups=15.7, wpb=561.6, bsz=32, num_updates=1420, lr=2.85846e-05, gnorm=3.265, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=204
2021-12-14 01:48:39 | INFO | train_inner | epoch 015:     44 / 99 loss=4.339, ppl=20.23, wps=8108.5, ups=15.7, wpb=516.6, bsz=32, num_updates=1430, lr=2.85692e-05, gnorm=2.916, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=204
2021-12-14 01:48:40 | INFO | train_inner | epoch 015:     54 / 99 loss=5.298, ppl=39.33, wps=9833.3, ups=14.74, wpb=667, bsz=32, num_updates=1440, lr=2.85538e-05, gnorm=2.935, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=205
2021-12-14 01:48:41 | INFO | train_inner | epoch 015:     64 / 99 loss=5.07, ppl=33.59, wps=10519.7, ups=15.5, wpb=678.9, bsz=32, num_updates=1450, lr=2.85385e-05, gnorm=2.852, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=206
2021-12-14 01:48:41 | INFO | train_inner | epoch 015:     74 / 99 loss=4.721, ppl=26.38, wps=8935.2, ups=15.62, wpb=572, bsz=32, num_updates=1460, lr=2.85231e-05, gnorm=2.962, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=206
2021-12-14 01:48:42 | INFO | train_inner | epoch 015:     84 / 99 loss=5.107, ppl=34.46, wps=10555.3, ups=15.5, wpb=681.2, bsz=32, num_updates=1470, lr=2.85077e-05, gnorm=2.773, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=207
2021-12-14 01:48:43 | INFO | train_inner | epoch 015:     94 / 99 loss=4.83, ppl=28.43, wps=7285, ups=11.96, wpb=609.3, bsz=32, num_updates=1480, lr=2.84923e-05, gnorm=2.96, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=208
2021-12-14 01:48:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:48:44 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 5.173 | ppl 36.09 | wps 20119.9 | wpb 586.4 | bsz 31.3 | num_updates 1485 | best_loss 5.173
2021-12-14 01:48:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1485 updates
2021-12-14 01:48:44 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:48:47 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:48:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 15 @ 1485 updates, score 5.173) (writing took 3.8124701061751693 seconds)
2021-12-14 01:48:48 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2021-12-14 01:48:48 | INFO | train | epoch 015 | loss 5.009 | ppl 32.2 | wps 5282.4 | ups 8.37 | wpb 630.8 | bsz 31.9 | num_updates 1485 | lr 2.84846e-05 | gnorm 2.896 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.7 | wall 213
2021-12-14 01:48:48 | INFO | fairseq.trainer | begin training epoch 16
2021-12-14 01:48:48 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:48:49 | INFO | train_inner | epoch 016:      5 / 99 loss=5.337, ppl=40.41, wps=1164.6, ups=1.7, wpb=683.6, bsz=31.5, num_updates=1490, lr=2.84769e-05, gnorm=2.731, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=214
2021-12-14 01:48:49 | INFO | train_inner | epoch 016:     15 / 99 loss=4.732, ppl=26.58, wps=8747.2, ups=13.73, wpb=637.1, bsz=32, num_updates=1500, lr=2.84615e-05, gnorm=2.878, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=214
2021-12-14 01:48:50 | INFO | train_inner | epoch 016:     25 / 99 loss=4.622, ppl=24.62, wps=9348.9, ups=15.33, wpb=610, bsz=32, num_updates=1510, lr=2.84462e-05, gnorm=2.718, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=215
2021-12-14 01:48:51 | INFO | train_inner | epoch 016:     35 / 99 loss=5.131, ppl=35.04, wps=9938.6, ups=15.07, wpb=659.7, bsz=32, num_updates=1520, lr=2.84308e-05, gnorm=2.677, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=216
2021-12-14 01:48:51 | INFO | train_inner | epoch 016:     45 / 99 loss=4.422, ppl=21.44, wps=8400, ups=15.69, wpb=535.4, bsz=32, num_updates=1530, lr=2.84154e-05, gnorm=2.848, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=216
2021-12-14 01:48:52 | INFO | train_inner | epoch 016:     55 / 99 loss=5.491, ppl=44.96, wps=12281.8, ups=15.14, wpb=811.3, bsz=32, num_updates=1540, lr=2.84e-05, gnorm=2.6, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=217
2021-12-14 01:48:53 | INFO | train_inner | epoch 016:     65 / 99 loss=4.902, ppl=29.9, wps=6958.9, ups=10.95, wpb=635.6, bsz=32, num_updates=1550, lr=2.83846e-05, gnorm=2.936, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=218
2021-12-14 01:48:54 | INFO | train_inner | epoch 016:     75 / 99 loss=4.701, ppl=26.01, wps=7445.9, ups=11.5, wpb=647.4, bsz=32, num_updates=1560, lr=2.83692e-05, gnorm=2.684, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=219
2021-12-14 01:48:55 | INFO | train_inner | epoch 016:     85 / 99 loss=4.11, ppl=17.27, wps=6845.3, ups=12.37, wpb=553.6, bsz=32, num_updates=1570, lr=2.83538e-05, gnorm=2.855, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=220
2021-12-14 01:48:56 | INFO | train_inner | epoch 016:     95 / 99 loss=5.564, ppl=47.31, wps=7863.9, ups=10.95, wpb=718.1, bsz=31.5, num_updates=1580, lr=2.83385e-05, gnorm=2.765, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=220
2021-12-14 01:48:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:48:57 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 5.031 | ppl 32.7 | wps 24816.9 | wpb 586.4 | bsz 31.3 | num_updates 1584 | best_loss 5.031
2021-12-14 01:48:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1584 updates
2021-12-14 01:48:57 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:48:59 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:49:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 16 @ 1584 updates, score 5.031) (writing took 3.754259553970769 seconds)
2021-12-14 01:49:01 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2021-12-14 01:49:01 | INFO | train | epoch 016 | loss 4.833 | ppl 28.51 | wps 5114 | ups 8.11 | wpb 630.8 | bsz 31.9 | num_updates 1584 | lr 2.83323e-05 | gnorm 2.782 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 225
2021-12-14 01:49:01 | INFO | fairseq.trainer | begin training epoch 17
2021-12-14 01:49:01 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:49:01 | INFO | train_inner | epoch 017:      6 / 99 loss=4.683, ppl=25.69, wps=1077.8, ups=1.8, wpb=600.2, bsz=32, num_updates=1590, lr=2.83231e-05, gnorm=2.819, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=226
2021-12-14 01:49:02 | INFO | train_inner | epoch 017:     16 / 99 loss=4.34, ppl=20.25, wps=6949.9, ups=12.24, wpb=567.9, bsz=32, num_updates=1600, lr=2.83077e-05, gnorm=2.802, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=227
2021-12-14 01:49:03 | INFO | train_inner | epoch 017:     26 / 99 loss=5.8, ppl=55.72, wps=9224, ups=10.69, wpb=862.5, bsz=31.5, num_updates=1610, lr=2.82923e-05, gnorm=2.503, clip=100, loss_scale=128, train_wall=1, gb_free=20, wall=228
2021-12-14 01:49:04 | INFO | train_inner | epoch 017:     36 / 99 loss=4.297, ppl=19.66, wps=6026.3, ups=10.83, wpb=556.3, bsz=32, num_updates=1620, lr=2.82769e-05, gnorm=3.12, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=229
2021-12-14 01:49:05 | INFO | train_inner | epoch 017:     46 / 99 loss=4.453, ppl=21.9, wps=6262.4, ups=11.09, wpb=564.9, bsz=32, num_updates=1630, lr=2.82615e-05, gnorm=2.896, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=230
2021-12-14 01:49:06 | INFO | train_inner | epoch 017:     56 / 99 loss=4.538, ppl=23.24, wps=7265.5, ups=11.89, wpb=611.3, bsz=32, num_updates=1640, lr=2.82462e-05, gnorm=2.92, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=230
2021-12-14 01:49:06 | INFO | train_inner | epoch 017:     66 / 99 loss=4.598, ppl=24.22, wps=7660.5, ups=11.94, wpb=641.4, bsz=32, num_updates=1650, lr=2.82308e-05, gnorm=2.929, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=231
2021-12-14 01:49:07 | INFO | train_inner | epoch 017:     76 / 99 loss=4.756, ppl=27.03, wps=6925.3, ups=10.98, wpb=631, bsz=32, num_updates=1660, lr=2.82154e-05, gnorm=3.073, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=232
2021-12-14 01:49:08 | INFO | train_inner | epoch 017:     86 / 99 loss=4.168, ppl=17.97, wps=6279.5, ups=10.87, wpb=577.7, bsz=32, num_updates=1670, lr=2.82e-05, gnorm=3.088, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=233
2021-12-14 01:49:09 | INFO | train_inner | epoch 017:     96 / 99 loss=4.363, ppl=20.57, wps=7630.4, ups=12.53, wpb=609, bsz=32, num_updates=1680, lr=2.81846e-05, gnorm=2.817, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=234
2021-12-14 01:49:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:49:10 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.862 | ppl 29.09 | wps 23940.7 | wpb 586.4 | bsz 31.3 | num_updates 1683 | best_loss 4.862
2021-12-14 01:49:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1683 updates
2021-12-14 01:49:10 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:49:13 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:49:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 17 @ 1683 updates, score 4.862) (writing took 5.600227003917098 seconds)
2021-12-14 01:49:16 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2021-12-14 01:49:16 | INFO | train | epoch 017 | loss 4.677 | ppl 25.59 | wps 4104.7 | ups 6.51 | wpb 630.8 | bsz 31.9 | num_updates 1683 | lr 2.818e-05 | gnorm 2.894 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 241
2021-12-14 01:49:16 | INFO | fairseq.trainer | begin training epoch 18
2021-12-14 01:49:16 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:49:16 | INFO | train_inner | epoch 018:      7 / 99 loss=4.904, ppl=29.95, wps=910.5, ups=1.36, wpb=669.4, bsz=32, num_updates=1690, lr=2.81692e-05, gnorm=3.029, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=241
2021-12-14 01:49:17 | INFO | train_inner | epoch 018:     17 / 99 loss=4.325, ppl=20.05, wps=6449.9, ups=10.32, wpb=624.8, bsz=32, num_updates=1700, lr=2.81538e-05, gnorm=2.981, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=242
2021-12-14 01:49:18 | INFO | train_inner | epoch 018:     27 / 99 loss=4.607, ppl=24.37, wps=6924.3, ups=10.43, wpb=664.1, bsz=32, num_updates=1710, lr=2.81385e-05, gnorm=2.92, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=243
2021-12-14 01:49:19 | INFO | train_inner | epoch 018:     37 / 99 loss=5.324, ppl=40.06, wps=8459.1, ups=10.57, wpb=800.4, bsz=32, num_updates=1720, lr=2.81231e-05, gnorm=2.779, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=244
2021-12-14 01:49:20 | INFO | train_inner | epoch 018:     47 / 99 loss=3.821, ppl=14.13, wps=5068, ups=9.6, wpb=528, bsz=32, num_updates=1730, lr=2.81077e-05, gnorm=3.552, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=245
2021-12-14 01:49:21 | INFO | train_inner | epoch 018:     57 / 99 loss=3.89, ppl=14.83, wps=4618.3, ups=9.41, wpb=490.9, bsz=32, num_updates=1740, lr=2.80923e-05, gnorm=3.491, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=246
2021-12-14 01:49:22 | INFO | train_inner | epoch 018:     67 / 99 loss=5.096, ppl=34.21, wps=7275.6, ups=10.2, wpb=713.6, bsz=31.5, num_updates=1750, lr=2.80769e-05, gnorm=2.947, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=247
2021-12-14 01:49:23 | INFO | train_inner | epoch 018:     77 / 99 loss=4.202, ppl=18.41, wps=5281.1, ups=9.45, wpb=559, bsz=32, num_updates=1760, lr=2.80615e-05, gnorm=2.885, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=248
2021-12-14 01:49:25 | INFO | train_inner | epoch 018:     87 / 99 loss=4.399, ppl=21.1, wps=6840.5, ups=9.96, wpb=687.1, bsz=32, num_updates=1770, lr=2.80462e-05, gnorm=2.675, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=249
2021-12-14 01:49:25 | INFO | train_inner | epoch 018:     97 / 99 loss=3.915, ppl=15.08, wps=5940.6, ups=10.82, wpb=548.9, bsz=32, num_updates=1780, lr=2.80308e-05, gnorm=2.776, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=250
2021-12-14 01:49:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:49:27 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 4.71 | ppl 26.16 | wps 21273.6 | wpb 586.4 | bsz 31.3 | num_updates 1782 | best_loss 4.71
2021-12-14 01:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1782 updates
2021-12-14 01:49:27 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:49:30 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:49:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 18 @ 1782 updates, score 4.71) (writing took 4.262088341172785 seconds)
2021-12-14 01:49:31 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2021-12-14 01:49:31 | INFO | train | epoch 018 | loss 4.527 | ppl 23.05 | wps 4153 | ups 6.58 | wpb 630.8 | bsz 31.9 | num_updates 1782 | lr 2.80277e-05 | gnorm 2.991 | clip 100 | loss_scale 128 | train_wall 10 | gb_free 20.8 | wall 256
2021-12-14 01:49:31 | INFO | fairseq.trainer | begin training epoch 19
2021-12-14 01:49:31 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:49:32 | INFO | train_inner | epoch 019:      8 / 99 loss=4.541, ppl=23.28, wps=1006.1, ups=1.59, wpb=634, bsz=32, num_updates=1790, lr=2.80154e-05, gnorm=2.801, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=257
2021-12-14 01:49:33 | INFO | train_inner | epoch 019:     18 / 99 loss=4.453, ppl=21.9, wps=7596, ups=11.64, wpb=652.6, bsz=32, num_updates=1800, lr=2.8e-05, gnorm=2.812, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=257
2021-12-14 01:49:34 | INFO | train_inner | epoch 019:     28 / 99 loss=4.152, ppl=17.78, wps=5906.2, ups=10.8, wpb=546.8, bsz=32, num_updates=1810, lr=2.79846e-05, gnorm=2.901, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=258
2021-12-14 01:49:34 | INFO | train_inner | epoch 019:     38 / 99 loss=4.16, ppl=17.88, wps=6786, ups=12.08, wpb=561.8, bsz=32, num_updates=1820, lr=2.79692e-05, gnorm=3.039, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=259
2021-12-14 01:49:35 | INFO | train_inner | epoch 019:     48 / 99 loss=3.265, ppl=9.62, wps=5087.2, ups=11.04, wpb=460.8, bsz=32, num_updates=1830, lr=2.79538e-05, gnorm=3.036, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=260
2021-12-14 01:49:36 | INFO | train_inner | epoch 019:     58 / 99 loss=4.179, ppl=18.12, wps=6944.9, ups=11.57, wpb=600.2, bsz=32, num_updates=1840, lr=2.79385e-05, gnorm=3.135, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=261
2021-12-14 01:49:37 | INFO | train_inner | epoch 019:     68 / 99 loss=5.26, ppl=38.33, wps=8224.7, ups=9.52, wpb=863.9, bsz=31.5, num_updates=1850, lr=2.79231e-05, gnorm=2.669, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=262
2021-12-14 01:49:38 | INFO | train_inner | epoch 019:     78 / 99 loss=4.175, ppl=18.06, wps=6567.7, ups=10.58, wpb=620.7, bsz=32, num_updates=1860, lr=2.79077e-05, gnorm=2.964, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=263
2021-12-14 01:49:39 | INFO | train_inner | epoch 019:     88 / 99 loss=4.52, ppl=22.94, wps=6906.3, ups=9.63, wpb=717, bsz=32, num_updates=1870, lr=2.78923e-05, gnorm=3.306, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=264
2021-12-14 01:49:40 | INFO | train_inner | epoch 019:     98 / 99 loss=4.565, ppl=23.66, wps=7240.8, ups=10.27, wpb=705.2, bsz=32, num_updates=1880, lr=2.78769e-05, gnorm=2.968, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=265
2021-12-14 01:49:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:49:41 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 4.587 | ppl 24.04 | wps 21296 | wpb 586.4 | bsz 31.3 | num_updates 1881 | best_loss 4.587
2021-12-14 01:49:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1881 updates
2021-12-14 01:49:41 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:49:44 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:49:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 19 @ 1881 updates, score 4.587) (writing took 5.945592936128378 seconds)
2021-12-14 01:49:47 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2021-12-14 01:49:47 | INFO | train | epoch 019 | loss 4.381 | ppl 20.84 | wps 3876.2 | ups 6.15 | wpb 630.8 | bsz 31.9 | num_updates 1881 | lr 2.78754e-05 | gnorm 2.982 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 272
2021-12-14 01:49:47 | INFO | fairseq.trainer | begin training epoch 20
2021-12-14 01:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:49:48 | INFO | train_inner | epoch 020:      9 / 99 loss=4.867, ppl=29.19, wps=1005.5, ups=1.32, wpb=763.8, bsz=31.5, num_updates=1890, lr=2.78615e-05, gnorm=2.803, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=273
2021-12-14 01:49:48 | INFO | train_inner | epoch 020:     19 / 99 loss=4.311, ppl=19.84, wps=9920.6, ups=14.13, wpb=702.3, bsz=32, num_updates=1900, lr=2.78462e-05, gnorm=2.653, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=273
2021-12-14 01:49:49 | INFO | train_inner | epoch 020:     29 / 99 loss=4.201, ppl=18.39, wps=7372.4, ups=13.02, wpb=566.3, bsz=32, num_updates=1910, lr=2.78308e-05, gnorm=3.438, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=274
2021-12-14 01:49:50 | INFO | train_inner | epoch 020:     39 / 99 loss=4.797, ppl=27.8, wps=10120.7, ups=13.05, wpb=775.8, bsz=32, num_updates=1920, lr=2.78154e-05, gnorm=2.733, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=275
2021-12-14 01:49:51 | INFO | train_inner | epoch 020:     49 / 99 loss=2.917, ppl=7.55, wps=5279, ups=11.8, wpb=447.2, bsz=32, num_updates=1930, lr=2.78e-05, gnorm=2.864, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=276
2021-12-14 01:49:52 | INFO | train_inner | epoch 020:     59 / 99 loss=4.387, ppl=20.93, wps=8717.4, ups=12.47, wpb=699.3, bsz=32, num_updates=1940, lr=2.77846e-05, gnorm=2.917, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=276
2021-12-14 01:49:53 | INFO | train_inner | epoch 020:     69 / 99 loss=4.633, ppl=24.8, wps=8205.5, ups=11.59, wpb=707.9, bsz=32, num_updates=1950, lr=2.77692e-05, gnorm=2.737, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=277
2021-12-14 01:49:53 | INFO | train_inner | epoch 020:     79 / 99 loss=3.643, ppl=12.49, wps=6532.2, ups=12.14, wpb=538.2, bsz=32, num_updates=1960, lr=2.77538e-05, gnorm=3.218, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=278
2021-12-14 01:49:54 | INFO | train_inner | epoch 020:     89 / 99 loss=4.209, ppl=18.49, wps=6995.7, ups=11.78, wpb=594, bsz=32, num_updates=1970, lr=2.77385e-05, gnorm=2.97, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=279
2021-12-14 01:49:55 | INFO | train_inner | epoch 020:     99 / 99 loss=3.353, ppl=10.22, wps=4955.3, ups=10.22, wpb=485, bsz=32, num_updates=1980, lr=2.77231e-05, gnorm=3.049, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=280
2021-12-14 01:49:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:49:56 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.418 | ppl 21.38 | wps 23505 | wpb 586.4 | bsz 31.3 | num_updates 1980 | best_loss 4.418
2021-12-14 01:49:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 1980 updates
2021-12-14 01:49:56 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:49:59 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:50:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 20 @ 1980 updates, score 4.418) (writing took 3.790130377979949 seconds)
2021-12-14 01:50:00 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2021-12-14 01:50:00 | INFO | train | epoch 020 | loss 4.242 | ppl 18.93 | wps 4901.7 | ups 7.77 | wpb 630.8 | bsz 31.9 | num_updates 1980 | lr 2.77231e-05 | gnorm 2.929 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 285
2021-12-14 01:50:00 | INFO | fairseq.trainer | begin training epoch 21
2021-12-14 01:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:50:01 | INFO | train_inner | epoch 021:     10 / 99 loss=3.695, ppl=12.95, wps=1016.7, ups=1.77, wpb=575.5, bsz=32, num_updates=1990, lr=2.77077e-05, gnorm=2.747, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=286
2021-12-14 01:50:02 | INFO | train_inner | epoch 021:     20 / 99 loss=4.513, ppl=22.84, wps=7998.3, ups=10.6, wpb=754.8, bsz=32, num_updates=2000, lr=2.76923e-05, gnorm=2.83, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=287
2021-12-14 01:50:03 | INFO | train_inner | epoch 021:     30 / 99 loss=4.632, ppl=24.8, wps=9354.7, ups=12.49, wpb=748.8, bsz=32, num_updates=2010, lr=2.76769e-05, gnorm=3.068, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=287
2021-12-14 01:50:03 | INFO | train_inner | epoch 021:     40 / 99 loss=3.334, ppl=10.08, wps=7436.8, ups=13.96, wpb=532.7, bsz=32, num_updates=2020, lr=2.76615e-05, gnorm=2.817, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=288
2021-12-14 01:50:04 | INFO | train_inner | epoch 021:     50 / 99 loss=3.853, ppl=14.45, wps=7951.8, ups=13.63, wpb=583.2, bsz=32, num_updates=2030, lr=2.76462e-05, gnorm=3.001, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=289
2021-12-14 01:50:05 | INFO | train_inner | epoch 021:     60 / 99 loss=4.543, ppl=23.31, wps=10239.4, ups=13.37, wpb=765.9, bsz=32, num_updates=2040, lr=2.76308e-05, gnorm=3.259, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=290
2021-12-14 01:50:06 | INFO | train_inner | epoch 021:     70 / 99 loss=4.288, ppl=19.54, wps=8308.2, ups=12.17, wpb=682.4, bsz=32, num_updates=2050, lr=2.76154e-05, gnorm=2.919, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=290
2021-12-14 01:50:07 | INFO | train_inner | epoch 021:     80 / 99 loss=3.345, ppl=10.16, wps=5242.6, ups=11.17, wpb=469.2, bsz=32, num_updates=2060, lr=2.76e-05, gnorm=3.155, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=291
2021-12-14 01:50:07 | INFO | train_inner | epoch 021:     90 / 99 loss=4.205, ppl=18.45, wps=6746.7, ups=11.23, wpb=600.8, bsz=31.5, num_updates=2070, lr=2.75846e-05, gnorm=2.993, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=292
2021-12-14 01:50:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:50:09 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.339 | ppl 20.24 | wps 23838.4 | wpb 586.4 | bsz 31.3 | num_updates 2079 | best_loss 4.339
2021-12-14 01:50:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2079 updates
2021-12-14 01:50:09 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:50:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 21 @ 2079 updates, score 4.339) (writing took 3.744157914072275 seconds)
2021-12-14 01:50:13 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2021-12-14 01:50:13 | INFO | train | epoch 021 | loss 4.107 | ppl 17.24 | wps 4834.6 | ups 7.66 | wpb 630.8 | bsz 31.9 | num_updates 2079 | lr 2.75708e-05 | gnorm 3.002 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 298
2021-12-14 01:50:13 | INFO | fairseq.trainer | begin training epoch 22
2021-12-14 01:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:50:13 | INFO | train_inner | epoch 022:      1 / 99 loss=3.887, ppl=14.79, wps=1028.5, ups=1.82, wpb=566.5, bsz=32, num_updates=2080, lr=2.75692e-05, gnorm=3.282, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=298
2021-12-14 01:50:14 | INFO | train_inner | epoch 022:     11 / 99 loss=4.112, ppl=17.29, wps=8651.6, ups=12.35, wpb=700.5, bsz=32, num_updates=2090, lr=2.75538e-05, gnorm=2.903, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=299
2021-12-14 01:50:14 | INFO | train_inner | epoch 022:     21 / 99 loss=3.876, ppl=14.69, wps=7786.7, ups=13.68, wpb=569.4, bsz=32, num_updates=2100, lr=2.75385e-05, gnorm=3.241, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=299
2021-12-14 01:50:15 | INFO | train_inner | epoch 022:     31 / 99 loss=4.68, ppl=25.63, wps=9659.9, ups=14.34, wpb=673.6, bsz=31.5, num_updates=2110, lr=2.75231e-05, gnorm=2.966, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=300
2021-12-14 01:50:16 | INFO | train_inner | epoch 022:     41 / 99 loss=3.783, ppl=13.77, wps=9767.5, ups=14.78, wpb=660.9, bsz=32, num_updates=2120, lr=2.75077e-05, gnorm=2.871, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=301
2021-12-14 01:50:17 | INFO | train_inner | epoch 022:     51 / 99 loss=4.254, ppl=19.09, wps=9246.6, ups=12.32, wpb=750.7, bsz=32, num_updates=2130, lr=2.74923e-05, gnorm=2.811, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=301
2021-12-14 01:50:17 | INFO | train_inner | epoch 022:     61 / 99 loss=4.213, ppl=18.55, wps=8670.3, ups=13.11, wpb=661.3, bsz=32, num_updates=2140, lr=2.74769e-05, gnorm=3.056, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=302
2021-12-14 01:50:18 | INFO | train_inner | epoch 022:     71 / 99 loss=4.415, ppl=21.33, wps=9970, ups=14.04, wpb=710.3, bsz=32, num_updates=2150, lr=2.74615e-05, gnorm=3.208, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=303
2021-12-14 01:50:19 | INFO | train_inner | epoch 022:     81 / 99 loss=3.341, ppl=10.13, wps=7311.5, ups=14.28, wpb=512, bsz=32, num_updates=2160, lr=2.74462e-05, gnorm=3.154, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=304
2021-12-14 01:50:20 | INFO | train_inner | epoch 022:     91 / 99 loss=3.095, ppl=8.54, wps=6588.2, ups=13.12, wpb=502.1, bsz=32, num_updates=2170, lr=2.74308e-05, gnorm=3.116, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=304
2021-12-14 01:50:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:50:21 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.205 | ppl 18.44 | wps 19920.1 | wpb 586.4 | bsz 31.3 | num_updates 2178 | best_loss 4.205
2021-12-14 01:50:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2178 updates
2021-12-14 01:50:21 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:50:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 22 @ 2178 updates, score 4.205) (writing took 3.748271729098633 seconds)
2021-12-14 01:50:25 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2021-12-14 01:50:25 | INFO | train | epoch 022 | loss 3.971 | ppl 15.68 | wps 5095.2 | ups 8.08 | wpb 630.8 | bsz 31.9 | num_updates 2178 | lr 2.74185e-05 | gnorm 3.05 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 310
2021-12-14 01:50:25 | INFO | fairseq.trainer | begin training epoch 23
2021-12-14 01:50:25 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:50:25 | INFO | train_inner | epoch 023:      2 / 99 loss=3.569, ppl=11.87, wps=1070.9, ups=1.77, wpb=606.2, bsz=32, num_updates=2180, lr=2.74154e-05, gnorm=3.153, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=310
2021-12-14 01:50:26 | INFO | train_inner | epoch 023:     12 / 99 loss=3.86, ppl=14.52, wps=10203.8, ups=14.76, wpb=691.4, bsz=32, num_updates=2190, lr=2.74e-05, gnorm=2.934, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=311
2021-12-14 01:50:27 | INFO | train_inner | epoch 023:     22 / 99 loss=3.62, ppl=12.29, wps=8780.2, ups=14.38, wpb=610.7, bsz=32, num_updates=2200, lr=2.73846e-05, gnorm=2.873, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=311
2021-12-14 01:50:27 | INFO | train_inner | epoch 023:     32 / 99 loss=3.66, ppl=12.64, wps=10255.8, ups=15.04, wpb=682, bsz=32, num_updates=2210, lr=2.73692e-05, gnorm=2.801, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=312
2021-12-14 01:50:28 | INFO | train_inner | epoch 023:     42 / 99 loss=3.961, ppl=15.57, wps=9520.5, ups=15.09, wpb=631.1, bsz=32, num_updates=2220, lr=2.73538e-05, gnorm=3.116, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=313
2021-12-14 01:50:29 | INFO | train_inner | epoch 023:     52 / 99 loss=4.17, ppl=18, wps=9607.8, ups=14.84, wpb=647.4, bsz=32, num_updates=2230, lr=2.73385e-05, gnorm=3.109, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=313
2021-12-14 01:50:29 | INFO | train_inner | epoch 023:     62 / 99 loss=4.235, ppl=18.84, wps=7746, ups=12.44, wpb=622.9, bsz=31.5, num_updates=2240, lr=2.73231e-05, gnorm=3.081, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=314
2021-12-14 01:50:30 | INFO | train_inner | epoch 023:     72 / 99 loss=3.659, ppl=12.63, wps=7606.2, ups=12.47, wpb=609.9, bsz=32, num_updates=2250, lr=2.73077e-05, gnorm=2.798, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=315
2021-12-14 01:50:31 | INFO | train_inner | epoch 023:     82 / 99 loss=3.026, ppl=8.15, wps=6303.4, ups=12.49, wpb=504.6, bsz=32, num_updates=2260, lr=2.72923e-05, gnorm=3.103, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=316
2021-12-14 01:50:32 | INFO | train_inner | epoch 023:     92 / 99 loss=4.364, ppl=20.59, wps=7388.6, ups=10.95, wpb=675, bsz=32, num_updates=2270, lr=2.72769e-05, gnorm=3.333, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=317
2021-12-14 01:50:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:50:34 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 4.159 | ppl 17.86 | wps 20187.9 | wpb 586.4 | bsz 31.3 | num_updates 2277 | best_loss 4.159
2021-12-14 01:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2277 updates
2021-12-14 01:50:34 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:50:36 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:50:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 23 @ 2277 updates, score 4.159) (writing took 3.904056137194857 seconds)
2021-12-14 01:50:37 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2021-12-14 01:50:38 | INFO | train | epoch 023 | loss 3.851 | ppl 14.43 | wps 5003.3 | ups 7.93 | wpb 630.8 | bsz 31.9 | num_updates 2277 | lr 2.72662e-05 | gnorm 3.046 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 322
2021-12-14 01:50:38 | INFO | fairseq.trainer | begin training epoch 24
2021-12-14 01:50:38 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:50:38 | INFO | train_inner | epoch 024:      3 / 99 loss=3.864, ppl=14.56, wps=1086.5, ups=1.71, wpb=636.4, bsz=32, num_updates=2280, lr=2.72615e-05, gnorm=3.793, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=323
2021-12-14 01:50:39 | INFO | train_inner | epoch 024:     13 / 99 loss=3.644, ppl=12.51, wps=7476.9, ups=12.05, wpb=620.6, bsz=32, num_updates=2290, lr=2.72462e-05, gnorm=3.083, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=324
2021-12-14 01:50:39 | INFO | train_inner | epoch 024:     23 / 99 loss=3.609, ppl=12.2, wps=8388.2, ups=13.43, wpb=624.6, bsz=32, num_updates=2300, lr=2.72308e-05, gnorm=3.155, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=324
2021-12-14 01:50:40 | INFO | train_inner | epoch 024:     33 / 99 loss=4.246, ppl=18.98, wps=8752.4, ups=12.92, wpb=677.3, bsz=31.5, num_updates=2310, lr=2.72154e-05, gnorm=3.123, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=325
2021-12-14 01:50:41 | INFO | train_inner | epoch 024:     43 / 99 loss=3.527, ppl=11.53, wps=7451.6, ups=11.99, wpb=621.6, bsz=32, num_updates=2320, lr=2.72e-05, gnorm=2.961, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=326
2021-12-14 01:50:42 | INFO | train_inner | epoch 024:     53 / 99 loss=2.954, ppl=7.75, wps=6426.9, ups=12.48, wpb=515, bsz=32, num_updates=2330, lr=2.71846e-05, gnorm=2.958, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=327
2021-12-14 01:50:43 | INFO | train_inner | epoch 024:     63 / 99 loss=3.604, ppl=12.16, wps=8243.7, ups=12.77, wpb=645.8, bsz=32, num_updates=2340, lr=2.71692e-05, gnorm=2.813, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=327
2021-12-14 01:50:43 | INFO | train_inner | epoch 024:     73 / 99 loss=3.802, ppl=13.95, wps=8042.7, ups=12.41, wpb=648.2, bsz=32, num_updates=2350, lr=2.71538e-05, gnorm=3.086, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=328
2021-12-14 01:50:44 | INFO | train_inner | epoch 024:     83 / 99 loss=3.529, ppl=11.55, wps=6648.9, ups=12, wpb=554.1, bsz=32, num_updates=2360, lr=2.71385e-05, gnorm=3.351, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=329
2021-12-14 01:50:45 | INFO | train_inner | epoch 024:     93 / 99 loss=4.228, ppl=18.74, wps=7156.8, ups=10.32, wpb=693.2, bsz=32, num_updates=2370, lr=2.71231e-05, gnorm=2.997, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=330
2021-12-14 01:50:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:50:47 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.978 | ppl 15.76 | wps 21667.5 | wpb 586.4 | bsz 31.3 | num_updates 2376 | best_loss 3.978
2021-12-14 01:50:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2376 updates
2021-12-14 01:50:47 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:50:49 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:50:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 24 @ 2376 updates, score 3.978) (writing took 3.772333832923323 seconds)
2021-12-14 01:50:51 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2021-12-14 01:50:51 | INFO | train | epoch 024 | loss 3.743 | ppl 13.39 | wps 4796.7 | ups 7.6 | wpb 630.8 | bsz 31.9 | num_updates 2376 | lr 2.71138e-05 | gnorm 3.096 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 335
2021-12-14 01:50:51 | INFO | fairseq.trainer | begin training epoch 25
2021-12-14 01:50:51 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:50:51 | INFO | train_inner | epoch 025:      4 / 99 loss=3.798, ppl=13.91, wps=1223.5, ups=1.75, wpb=699.3, bsz=32, num_updates=2380, lr=2.71077e-05, gnorm=2.88, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=336
2021-12-14 01:50:52 | INFO | train_inner | epoch 025:     14 / 99 loss=3.766, ppl=13.61, wps=7287.6, ups=11.53, wpb=632.1, bsz=32, num_updates=2390, lr=2.70923e-05, gnorm=2.943, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=337
2021-12-14 01:50:53 | INFO | train_inner | epoch 025:     24 / 99 loss=4.113, ppl=17.31, wps=7967.5, ups=12.47, wpb=638.9, bsz=31.5, num_updates=2400, lr=2.70769e-05, gnorm=3.149, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=337
2021-12-14 01:50:54 | INFO | train_inner | epoch 025:     34 / 99 loss=2.491, ppl=5.62, wps=5051.8, ups=11.85, wpb=426.4, bsz=32, num_updates=2410, lr=2.70615e-05, gnorm=3.36, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=338
2021-12-14 01:50:54 | INFO | train_inner | epoch 025:     44 / 99 loss=3.18, ppl=9.06, wps=7819.7, ups=13.41, wpb=583.2, bsz=32, num_updates=2420, lr=2.70462e-05, gnorm=2.918, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=339
2021-12-14 01:50:55 | INFO | train_inner | epoch 025:     54 / 99 loss=3.18, ppl=9.06, wps=7935.3, ups=13.39, wpb=592.8, bsz=32, num_updates=2430, lr=2.70308e-05, gnorm=3.167, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=340
2021-12-14 01:50:56 | INFO | train_inner | epoch 025:     64 / 99 loss=3.734, ppl=13.31, wps=9324, ups=13.27, wpb=702.6, bsz=32, num_updates=2440, lr=2.70154e-05, gnorm=2.837, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=341
2021-12-14 01:50:57 | INFO | train_inner | epoch 025:     74 / 99 loss=3.949, ppl=15.44, wps=9384.7, ups=13.26, wpb=707.8, bsz=32, num_updates=2450, lr=2.7e-05, gnorm=3.108, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=341
2021-12-14 01:50:57 | INFO | train_inner | epoch 025:     84 / 99 loss=3.28, ppl=9.71, wps=7983.5, ups=13.36, wpb=597.6, bsz=32, num_updates=2460, lr=2.69846e-05, gnorm=3.093, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=342
2021-12-14 01:50:58 | INFO | train_inner | epoch 025:     94 / 99 loss=4.374, ppl=20.73, wps=9251.3, ups=11.66, wpb=793.3, bsz=32, num_updates=2470, lr=2.69692e-05, gnorm=3.211, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=343
2021-12-14 01:50:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:51:00 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.897 | ppl 14.89 | wps 19705 | wpb 586.4 | bsz 31.3 | num_updates 2475 | best_loss 3.897
2021-12-14 01:51:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2475 updates
2021-12-14 01:51:00 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:51:02 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:51:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 25 @ 2475 updates, score 3.897) (writing took 3.741789238061756 seconds)
2021-12-14 01:51:03 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2021-12-14 01:51:03 | INFO | train | epoch 025 | loss 3.626 | ppl 12.35 | wps 4906.2 | ups 7.78 | wpb 630.8 | bsz 31.9 | num_updates 2475 | lr 2.69615e-05 | gnorm 3.072 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 348
2021-12-14 01:51:03 | INFO | fairseq.trainer | begin training epoch 26
2021-12-14 01:51:03 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:51:04 | INFO | train_inner | epoch 026:      5 / 99 loss=3.753, ppl=13.48, wps=1223.3, ups=1.75, wpb=699.8, bsz=32, num_updates=2480, lr=2.69538e-05, gnorm=3.028, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=349
2021-12-14 01:51:05 | INFO | train_inner | epoch 026:     15 / 99 loss=4.512, ppl=22.82, wps=9293.6, ups=11.71, wpb=793.6, bsz=31.5, num_updates=2490, lr=2.69385e-05, gnorm=3.414, clip=100, loss_scale=128, train_wall=1, gb_free=20, wall=350
2021-12-14 01:51:06 | INFO | train_inner | epoch 026:     25 / 99 loss=3.863, ppl=14.55, wps=8881, ups=12.22, wpb=726.9, bsz=32, num_updates=2500, lr=2.69231e-05, gnorm=2.82, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=350
2021-12-14 01:51:06 | INFO | train_inner | epoch 026:     35 / 99 loss=3.644, ppl=12.5, wps=8030.1, ups=13.03, wpb=616.5, bsz=32, num_updates=2510, lr=2.69077e-05, gnorm=3.081, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=351
2021-12-14 01:51:07 | INFO | train_inner | epoch 026:     45 / 99 loss=2.565, ppl=5.92, wps=6227.9, ups=13.13, wpb=474.3, bsz=32, num_updates=2520, lr=2.68923e-05, gnorm=3.036, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=352
2021-12-14 01:51:08 | INFO | train_inner | epoch 026:     55 / 99 loss=2.924, ppl=7.59, wps=7261.1, ups=13.66, wpb=531.5, bsz=32, num_updates=2530, lr=2.68769e-05, gnorm=3.36, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=353
2021-12-14 01:51:09 | INFO | train_inner | epoch 026:     65 / 99 loss=3.788, ppl=13.81, wps=8804.5, ups=12.99, wpb=677.8, bsz=32, num_updates=2540, lr=2.68615e-05, gnorm=3.304, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=353
2021-12-14 01:51:09 | INFO | train_inner | epoch 026:     75 / 99 loss=3.518, ppl=11.46, wps=9676.4, ups=13.32, wpb=726.2, bsz=32, num_updates=2550, lr=2.68462e-05, gnorm=2.943, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=354
2021-12-14 01:51:10 | INFO | train_inner | epoch 026:     85 / 99 loss=2.84, ppl=7.16, wps=6708.9, ups=13.94, wpb=481.4, bsz=32, num_updates=2560, lr=2.68308e-05, gnorm=3.166, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=355
2021-12-14 01:51:11 | INFO | train_inner | epoch 026:     95 / 99 loss=3.109, ppl=8.63, wps=6866, ups=11.83, wpb=580.6, bsz=32, num_updates=2570, lr=2.68154e-05, gnorm=3.446, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=356
2021-12-14 01:51:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:51:12 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.789 | ppl 13.83 | wps 23864.7 | wpb 586.4 | bsz 31.3 | num_updates 2574 | best_loss 3.789
2021-12-14 01:51:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2574 updates
2021-12-14 01:51:12 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:51:15 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 26 @ 2574 updates, score 3.789) (writing took 3.9135968999471515 seconds)
2021-12-14 01:51:16 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2021-12-14 01:51:16 | INFO | train | epoch 026 | loss 3.533 | ppl 11.57 | wps 4934.5 | ups 7.82 | wpb 630.8 | bsz 31.9 | num_updates 2574 | lr 2.68092e-05 | gnorm 3.177 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 361
2021-12-14 01:51:16 | INFO | fairseq.trainer | begin training epoch 27
2021-12-14 01:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:51:16 | INFO | train_inner | epoch 027:      6 / 99 loss=2.987, ppl=7.93, wps=1019.2, ups=1.8, wpb=567.4, bsz=32, num_updates=2580, lr=2.68e-05, gnorm=3.173, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=361
2021-12-14 01:51:17 | INFO | train_inner | epoch 027:     16 / 99 loss=4.29, ppl=19.57, wps=11398, ups=13.43, wpb=848.9, bsz=32, num_updates=2590, lr=2.67846e-05, gnorm=2.863, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=362
2021-12-14 01:51:18 | INFO | train_inner | epoch 027:     26 / 99 loss=3.38, ppl=10.41, wps=8861.2, ups=13.71, wpb=646.3, bsz=32, num_updates=2600, lr=2.67692e-05, gnorm=3.139, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=363
2021-12-14 01:51:19 | INFO | train_inner | epoch 027:     36 / 99 loss=3.064, ppl=8.36, wps=7781.4, ups=13.93, wpb=558.8, bsz=32, num_updates=2610, lr=2.67538e-05, gnorm=3.123, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=363
2021-12-14 01:51:20 | INFO | train_inner | epoch 027:     46 / 99 loss=3.412, ppl=10.64, wps=6951.2, ups=12.32, wpb=564.4, bsz=32, num_updates=2620, lr=2.67385e-05, gnorm=3.011, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=364
2021-12-14 01:51:20 | INFO | train_inner | epoch 027:     56 / 99 loss=4.016, ppl=16.18, wps=9303.2, ups=12.75, wpb=729.7, bsz=31.5, num_updates=2630, lr=2.67231e-05, gnorm=2.995, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=365
2021-12-14 01:51:21 | INFO | train_inner | epoch 027:     66 / 99 loss=2.486, ppl=5.6, wps=7113.4, ups=13.34, wpb=533.1, bsz=32, num_updates=2640, lr=2.67077e-05, gnorm=2.788, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=366
2021-12-14 01:51:22 | INFO | train_inner | epoch 027:     76 / 99 loss=3.207, ppl=9.24, wps=8275.2, ups=13.35, wpb=619.9, bsz=32, num_updates=2650, lr=2.66923e-05, gnorm=3.139, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=367
2021-12-14 01:51:23 | INFO | train_inner | epoch 027:     86 / 99 loss=3.793, ppl=13.86, wps=8865.6, ups=13.01, wpb=681.4, bsz=32, num_updates=2660, lr=2.66769e-05, gnorm=3.264, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=367
2021-12-14 01:51:24 | INFO | train_inner | epoch 027:     96 / 99 loss=2.776, ppl=6.85, wps=5259.5, ups=10.05, wpb=523.2, bsz=32, num_updates=2670, lr=2.66615e-05, gnorm=3.253, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=368
2021-12-14 01:51:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:51:25 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.733 | ppl 13.3 | wps 23091 | wpb 586.4 | bsz 31.3 | num_updates 2673 | best_loss 3.733
2021-12-14 01:51:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2673 updates
2021-12-14 01:51:25 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:51:27 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:51:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 27 @ 2673 updates, score 3.733) (writing took 3.600360007956624 seconds)
2021-12-14 01:51:28 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2021-12-14 01:51:28 | INFO | train | epoch 027 | loss 3.434 | ppl 10.81 | wps 5082.6 | ups 8.06 | wpb 630.8 | bsz 31.9 | num_updates 2673 | lr 2.66569e-05 | gnorm 3.064 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 373
2021-12-14 01:51:28 | INFO | fairseq.trainer | begin training epoch 28
2021-12-14 01:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:51:29 | INFO | train_inner | epoch 028:      7 / 99 loss=2.969, ppl=7.83, wps=1178.3, ups=1.88, wpb=625.2, bsz=32, num_updates=2680, lr=2.66462e-05, gnorm=2.986, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=374
2021-12-14 01:51:30 | INFO | train_inner | epoch 028:     17 / 99 loss=3.038, ppl=8.21, wps=8275.8, ups=13.52, wpb=612, bsz=32, num_updates=2690, lr=2.66308e-05, gnorm=2.992, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=374
2021-12-14 01:51:30 | INFO | train_inner | epoch 028:     27 / 99 loss=3.929, ppl=15.24, wps=9383.2, ups=13.98, wpb=671.1, bsz=32, num_updates=2700, lr=2.66154e-05, gnorm=3.068, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=375
2021-12-14 01:51:31 | INFO | train_inner | epoch 028:     37 / 99 loss=3.26, ppl=9.58, wps=9779.7, ups=14.69, wpb=665.8, bsz=32, num_updates=2710, lr=2.66e-05, gnorm=3.158, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=376
2021-12-14 01:51:32 | INFO | train_inner | epoch 028:     47 / 99 loss=3.375, ppl=10.38, wps=8677.6, ups=15.01, wpb=578.3, bsz=32, num_updates=2720, lr=2.65846e-05, gnorm=2.874, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=376
2021-12-14 01:51:32 | INFO | train_inner | epoch 028:     57 / 99 loss=2.945, ppl=7.7, wps=8949.3, ups=14.7, wpb=608.8, bsz=32, num_updates=2730, lr=2.65692e-05, gnorm=3.316, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=377
2021-12-14 01:51:33 | INFO | train_inner | epoch 028:     67 / 99 loss=3.974, ppl=15.72, wps=9337.3, ups=13.42, wpb=695.7, bsz=31.5, num_updates=2740, lr=2.65538e-05, gnorm=3.16, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=378
2021-12-14 01:51:34 | INFO | train_inner | epoch 028:     77 / 99 loss=2.641, ppl=6.24, wps=6882.4, ups=14.27, wpb=482.3, bsz=32, num_updates=2750, lr=2.65385e-05, gnorm=3.036, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=379
2021-12-14 01:51:34 | INFO | train_inner | epoch 028:     87 / 99 loss=3.653, ppl=12.58, wps=10124.9, ups=15.06, wpb=672.4, bsz=32, num_updates=2760, lr=2.65231e-05, gnorm=2.98, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=379
2021-12-14 01:51:35 | INFO | train_inner | epoch 028:     97 / 99 loss=3.298, ppl=9.84, wps=8297.8, ups=12.45, wpb=666.5, bsz=32, num_updates=2770, lr=2.65077e-05, gnorm=3.017, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=380
2021-12-14 01:51:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:51:36 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.66 | ppl 12.64 | wps 19445.8 | wpb 586.4 | bsz 31.3 | num_updates 2772 | best_loss 3.66
2021-12-14 01:51:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2772 updates
2021-12-14 01:51:36 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:51:39 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:51:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 28 @ 2772 updates, score 3.66) (writing took 3.8178415920119733 seconds)
2021-12-14 01:51:40 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2021-12-14 01:51:40 | INFO | train | epoch 028 | loss 3.35 | ppl 10.19 | wps 5218.9 | ups 8.27 | wpb 630.8 | bsz 31.9 | num_updates 2772 | lr 2.65046e-05 | gnorm 3.057 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.7 | wall 385
2021-12-14 01:51:40 | INFO | fairseq.trainer | begin training epoch 29
2021-12-14 01:51:40 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:51:41 | INFO | train_inner | epoch 029:      8 / 99 loss=3.716, ppl=13.14, wps=1366.5, ups=1.79, wpb=762.3, bsz=32, num_updates=2780, lr=2.64923e-05, gnorm=2.937, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=386
2021-12-14 01:51:42 | INFO | train_inner | epoch 029:     18 / 99 loss=3.093, ppl=8.53, wps=9374.2, ups=14.95, wpb=627, bsz=32, num_updates=2790, lr=2.64769e-05, gnorm=2.883, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=386
2021-12-14 01:51:42 | INFO | train_inner | epoch 029:     28 / 99 loss=3.732, ppl=13.28, wps=11822.7, ups=14.92, wpb=792.5, bsz=32, num_updates=2800, lr=2.64615e-05, gnorm=2.884, clip=100, loss_scale=128, train_wall=1, gb_free=20, wall=387
2021-12-14 01:51:43 | INFO | train_inner | epoch 029:     38 / 99 loss=2.942, ppl=7.68, wps=7947.4, ups=13.49, wpb=589.3, bsz=32, num_updates=2810, lr=2.64462e-05, gnorm=2.927, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=388
2021-12-14 01:51:44 | INFO | train_inner | epoch 029:     48 / 99 loss=2.859, ppl=7.25, wps=7488.7, ups=13.38, wpb=559.6, bsz=32, num_updates=2820, lr=2.64308e-05, gnorm=3.163, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=389
2021-12-14 01:51:44 | INFO | train_inner | epoch 029:     58 / 99 loss=2.653, ppl=6.29, wps=7515, ups=13.51, wpb=556.3, bsz=32, num_updates=2830, lr=2.64154e-05, gnorm=3.172, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=389
2021-12-14 01:51:45 | INFO | train_inner | epoch 029:     68 / 99 loss=3.807, ppl=14, wps=9186.7, ups=12.96, wpb=708.9, bsz=31.5, num_updates=2840, lr=2.64e-05, gnorm=2.968, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=390
2021-12-14 01:51:46 | INFO | train_inner | epoch 029:     78 / 99 loss=3.229, ppl=9.38, wps=8674, ups=13.31, wpb=651.9, bsz=32, num_updates=2850, lr=2.63846e-05, gnorm=2.913, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=391
2021-12-14 01:51:47 | INFO | train_inner | epoch 029:     88 / 99 loss=3.05, ppl=8.28, wps=6520.8, ups=12.37, wpb=527.2, bsz=32, num_updates=2860, lr=2.63692e-05, gnorm=3.331, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=392
2021-12-14 01:51:48 | INFO | train_inner | epoch 029:     98 / 99 loss=3.146, ppl=8.85, wps=6807.3, ups=11.35, wpb=599.6, bsz=32, num_updates=2870, lr=2.63538e-05, gnorm=3.118, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=392
2021-12-14 01:51:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:51:49 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.575 | ppl 11.91 | wps 23590.4 | wpb 586.4 | bsz 31.3 | num_updates 2871 | best_loss 3.575
2021-12-14 01:51:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2871 updates
2021-12-14 01:51:49 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:51:51 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:51:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 29 @ 2871 updates, score 3.575) (writing took 4.068031691014767 seconds)
2021-12-14 01:51:53 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2021-12-14 01:51:53 | INFO | train | epoch 029 | loss 3.24 | ppl 9.45 | wps 5026.7 | ups 7.97 | wpb 630.8 | bsz 31.9 | num_updates 2871 | lr 2.63523e-05 | gnorm 3.034 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 397
2021-12-14 01:51:53 | INFO | fairseq.trainer | begin training epoch 30
2021-12-14 01:51:53 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:51:53 | INFO | train_inner | epoch 030:      9 / 99 loss=3.192, ppl=9.14, wps=1155.3, ups=1.74, wpb=665.1, bsz=32, num_updates=2880, lr=2.63385e-05, gnorm=2.995, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=398
2021-12-14 01:51:54 | INFO | train_inner | epoch 030:     19 / 99 loss=3.187, ppl=9.11, wps=7831.1, ups=13.71, wpb=571.3, bsz=32, num_updates=2890, lr=2.63231e-05, gnorm=3.101, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=399
2021-12-14 01:51:55 | INFO | train_inner | epoch 030:     29 / 99 loss=2.982, ppl=7.9, wps=7750.5, ups=13.26, wpb=584.3, bsz=32, num_updates=2900, lr=2.63077e-05, gnorm=3.005, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=400
2021-12-14 01:51:56 | INFO | train_inner | epoch 030:     39 / 99 loss=2.543, ppl=5.83, wps=7330, ups=13.32, wpb=550.5, bsz=32, num_updates=2910, lr=2.62923e-05, gnorm=2.951, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=400
2021-12-14 01:51:56 | INFO | train_inner | epoch 030:     49 / 99 loss=3.534, ppl=11.58, wps=10530.3, ups=13.5, wpb=780, bsz=32, num_updates=2920, lr=2.62769e-05, gnorm=2.961, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=401
2021-12-14 01:51:57 | INFO | train_inner | epoch 030:     59 / 99 loss=3.072, ppl=8.41, wps=8077.6, ups=12.92, wpb=625.2, bsz=32, num_updates=2930, lr=2.62615e-05, gnorm=3.068, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=402
2021-12-14 01:51:58 | INFO | train_inner | epoch 030:     69 / 99 loss=3.963, ppl=15.59, wps=8782.2, ups=12.74, wpb=689.5, bsz=31.5, num_updates=2940, lr=2.62462e-05, gnorm=3.174, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=403
2021-12-14 01:51:59 | INFO | train_inner | epoch 030:     79 / 99 loss=2.424, ppl=5.37, wps=6784.8, ups=13.09, wpb=518.3, bsz=32, num_updates=2950, lr=2.62308e-05, gnorm=3.176, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=404
2021-12-14 01:52:00 | INFO | train_inner | epoch 030:     89 / 99 loss=3.008, ppl=8.04, wps=8050, ups=12.5, wpb=643.8, bsz=32, num_updates=2960, lr=2.62154e-05, gnorm=2.961, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=404
2021-12-14 01:52:00 | INFO | train_inner | epoch 030:     99 / 99 loss=3.334, ppl=10.08, wps=7332.3, ups=10.93, wpb=671, bsz=32, num_updates=2970, lr=2.62e-05, gnorm=3.256, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=405
2021-12-14 01:52:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:52:01 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 3.551 | ppl 11.72 | wps 24462.8 | wpb 586.4 | bsz 31.3 | num_updates 2970 | best_loss 3.551
2021-12-14 01:52:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 2970 updates
2021-12-14 01:52:01 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:52:04 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:52:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 30 @ 2970 updates, score 3.551) (writing took 3.7079593669623137 seconds)
2021-12-14 01:52:05 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2021-12-14 01:52:05 | INFO | train | epoch 030 | loss 3.172 | ppl 9.01 | wps 5067.3 | ups 8.03 | wpb 630.8 | bsz 31.9 | num_updates 2970 | lr 2.62e-05 | gnorm 3.064 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.5 | wall 410
2021-12-14 01:52:05 | INFO | fairseq.trainer | begin training epoch 31
2021-12-14 01:52:05 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:52:06 | INFO | train_inner | epoch 031:     10 / 99 loss=2.89, ppl=7.41, wps=1176.2, ups=1.86, wpb=633.3, bsz=32, num_updates=2980, lr=2.61846e-05, gnorm=3.17, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=411
2021-12-14 01:52:07 | INFO | train_inner | epoch 031:     20 / 99 loss=2.794, ppl=6.93, wps=5445.6, ups=9.63, wpb=565.5, bsz=32, num_updates=2990, lr=2.61692e-05, gnorm=3.123, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=412
2021-12-14 01:52:08 | INFO | train_inner | epoch 031:     30 / 99 loss=2.726, ppl=6.62, wps=5222.5, ups=9.17, wpb=569.4, bsz=32, num_updates=3000, lr=2.61538e-05, gnorm=3.183, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=413
2021-12-14 01:52:09 | INFO | train_inner | epoch 031:     40 / 99 loss=3.175, ppl=9.03, wps=6024.9, ups=10.39, wpb=579.8, bsz=32, num_updates=3010, lr=2.61385e-05, gnorm=3.095, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=414
2021-12-14 01:52:10 | INFO | train_inner | epoch 031:     50 / 99 loss=3.168, ppl=8.99, wps=7656.5, ups=11.71, wpb=653.7, bsz=32, num_updates=3020, lr=2.61231e-05, gnorm=2.924, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=415
2021-12-14 01:52:11 | INFO | train_inner | epoch 031:     60 / 99 loss=2.939, ppl=7.67, wps=8368, ups=12.68, wpb=659.9, bsz=32, num_updates=3030, lr=2.61077e-05, gnorm=2.786, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=415
2021-12-14 01:52:11 | INFO | train_inner | epoch 031:     70 / 99 loss=4.067, ppl=16.76, wps=10550.3, ups=11.7, wpb=901.7, bsz=31.5, num_updates=3040, lr=2.60923e-05, gnorm=2.891, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=416
2021-12-14 01:52:12 | INFO | train_inner | epoch 031:     80 / 99 loss=2.518, ppl=5.73, wps=6555.6, ups=12.9, wpb=508.1, bsz=32, num_updates=3050, lr=2.60769e-05, gnorm=3.167, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=417
2021-12-14 01:52:13 | INFO | train_inner | epoch 031:     90 / 99 loss=3.512, ppl=11.41, wps=8845.4, ups=11.59, wpb=762.9, bsz=32, num_updates=3060, lr=2.60615e-05, gnorm=2.906, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=418
2021-12-14 01:52:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:52:15 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.542 | ppl 11.65 | wps 23235.4 | wpb 586.4 | bsz 31.3 | num_updates 3069 | best_loss 3.542
2021-12-14 01:52:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 3069 updates
2021-12-14 01:52:15 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:52:17 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:52:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 31 @ 3069 updates, score 3.542) (writing took 3.617561422055587 seconds)
2021-12-14 01:52:18 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2021-12-14 01:52:18 | INFO | train | epoch 031 | loss 3.086 | ppl 8.49 | wps 4687.2 | ups 7.43 | wpb 630.8 | bsz 31.9 | num_updates 3069 | lr 2.60477e-05 | gnorm 3.026 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 423
2021-12-14 01:52:18 | INFO | fairseq.trainer | begin training epoch 32
2021-12-14 01:52:18 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:52:19 | INFO | train_inner | epoch 032:      1 / 99 loss=2.242, ppl=4.73, wps=924.1, ups=1.83, wpb=504.5, bsz=32, num_updates=3070, lr=2.60462e-05, gnorm=3.09, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=423
2021-12-14 01:52:19 | INFO | train_inner | epoch 032:     11 / 99 loss=2.225, ppl=4.68, wps=5655.3, ups=11.89, wpb=475.6, bsz=32, num_updates=3080, lr=2.60308e-05, gnorm=3.004, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=424
2021-12-14 01:52:20 | INFO | train_inner | epoch 032:     21 / 99 loss=2.85, ppl=7.21, wps=6724.7, ups=10.74, wpb=626.2, bsz=32, num_updates=3090, lr=2.60154e-05, gnorm=3.065, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=425
2021-12-14 01:52:21 | INFO | train_inner | epoch 032:     31 / 99 loss=3.511, ppl=11.4, wps=7435.2, ups=10.89, wpb=683, bsz=31.5, num_updates=3100, lr=2.6e-05, gnorm=3.507, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=426
2021-12-14 01:52:22 | INFO | train_inner | epoch 032:     41 / 99 loss=2.571, ppl=5.94, wps=6707.2, ups=11.26, wpb=595.9, bsz=32, num_updates=3110, lr=2.59846e-05, gnorm=3.307, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=427
2021-12-14 01:52:23 | INFO | train_inner | epoch 032:     51 / 99 loss=3.177, ppl=9.05, wps=7679.9, ups=13.2, wpb=581.6, bsz=32, num_updates=3120, lr=2.59692e-05, gnorm=3.172, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=428
2021-12-14 01:52:24 | INFO | train_inner | epoch 032:     61 / 99 loss=2.477, ppl=5.57, wps=8073.6, ups=13.45, wpb=600.4, bsz=32, num_updates=3130, lr=2.59538e-05, gnorm=3.022, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=428
2021-12-14 01:52:24 | INFO | train_inner | epoch 032:     71 / 99 loss=3.6, ppl=12.13, wps=9683.8, ups=12.58, wpb=769.5, bsz=32, num_updates=3140, lr=2.59385e-05, gnorm=3.184, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=429
2021-12-14 01:52:25 | INFO | train_inner | epoch 032:     81 / 99 loss=2.595, ppl=6.04, wps=6858.2, ups=11.65, wpb=588.8, bsz=32, num_updates=3150, lr=2.59231e-05, gnorm=3.287, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=430
2021-12-14 01:52:26 | INFO | train_inner | epoch 032:     91 / 99 loss=3.174, ppl=9.02, wps=8119.5, ups=11.82, wpb=687.1, bsz=32, num_updates=3160, lr=2.59077e-05, gnorm=3.005, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=431
2021-12-14 01:52:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:52:28 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.368 | ppl 10.33 | wps 21742.1 | wpb 586.4 | bsz 31.3 | num_updates 3168 | best_loss 3.368
2021-12-14 01:52:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3168 updates
2021-12-14 01:52:28 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:52:30 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:52:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 32 @ 3168 updates, score 3.368) (writing took 3.7075136620551348 seconds)
2021-12-14 01:52:31 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2021-12-14 01:52:31 | INFO | train | epoch 032 | loss 3.003 | ppl 8.02 | wps 4766.1 | ups 7.56 | wpb 630.8 | bsz 31.9 | num_updates 3168 | lr 2.58954e-05 | gnorm 3.167 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 436
2021-12-14 01:52:32 | INFO | fairseq.trainer | begin training epoch 33
2021-12-14 01:52:32 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:52:32 | INFO | train_inner | epoch 033:      2 / 99 loss=3.209, ppl=9.25, wps=1114.9, ups=1.81, wpb=615.9, bsz=32, num_updates=3170, lr=2.58923e-05, gnorm=3.012, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=437
2021-12-14 01:52:33 | INFO | train_inner | epoch 033:     12 / 99 loss=2.375, ppl=5.19, wps=6300.1, ups=11.73, wpb=537.1, bsz=32, num_updates=3180, lr=2.58769e-05, gnorm=3.429, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=437
2021-12-14 01:52:33 | INFO | train_inner | epoch 033:     22 / 99 loss=3.6, ppl=12.12, wps=9807, ups=13.03, wpb=752.9, bsz=31.5, num_updates=3190, lr=2.58615e-05, gnorm=2.952, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=438
2021-12-14 01:52:34 | INFO | train_inner | epoch 033:     32 / 99 loss=2.988, ppl=7.94, wps=8550, ups=13.36, wpb=640, bsz=32, num_updates=3200, lr=2.58462e-05, gnorm=2.848, clip=100, loss_scale=128, train_wall=1, gb_free=20, wall=439
2021-12-14 01:52:35 | INFO | train_inner | epoch 033:     42 / 99 loss=3.067, ppl=8.38, wps=7440.8, ups=11.67, wpb=637.6, bsz=32, num_updates=3210, lr=2.58308e-05, gnorm=3.076, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=440
2021-12-14 01:52:36 | INFO | train_inner | epoch 033:     52 / 99 loss=2.801, ppl=6.97, wps=6794.8, ups=11.35, wpb=598.8, bsz=32, num_updates=3220, lr=2.58154e-05, gnorm=2.923, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=441
2021-12-14 01:52:37 | INFO | train_inner | epoch 033:     62 / 99 loss=2.57, ppl=5.94, wps=6712.1, ups=12.54, wpb=535.3, bsz=32, num_updates=3230, lr=2.58e-05, gnorm=3.401, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=441
2021-12-14 01:52:37 | INFO | train_inner | epoch 033:     72 / 99 loss=2.949, ppl=7.72, wps=8450.5, ups=12.02, wpb=703, bsz=32, num_updates=3240, lr=2.57846e-05, gnorm=3.183, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=442
2021-12-14 01:52:38 | INFO | train_inner | epoch 033:     82 / 99 loss=2.98, ppl=7.89, wps=7624.6, ups=11.86, wpb=642.8, bsz=32, num_updates=3250, lr=2.57692e-05, gnorm=3.077, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=443
2021-12-14 01:52:39 | INFO | train_inner | epoch 033:     92 / 99 loss=3.205, ppl=9.22, wps=7945.8, ups=10.75, wpb=739.1, bsz=32, num_updates=3260, lr=2.57538e-05, gnorm=3.011, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=444
2021-12-14 01:52:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:52:41 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.359 | ppl 10.26 | wps 22660.8 | wpb 586.4 | bsz 31.3 | num_updates 3267 | best_loss 3.359
2021-12-14 01:52:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3267 updates
2021-12-14 01:52:41 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:52:44 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:52:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 33 @ 3267 updates, score 3.359) (writing took 4.156356377992779 seconds)
2021-12-14 01:52:45 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2021-12-14 01:52:46 | INFO | train | epoch 033 | loss 2.931 | ppl 7.63 | wps 4630.3 | ups 7.34 | wpb 630.8 | bsz 31.9 | num_updates 3267 | lr 2.57431e-05 | gnorm 3.091 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 450
2021-12-14 01:52:46 | INFO | fairseq.trainer | begin training epoch 34
2021-12-14 01:52:46 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:52:46 | INFO | train_inner | epoch 034:      3 / 99 loss=2.283, ppl=4.87, wps=760.5, ups=1.44, wpb=526.8, bsz=32, num_updates=3270, lr=2.57385e-05, gnorm=2.97, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=451
2021-12-14 01:52:47 | INFO | train_inner | epoch 034:     13 / 99 loss=2.728, ppl=6.63, wps=8083.6, ups=13.1, wpb=616.9, bsz=32, num_updates=3280, lr=2.57231e-05, gnorm=2.936, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=452
2021-12-14 01:52:48 | INFO | train_inner | epoch 034:     23 / 99 loss=3.45, ppl=10.93, wps=9637.7, ups=12.85, wpb=750.1, bsz=31.5, num_updates=3290, lr=2.57077e-05, gnorm=2.931, clip=100, loss_scale=128, train_wall=1, gb_free=20.3, wall=453
2021-12-14 01:52:49 | INFO | train_inner | epoch 034:     33 / 99 loss=3.203, ppl=9.21, wps=9197.2, ups=13.07, wpb=703.8, bsz=32, num_updates=3300, lr=2.56923e-05, gnorm=2.905, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=453
2021-12-14 01:52:49 | INFO | train_inner | epoch 034:     43 / 99 loss=2.632, ppl=6.2, wps=8519.3, ups=13.77, wpb=618.7, bsz=32, num_updates=3310, lr=2.56769e-05, gnorm=3.068, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=454
2021-12-14 01:52:50 | INFO | train_inner | epoch 034:     53 / 99 loss=2.277, ppl=4.85, wps=6930.5, ups=13.89, wpb=498.9, bsz=32, num_updates=3320, lr=2.56615e-05, gnorm=3.287, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=455
2021-12-14 01:52:51 | INFO | train_inner | epoch 034:     63 / 99 loss=2.908, ppl=7.5, wps=9612.5, ups=14.37, wpb=668.9, bsz=32, num_updates=3330, lr=2.56462e-05, gnorm=3.189, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=455
2021-12-14 01:52:51 | INFO | train_inner | epoch 034:     73 / 99 loss=2.835, ppl=7.13, wps=9630.1, ups=13.75, wpb=700.6, bsz=32, num_updates=3340, lr=2.56308e-05, gnorm=2.954, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=456
2021-12-14 01:52:52 | INFO | train_inner | epoch 034:     83 / 99 loss=2.871, ppl=7.31, wps=9142.3, ups=15.16, wpb=603, bsz=32, num_updates=3350, lr=2.56154e-05, gnorm=3.125, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=457
2021-12-14 01:52:53 | INFO | train_inner | epoch 034:     93 / 99 loss=3.099, ppl=8.57, wps=8083.7, ups=10.92, wpb=740.4, bsz=32, num_updates=3360, lr=2.56e-05, gnorm=2.902, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=458
2021-12-14 01:52:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:52:55 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.254 | ppl 9.54 | wps 18838.8 | wpb 586.4 | bsz 31.3 | num_updates 3366 | best_loss 3.254
2021-12-14 01:52:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3366 updates
2021-12-14 01:52:55 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:52:57 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:52:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 34 @ 3366 updates, score 3.254) (writing took 3.753084700088948 seconds)
2021-12-14 01:52:58 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2021-12-14 01:52:58 | INFO | train | epoch 034 | loss 2.857 | ppl 7.25 | wps 5003 | ups 7.93 | wpb 630.8 | bsz 31.9 | num_updates 3366 | lr 2.55908e-05 | gnorm 3.046 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 463
2021-12-14 01:52:58 | INFO | fairseq.trainer | begin training epoch 35
2021-12-14 01:52:58 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:52:59 | INFO | train_inner | epoch 035:      4 / 99 loss=2.331, ppl=5.03, wps=788.4, ups=1.74, wpb=454, bsz=32, num_updates=3370, lr=2.55846e-05, gnorm=3.129, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=464
2021-12-14 01:52:59 | INFO | train_inner | epoch 035:     14 / 99 loss=2.816, ppl=7.04, wps=9546.1, ups=14.5, wpb=658.2, bsz=32, num_updates=3380, lr=2.55692e-05, gnorm=2.965, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=464
2021-12-14 01:53:00 | INFO | train_inner | epoch 035:     24 / 99 loss=2.461, ppl=5.5, wps=9724.3, ups=15.27, wpb=636.8, bsz=32, num_updates=3390, lr=2.55538e-05, gnorm=3.289, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=465
2021-12-14 01:53:01 | INFO | train_inner | epoch 035:     34 / 99 loss=2.315, ppl=4.98, wps=7686.6, ups=13.57, wpb=566.6, bsz=32, num_updates=3400, lr=2.55385e-05, gnorm=3.385, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=466
2021-12-14 01:53:02 | INFO | train_inner | epoch 035:     44 / 99 loss=3.631, ppl=12.39, wps=10388.1, ups=13.19, wpb=787.6, bsz=31.5, num_updates=3410, lr=2.55231e-05, gnorm=3.059, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=466
2021-12-14 01:53:02 | INFO | train_inner | epoch 035:     54 / 99 loss=2.278, ppl=4.85, wps=7313.5, ups=13.49, wpb=542.3, bsz=32, num_updates=3420, lr=2.55077e-05, gnorm=3.327, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=467
2021-12-14 01:53:03 | INFO | train_inner | epoch 035:     64 / 99 loss=3.325, ppl=10.02, wps=9418.9, ups=13.55, wpb=695.3, bsz=32, num_updates=3430, lr=2.54923e-05, gnorm=2.956, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=468
2021-12-14 01:53:04 | INFO | train_inner | epoch 035:     74 / 99 loss=2.246, ppl=4.74, wps=8298.4, ups=14.52, wpb=571.4, bsz=32, num_updates=3440, lr=2.54769e-05, gnorm=3.037, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=469
2021-12-14 01:53:04 | INFO | train_inner | epoch 035:     84 / 99 loss=2.299, ppl=4.92, wps=7850, ups=15.6, wpb=503.1, bsz=32, num_updates=3450, lr=2.54615e-05, gnorm=3.084, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=469
2021-12-14 01:53:05 | INFO | train_inner | epoch 035:     94 / 99 loss=2.013, ppl=4.04, wps=5760.8, ups=11.33, wpb=508.4, bsz=32, num_updates=3460, lr=2.54462e-05, gnorm=3.097, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=470
2021-12-14 01:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:53:07 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 3.263 | ppl 9.6 | wps 19779.8 | wpb 586.4 | bsz 31.3 | num_updates 3465 | best_loss 3.254
2021-12-14 01:53:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3465 updates
2021-12-14 01:53:07 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:53:09 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:53:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 35 @ 3465 updates, score 3.263) (writing took 2.716761423042044 seconds)
2021-12-14 01:53:09 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2021-12-14 01:53:09 | INFO | train | epoch 035 | loss 2.802 | ppl 6.97 | wps 5635.4 | ups 8.93 | wpb 630.8 | bsz 31.9 | num_updates 3465 | lr 2.54385e-05 | gnorm 3.109 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.6 | wall 474
2021-12-14 01:53:09 | INFO | fairseq.trainer | begin training epoch 36
2021-12-14 01:53:09 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:53:10 | INFO | train_inner | epoch 036:      5 / 99 loss=3.466, ppl=11.05, wps=1597.8, ups=2.18, wpb=732.2, bsz=32, num_updates=3470, lr=2.54308e-05, gnorm=3.08, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=475
2021-12-14 01:53:11 | INFO | train_inner | epoch 036:     15 / 99 loss=1.944, ppl=3.85, wps=7138.1, ups=14.99, wpb=476.3, bsz=32, num_updates=3480, lr=2.54154e-05, gnorm=2.915, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=475
2021-12-14 01:53:11 | INFO | train_inner | epoch 036:     25 / 99 loss=2.982, ppl=7.9, wps=9090.9, ups=13.51, wpb=672.7, bsz=32, num_updates=3490, lr=2.54e-05, gnorm=2.981, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=476
2021-12-14 01:53:12 | INFO | train_inner | epoch 036:     35 / 99 loss=2.336, ppl=5.05, wps=5935, ups=10.39, wpb=571, bsz=32, num_updates=3500, lr=2.53846e-05, gnorm=3.271, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=477
2021-12-14 01:53:13 | INFO | train_inner | epoch 036:     45 / 99 loss=2.559, ppl=5.89, wps=7654.2, ups=12.37, wpb=619, bsz=32, num_updates=3510, lr=2.53692e-05, gnorm=3.262, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=478
2021-12-14 01:53:14 | INFO | train_inner | epoch 036:     55 / 99 loss=2.848, ppl=7.2, wps=7656, ups=12.3, wpb=622.6, bsz=32, num_updates=3520, lr=2.53538e-05, gnorm=3.187, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=479
2021-12-14 01:53:15 | INFO | train_inner | epoch 036:     65 / 99 loss=3.037, ppl=8.21, wps=8318.9, ups=12.01, wpb=692.4, bsz=31.5, num_updates=3530, lr=2.53385e-05, gnorm=3.009, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=480
2021-12-14 01:53:16 | INFO | train_inner | epoch 036:     75 / 99 loss=2.909, ppl=7.51, wps=7685.4, ups=11.03, wpb=696.6, bsz=32, num_updates=3540, lr=2.53231e-05, gnorm=2.855, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=480
2021-12-14 01:53:17 | INFO | train_inner | epoch 036:     85 / 99 loss=3.485, ppl=11.2, wps=8636.3, ups=10.29, wpb=839.3, bsz=32, num_updates=3550, lr=2.53077e-05, gnorm=2.985, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=481
2021-12-14 01:53:18 | INFO | train_inner | epoch 036:     95 / 99 loss=2.385, ppl=5.22, wps=6399, ups=11, wpb=581.9, bsz=32, num_updates=3560, lr=2.52923e-05, gnorm=3.413, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=482
2021-12-14 01:53:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:53:19 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 3.197 | ppl 9.17 | wps 24546.6 | wpb 586.4 | bsz 31.3 | num_updates 3564 | best_loss 3.197
2021-12-14 01:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3564 updates
2021-12-14 01:53:19 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 36 @ 3564 updates, score 3.197) (writing took 3.5988363248761743 seconds)
2021-12-14 01:53:22 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2021-12-14 01:53:22 | INFO | train | epoch 036 | loss 2.74 | ppl 6.68 | wps 4854.6 | ups 7.7 | wpb 630.8 | bsz 31.9 | num_updates 3564 | lr 2.52862e-05 | gnorm 3.111 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 487
2021-12-14 01:53:22 | INFO | fairseq.trainer | begin training epoch 37
2021-12-14 01:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:53:23 | INFO | train_inner | epoch 037:      6 / 99 loss=2.283, ppl=4.87, wps=1090.9, ups=1.86, wpb=585.6, bsz=32, num_updates=3570, lr=2.52769e-05, gnorm=3.138, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=488
2021-12-14 01:53:24 | INFO | train_inner | epoch 037:     16 / 99 loss=2.69, ppl=6.45, wps=7092.7, ups=11.93, wpb=594.4, bsz=32, num_updates=3580, lr=2.52615e-05, gnorm=3.118, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=489
2021-12-14 01:53:25 | INFO | train_inner | epoch 037:     26 / 99 loss=1.952, ppl=3.87, wps=5750, ups=10.98, wpb=523.5, bsz=32, num_updates=3590, lr=2.52462e-05, gnorm=3.09, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=489
2021-12-14 01:53:25 | INFO | train_inner | epoch 037:     36 / 99 loss=2.406, ppl=5.3, wps=7770.9, ups=12.82, wpb=606.3, bsz=32, num_updates=3600, lr=2.52308e-05, gnorm=2.839, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=490
2021-12-14 01:53:26 | INFO | train_inner | epoch 037:     46 / 99 loss=2.745, ppl=6.7, wps=8421.2, ups=14.25, wpb=590.8, bsz=32, num_updates=3610, lr=2.52154e-05, gnorm=2.846, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=491
2021-12-14 01:53:27 | INFO | train_inner | epoch 037:     56 / 99 loss=2.608, ppl=6.09, wps=8037.3, ups=13.71, wpb=586.3, bsz=32, num_updates=3620, lr=2.52e-05, gnorm=2.835, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=492
2021-12-14 01:53:28 | INFO | train_inner | epoch 037:     66 / 99 loss=3.254, ppl=9.54, wps=9015.5, ups=12.8, wpb=704.2, bsz=32, num_updates=3630, lr=2.51846e-05, gnorm=2.824, clip=100, loss_scale=128, train_wall=1, gb_free=20.3, wall=492
2021-12-14 01:53:28 | INFO | train_inner | epoch 037:     76 / 99 loss=2.481, ppl=5.58, wps=8182.3, ups=11.97, wpb=683.5, bsz=32, num_updates=3640, lr=2.51692e-05, gnorm=2.841, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=493
2021-12-14 01:53:29 | INFO | train_inner | epoch 037:     86 / 99 loss=2.355, ppl=5.12, wps=7905.9, ups=12.09, wpb=654, bsz=32, num_updates=3650, lr=2.51538e-05, gnorm=2.915, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=494
2021-12-14 01:53:30 | INFO | train_inner | epoch 037:     96 / 99 loss=3.395, ppl=10.52, wps=8918.2, ups=12.19, wpb=731.4, bsz=31.5, num_updates=3660, lr=2.51385e-05, gnorm=3.024, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=495
2021-12-14 01:53:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:53:31 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 3.178 | ppl 9.05 | wps 22605.9 | wpb 586.4 | bsz 31.3 | num_updates 3663 | best_loss 3.178
2021-12-14 01:53:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3663 updates
2021-12-14 01:53:31 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:53:34 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:53:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 37 @ 3663 updates, score 3.178) (writing took 3.795583792962134 seconds)
2021-12-14 01:53:35 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2021-12-14 01:53:35 | INFO | train | epoch 037 | loss 2.662 | ppl 6.33 | wps 4908 | ups 7.78 | wpb 630.8 | bsz 31.9 | num_updates 3663 | lr 2.51338e-05 | gnorm 2.934 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.6 | wall 500
2021-12-14 01:53:35 | INFO | fairseq.trainer | begin training epoch 38
2021-12-14 01:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:53:36 | INFO | train_inner | epoch 038:      7 / 99 loss=3.375, ppl=10.37, wps=1494.7, ups=1.79, wpb=837.1, bsz=31.5, num_updates=3670, lr=2.51231e-05, gnorm=2.831, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=501
2021-12-14 01:53:37 | INFO | train_inner | epoch 038:     17 / 99 loss=2.699, ppl=6.49, wps=8284.5, ups=11.99, wpb=690.9, bsz=32, num_updates=3680, lr=2.51077e-05, gnorm=3.434, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=501
2021-12-14 01:53:37 | INFO | train_inner | epoch 038:     27 / 99 loss=2.648, ppl=6.27, wps=6362, ups=11.45, wpb=555.4, bsz=32, num_updates=3690, lr=2.50923e-05, gnorm=2.939, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=502
2021-12-14 01:53:38 | INFO | train_inner | epoch 038:     37 / 99 loss=2.265, ppl=4.81, wps=6598.5, ups=11.55, wpb=571.5, bsz=32, num_updates=3700, lr=2.50769e-05, gnorm=3.137, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=503
2021-12-14 01:53:39 | INFO | train_inner | epoch 038:     47 / 99 loss=2.689, ppl=6.45, wps=7602.9, ups=11.83, wpb=642.9, bsz=32, num_updates=3710, lr=2.50615e-05, gnorm=3.022, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=504
2021-12-14 01:53:40 | INFO | train_inner | epoch 038:     57 / 99 loss=2.204, ppl=4.61, wps=6884.3, ups=11.64, wpb=591.5, bsz=32, num_updates=3720, lr=2.50462e-05, gnorm=3.205, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=505
2021-12-14 01:53:41 | INFO | train_inner | epoch 038:     67 / 99 loss=2.655, ppl=6.3, wps=7312.3, ups=11.88, wpb=615.6, bsz=32, num_updates=3730, lr=2.50308e-05, gnorm=3.343, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=506
2021-12-14 01:53:42 | INFO | train_inner | epoch 038:     77 / 99 loss=2.875, ppl=7.34, wps=9033.2, ups=11.42, wpb=791.2, bsz=32, num_updates=3740, lr=2.50154e-05, gnorm=3.049, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=507
2021-12-14 01:53:43 | INFO | train_inner | epoch 038:     87 / 99 loss=2.393, ppl=5.25, wps=6419.4, ups=11.96, wpb=536.7, bsz=32, num_updates=3750, lr=2.5e-05, gnorm=3.635, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=507
2021-12-14 01:53:44 | INFO | train_inner | epoch 038:     97 / 99 loss=2.262, ppl=4.8, wps=5605.2, ups=10.41, wpb=538.4, bsz=32, num_updates=3760, lr=2.49846e-05, gnorm=3.012, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=508
2021-12-14 01:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:53:45 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.093 | ppl 8.53 | wps 22497.6 | wpb 586.4 | bsz 31.3 | num_updates 3762 | best_loss 3.093
2021-12-14 01:53:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3762 updates
2021-12-14 01:53:45 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:53:47 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 38 @ 3762 updates, score 3.093) (writing took 3.7117249800357968 seconds)
2021-12-14 01:53:48 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2021-12-14 01:53:48 | INFO | train | epoch 038 | loss 2.623 | ppl 6.16 | wps 4690.9 | ups 7.44 | wpb 630.8 | bsz 31.9 | num_updates 3762 | lr 2.49815e-05 | gnorm 3.172 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 513
2021-12-14 01:53:48 | INFO | fairseq.trainer | begin training epoch 39
2021-12-14 01:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:53:49 | INFO | train_inner | epoch 039:      8 / 99 loss=2.747, ppl=6.71, wps=1368.6, ups=1.81, wpb=755.4, bsz=32, num_updates=3770, lr=2.49692e-05, gnorm=3.013, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=514
2021-12-14 01:53:50 | INFO | train_inner | epoch 039:     18 / 99 loss=1.929, ppl=3.81, wps=5265.6, ups=11.58, wpb=454.9, bsz=32, num_updates=3780, lr=2.49538e-05, gnorm=3.055, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=515
2021-12-14 01:53:51 | INFO | train_inner | epoch 039:     28 / 99 loss=2.108, ppl=4.31, wps=6546, ups=12.04, wpb=543.7, bsz=32, num_updates=3790, lr=2.49385e-05, gnorm=3.19, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=516
2021-12-14 01:53:51 | INFO | train_inner | epoch 039:     38 / 99 loss=2.257, ppl=4.78, wps=8814.1, ups=14.38, wpb=612.9, bsz=32, num_updates=3800, lr=2.49231e-05, gnorm=3.082, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=516
2021-12-14 01:53:52 | INFO | train_inner | epoch 039:     48 / 99 loss=2.485, ppl=5.6, wps=10014.8, ups=13.85, wpb=723, bsz=32, num_updates=3810, lr=2.49077e-05, gnorm=2.902, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=517
2021-12-14 01:53:53 | INFO | train_inner | epoch 039:     58 / 99 loss=2.665, ppl=6.34, wps=9409.8, ups=13.56, wpb=694, bsz=32, num_updates=3820, lr=2.48923e-05, gnorm=3.041, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=518
2021-12-14 01:53:54 | INFO | train_inner | epoch 039:     68 / 99 loss=1.509, ppl=2.85, wps=5903.9, ups=13.73, wpb=430.1, bsz=32, num_updates=3830, lr=2.48769e-05, gnorm=2.834, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=518
2021-12-14 01:53:55 | INFO | train_inner | epoch 039:     78 / 99 loss=2.168, ppl=4.49, wps=5753.3, ups=11.15, wpb=516, bsz=32, num_updates=3840, lr=2.48615e-05, gnorm=3.094, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=519
2021-12-14 01:53:56 | INFO | train_inner | epoch 039:     88 / 99 loss=3.286, ppl=9.75, wps=8784.3, ups=10.66, wpb=824.2, bsz=32, num_updates=3850, lr=2.48462e-05, gnorm=2.788, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=520
2021-12-14 01:53:56 | INFO | train_inner | epoch 039:     98 / 99 loss=3.192, ppl=9.14, wps=7875.5, ups=10.64, wpb=740.4, bsz=31.5, num_updates=3860, lr=2.48308e-05, gnorm=2.946, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=521
2021-12-14 01:53:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:53:57 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 3.091 | ppl 8.52 | wps 22084.3 | wpb 586.4 | bsz 31.3 | num_updates 3861 | best_loss 3.091
2021-12-14 01:53:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 3861 updates
2021-12-14 01:53:57 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:54:00 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:54:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 39 @ 3861 updates, score 3.091) (writing took 3.8615691009908915 seconds)
2021-12-14 01:54:01 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2021-12-14 01:54:01 | INFO | train | epoch 039 | loss 2.551 | ppl 5.86 | wps 4834.6 | ups 7.66 | wpb 630.8 | bsz 31.9 | num_updates 3861 | lr 2.48292e-05 | gnorm 2.987 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 526
2021-12-14 01:54:01 | INFO | fairseq.trainer | begin training epoch 40
2021-12-14 01:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:54:02 | INFO | train_inner | epoch 040:      9 / 99 loss=2.091, ppl=4.26, wps=1073.5, ups=1.79, wpb=598.4, bsz=32, num_updates=3870, lr=2.48154e-05, gnorm=2.806, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=527
2021-12-14 01:54:03 | INFO | train_inner | epoch 040:     19 / 99 loss=1.808, ppl=3.5, wps=7476.8, ups=15.1, wpb=495.2, bsz=32, num_updates=3880, lr=2.48e-05, gnorm=3.349, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=528
2021-12-14 01:54:03 | INFO | train_inner | epoch 040:     29 / 99 loss=2.429, ppl=5.38, wps=8350.4, ups=13.22, wpb=631.8, bsz=32, num_updates=3890, lr=2.47846e-05, gnorm=3.089, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=528
2021-12-14 01:54:04 | INFO | train_inner | epoch 040:     39 / 99 loss=2.646, ppl=6.26, wps=8897.8, ups=12.6, wpb=706.1, bsz=32, num_updates=3900, lr=2.47692e-05, gnorm=2.894, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=529
2021-12-14 01:54:05 | INFO | train_inner | epoch 040:     49 / 99 loss=2.31, ppl=4.96, wps=6965.1, ups=12.9, wpb=539.9, bsz=32, num_updates=3910, lr=2.47538e-05, gnorm=3.191, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=530
2021-12-14 01:54:06 | INFO | train_inner | epoch 040:     59 / 99 loss=2.888, ppl=7.4, wps=7719, ups=12.31, wpb=627.2, bsz=32, num_updates=3920, lr=2.47385e-05, gnorm=3.226, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=531
2021-12-14 01:54:07 | INFO | train_inner | epoch 040:     69 / 99 loss=3.029, ppl=8.16, wps=9668.5, ups=12.26, wpb=788.7, bsz=32, num_updates=3930, lr=2.47231e-05, gnorm=3.496, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=531
2021-12-14 01:54:08 | INFO | train_inner | epoch 040:     79 / 99 loss=2.269, ppl=4.82, wps=6793.9, ups=11.95, wpb=568.6, bsz=32, num_updates=3940, lr=2.47077e-05, gnorm=3.871, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=532
2021-12-14 01:54:08 | INFO | train_inner | epoch 040:     89 / 99 loss=1.727, ppl=3.31, wps=5964.7, ups=11.18, wpb=533.3, bsz=32, num_updates=3950, lr=2.46923e-05, gnorm=2.904, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=533
2021-12-14 01:54:09 | INFO | train_inner | epoch 040:     99 / 99 loss=3.297, ppl=9.83, wps=7817.7, ups=9.47, wpb=825.8, bsz=31.5, num_updates=3960, lr=2.46769e-05, gnorm=3.19, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=534
2021-12-14 01:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:54:10 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 3.044 | ppl 8.25 | wps 23464.1 | wpb 586.4 | bsz 31.3 | num_updates 3960 | best_loss 3.044
2021-12-14 01:54:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 3960 updates
2021-12-14 01:54:10 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:54:13 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:54:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 40 @ 3960 updates, score 3.044) (writing took 4.076361168175936 seconds)
2021-12-14 01:54:14 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2021-12-14 01:54:14 | INFO | train | epoch 040 | loss 2.526 | ppl 5.76 | wps 4764.2 | ups 7.55 | wpb 630.8 | bsz 31.9 | num_updates 3960 | lr 2.46769e-05 | gnorm 3.205 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 539
2021-12-14 01:54:14 | INFO | fairseq.trainer | begin training epoch 41
2021-12-14 01:54:14 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:54:15 | INFO | train_inner | epoch 041:     10 / 99 loss=2.666, ppl=6.34, wps=1161.4, ups=1.74, wpb=669.3, bsz=32, num_updates=3970, lr=2.46615e-05, gnorm=2.918, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=540
2021-12-14 01:54:16 | INFO | train_inner | epoch 041:     20 / 99 loss=2.58, ppl=5.98, wps=10061.6, ups=13.14, wpb=766, bsz=32, num_updates=3980, lr=2.46462e-05, gnorm=2.97, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=541
2021-12-14 01:54:17 | INFO | train_inner | epoch 041:     30 / 99 loss=1.905, ppl=3.75, wps=7202.6, ups=13.05, wpb=552, bsz=32, num_updates=3990, lr=2.46308e-05, gnorm=3.185, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=542
2021-12-14 01:54:18 | INFO | train_inner | epoch 041:     40 / 99 loss=2.426, ppl=5.37, wps=7551.7, ups=12.86, wpb=587.1, bsz=32, num_updates=4000, lr=2.46154e-05, gnorm=2.884, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=542
2021-12-14 01:54:18 | INFO | train_inner | epoch 041:     50 / 99 loss=1.989, ppl=3.97, wps=7612.2, ups=13.63, wpb=558.3, bsz=32, num_updates=4010, lr=2.46e-05, gnorm=3.259, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=543
2021-12-14 01:54:19 | INFO | train_inner | epoch 041:     60 / 99 loss=2.343, ppl=5.07, wps=8641.8, ups=13.31, wpb=649.1, bsz=32, num_updates=4020, lr=2.45846e-05, gnorm=3.457, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=544
2021-12-14 01:54:20 | INFO | train_inner | epoch 041:     70 / 99 loss=3.099, ppl=8.57, wps=9648.2, ups=12.84, wpb=751.2, bsz=31.5, num_updates=4030, lr=2.45692e-05, gnorm=3.206, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=545
2021-12-14 01:54:21 | INFO | train_inner | epoch 041:     80 / 99 loss=2.757, ppl=6.76, wps=8730.4, ups=12.8, wpb=681.9, bsz=32, num_updates=4040, lr=2.45538e-05, gnorm=3.034, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=545
2021-12-14 01:54:21 | INFO | train_inner | epoch 041:     90 / 99 loss=1.923, ppl=3.79, wps=6003.3, ups=11.73, wpb=511.7, bsz=32, num_updates=4050, lr=2.45385e-05, gnorm=2.849, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=546
2021-12-14 01:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:54:23 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 3 | ppl 8 | wps 22404.6 | wpb 586.4 | bsz 31.3 | num_updates 4059 | best_loss 3
2021-12-14 01:54:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 4059 updates
2021-12-14 01:54:23 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:54:26 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:54:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 41 @ 4059 updates, score 3.0) (writing took 3.861359753878787 seconds)
2021-12-14 01:54:27 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2021-12-14 01:54:27 | INFO | train | epoch 041 | loss 2.457 | ppl 5.49 | wps 4904.9 | ups 7.78 | wpb 630.8 | bsz 31.9 | num_updates 4059 | lr 2.45246e-05 | gnorm 3.093 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.7 | wall 552
2021-12-14 01:54:27 | INFO | fairseq.trainer | begin training epoch 42
2021-12-14 01:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:54:27 | INFO | train_inner | epoch 042:      1 / 99 loss=2.444, ppl=5.44, wps=1026.9, ups=1.73, wpb=595.1, bsz=32, num_updates=4060, lr=2.45231e-05, gnorm=3.129, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=552
2021-12-14 01:54:28 | INFO | train_inner | epoch 042:     11 / 99 loss=1.991, ppl=3.98, wps=7365.4, ups=13.59, wpb=541.8, bsz=32, num_updates=4070, lr=2.45077e-05, gnorm=2.996, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=553
2021-12-14 01:54:29 | INFO | train_inner | epoch 042:     21 / 99 loss=2.473, ppl=5.55, wps=9594, ups=14.56, wpb=658.8, bsz=32, num_updates=4080, lr=2.44923e-05, gnorm=2.927, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=553
2021-12-14 01:54:29 | INFO | train_inner | epoch 042:     31 / 99 loss=2.593, ppl=6.03, wps=8589.6, ups=13.65, wpb=629.2, bsz=32, num_updates=4090, lr=2.44769e-05, gnorm=2.901, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=554
2021-12-14 01:54:30 | INFO | train_inner | epoch 042:     41 / 99 loss=2.338, ppl=5.06, wps=9723.5, ups=14.84, wpb=655.1, bsz=32, num_updates=4100, lr=2.44615e-05, gnorm=3.124, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=555
2021-12-14 01:54:31 | INFO | train_inner | epoch 042:     51 / 99 loss=2.798, ppl=6.95, wps=10057.7, ups=14.38, wpb=699.2, bsz=31.5, num_updates=4110, lr=2.44462e-05, gnorm=2.981, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=556
2021-12-14 01:54:31 | INFO | train_inner | epoch 042:     61 / 99 loss=2.478, ppl=5.57, wps=9392.9, ups=15.13, wpb=620.8, bsz=32, num_updates=4120, lr=2.44308e-05, gnorm=3.038, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=556
2021-12-14 01:54:32 | INFO | train_inner | epoch 042:     71 / 99 loss=1.467, ppl=2.76, wps=6338.9, ups=15.7, wpb=403.8, bsz=32, num_updates=4130, lr=2.44154e-05, gnorm=3.196, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=557
2021-12-14 01:54:33 | INFO | train_inner | epoch 042:     81 / 99 loss=2.453, ppl=5.47, wps=8525, ups=14.72, wpb=579.1, bsz=32, num_updates=4140, lr=2.44e-05, gnorm=3.466, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=558
2021-12-14 01:54:34 | INFO | train_inner | epoch 042:     91 / 99 loss=2.712, ppl=6.55, wps=11100.8, ups=13.72, wpb=808.9, bsz=32, num_updates=4150, lr=2.43846e-05, gnorm=3.088, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=558
2021-12-14 01:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:54:35 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 2.991 | ppl 7.95 | wps 19266.9 | wpb 586.4 | bsz 31.3 | num_updates 4158 | best_loss 2.991
2021-12-14 01:54:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4158 updates
2021-12-14 01:54:35 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:54:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 42 @ 4158 updates, score 2.991) (writing took 3.7539751071017236 seconds)
2021-12-14 01:54:39 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2021-12-14 01:54:39 | INFO | train | epoch 042 | loss 2.401 | ppl 5.28 | wps 5307.2 | ups 8.41 | wpb 630.8 | bsz 31.9 | num_updates 4158 | lr 2.43723e-05 | gnorm 3.057 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 564
2021-12-14 01:54:39 | INFO | fairseq.trainer | begin training epoch 43
2021-12-14 01:54:39 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:54:39 | INFO | train_inner | epoch 043:      2 / 99 loss=2.19, ppl=4.56, wps=1254.9, ups=1.79, wpb=700.8, bsz=32, num_updates=4160, lr=2.43692e-05, gnorm=2.804, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=564
2021-12-14 01:54:40 | INFO | train_inner | epoch 043:     12 / 99 loss=2.489, ppl=5.61, wps=9165.6, ups=12.9, wpb=710.5, bsz=32, num_updates=4170, lr=2.43538e-05, gnorm=3.089, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=565
2021-12-14 01:54:41 | INFO | train_inner | epoch 043:     22 / 99 loss=2.617, ppl=6.13, wps=9174.6, ups=13.49, wpb=680.3, bsz=32, num_updates=4180, lr=2.43385e-05, gnorm=2.833, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=565
2021-12-14 01:54:41 | INFO | train_inner | epoch 043:     32 / 99 loss=2.958, ppl=7.77, wps=11047.3, ups=14.13, wpb=781.9, bsz=31.5, num_updates=4190, lr=2.43231e-05, gnorm=2.739, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=566
2021-12-14 01:54:42 | INFO | train_inner | epoch 043:     42 / 99 loss=2.048, ppl=4.14, wps=8104.7, ups=14.73, wpb=550.1, bsz=32, num_updates=4200, lr=2.43077e-05, gnorm=2.766, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=567
2021-12-14 01:54:43 | INFO | train_inner | epoch 043:     52 / 99 loss=1.957, ppl=3.88, wps=8895.3, ups=15.58, wpb=570.9, bsz=32, num_updates=4210, lr=2.42923e-05, gnorm=2.884, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=567
2021-12-14 01:54:43 | INFO | train_inner | epoch 043:     62 / 99 loss=2.592, ppl=6.03, wps=9710, ups=15.11, wpb=642.5, bsz=32, num_updates=4220, lr=2.42769e-05, gnorm=3.035, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=568
2021-12-14 01:54:44 | INFO | train_inner | epoch 043:     72 / 99 loss=1.728, ppl=3.31, wps=7666, ups=14.34, wpb=534.5, bsz=32, num_updates=4230, lr=2.42615e-05, gnorm=2.916, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=569
2021-12-14 01:54:45 | INFO | train_inner | epoch 043:     82 / 99 loss=2.065, ppl=4.18, wps=8812.2, ups=15.04, wpb=585.9, bsz=32, num_updates=4240, lr=2.42462e-05, gnorm=2.881, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=569
2021-12-14 01:54:46 | INFO | train_inner | epoch 043:     92 / 99 loss=1.823, ppl=3.54, wps=6312.1, ups=11.71, wpb=539, bsz=32, num_updates=4250, lr=2.42308e-05, gnorm=2.867, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=570
2021-12-14 01:54:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:54:47 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 2.963 | ppl 7.8 | wps 20156.5 | wpb 586.4 | bsz 31.3 | num_updates 4257 | best_loss 2.963
2021-12-14 01:54:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4257 updates
2021-12-14 01:54:47 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:54:50 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:54:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 43 @ 4257 updates, score 2.963) (writing took 3.8949579778127372 seconds)
2021-12-14 01:54:51 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2021-12-14 01:54:51 | INFO | train | epoch 043 | loss 2.333 | ppl 5.04 | wps 5114.6 | ups 8.11 | wpb 630.8 | bsz 31.9 | num_updates 4257 | lr 2.422e-05 | gnorm 2.875 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 576
2021-12-14 01:54:51 | INFO | fairseq.trainer | begin training epoch 44
2021-12-14 01:54:51 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:54:51 | INFO | train_inner | epoch 044:      3 / 99 loss=2.506, ppl=5.68, wps=1227.8, ups=1.71, wpb=719.9, bsz=32, num_updates=4260, lr=2.42154e-05, gnorm=2.634, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=576
2021-12-14 01:54:52 | INFO | train_inner | epoch 044:     13 / 99 loss=1.484, ppl=2.8, wps=5355.3, ups=12.32, wpb=434.7, bsz=32, num_updates=4270, lr=2.42e-05, gnorm=3.189, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=577
2021-12-14 01:54:53 | INFO | train_inner | epoch 044:     23 / 99 loss=2.867, ppl=7.3, wps=10457.1, ups=12.34, wpb=847.7, bsz=31.5, num_updates=4280, lr=2.41846e-05, gnorm=3.011, clip=100, loss_scale=128, train_wall=1, gb_free=19.1, wall=578
2021-12-14 01:54:54 | INFO | train_inner | epoch 044:     33 / 99 loss=2.321, ppl=5, wps=8069.4, ups=12.91, wpb=625.1, bsz=32, num_updates=4290, lr=2.41692e-05, gnorm=3.092, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=579
2021-12-14 01:54:55 | INFO | train_inner | epoch 044:     43 / 99 loss=2.302, ppl=4.93, wps=7609.3, ups=11.37, wpb=669.3, bsz=32, num_updates=4300, lr=2.41538e-05, gnorm=2.93, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=580
2021-12-14 01:54:56 | INFO | train_inner | epoch 044:     53 / 99 loss=2.767, ppl=6.81, wps=8675.4, ups=11.71, wpb=741, bsz=32, num_updates=4310, lr=2.41385e-05, gnorm=3.212, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=580
2021-12-14 01:54:56 | INFO | train_inner | epoch 044:     63 / 99 loss=2.287, ppl=4.88, wps=8127.7, ups=12.71, wpb=639.4, bsz=32, num_updates=4320, lr=2.41231e-05, gnorm=2.84, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=581
2021-12-14 01:54:57 | INFO | train_inner | epoch 044:     73 / 99 loss=2.06, ppl=4.17, wps=7386.7, ups=12.07, wpb=612.2, bsz=32, num_updates=4330, lr=2.41077e-05, gnorm=3.049, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=582
2021-12-14 01:54:58 | INFO | train_inner | epoch 044:     83 / 99 loss=1.585, ppl=3, wps=5493.1, ups=10.91, wpb=503.3, bsz=32, num_updates=4340, lr=2.40923e-05, gnorm=2.921, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=583
2021-12-14 01:54:59 | INFO | train_inner | epoch 044:     93 / 99 loss=2.367, ppl=5.16, wps=7069.2, ups=11.61, wpb=609, bsz=32, num_updates=4350, lr=2.40769e-05, gnorm=2.886, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=584
2021-12-14 01:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:55:00 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 2.9 | ppl 7.46 | wps 24901.1 | wpb 586.4 | bsz 31.3 | num_updates 4356 | best_loss 2.9
2021-12-14 01:55:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4356 updates
2021-12-14 01:55:00 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:55:03 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:55:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 44 @ 4356 updates, score 2.9) (writing took 4.067699137842283 seconds)
2021-12-14 01:55:04 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2021-12-14 01:55:04 | INFO | train | epoch 044 | loss 2.306 | ppl 4.95 | wps 4726.2 | ups 7.49 | wpb 630.8 | bsz 31.9 | num_updates 4356 | lr 2.40677e-05 | gnorm 2.989 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 589
2021-12-14 01:55:04 | INFO | fairseq.trainer | begin training epoch 45
2021-12-14 01:55:04 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:55:05 | INFO | train_inner | epoch 045:      4 / 99 loss=2.148, ppl=4.43, wps=961.5, ups=1.75, wpb=550.8, bsz=32, num_updates=4360, lr=2.40615e-05, gnorm=2.96, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=589
2021-12-14 01:55:06 | INFO | train_inner | epoch 045:     14 / 99 loss=1.842, ppl=3.59, wps=7511.8, ups=11.95, wpb=628.6, bsz=32, num_updates=4370, lr=2.40462e-05, gnorm=2.793, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=590
2021-12-14 01:55:06 | INFO | train_inner | epoch 045:     24 / 99 loss=2.166, ppl=4.49, wps=7129.7, ups=11.72, wpb=608.4, bsz=32, num_updates=4380, lr=2.40308e-05, gnorm=2.776, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=591
2021-12-14 01:55:07 | INFO | train_inner | epoch 045:     34 / 99 loss=1.897, ppl=3.72, wps=6127.1, ups=11.93, wpb=513.5, bsz=32, num_updates=4390, lr=2.40154e-05, gnorm=2.986, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=592
2021-12-14 01:55:08 | INFO | train_inner | epoch 045:     44 / 99 loss=2.684, ppl=6.43, wps=8226.9, ups=11.23, wpb=732.6, bsz=32, num_updates=4400, lr=2.4e-05, gnorm=2.825, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=593
2021-12-14 01:55:09 | INFO | train_inner | epoch 045:     54 / 99 loss=2.028, ppl=4.08, wps=6378.3, ups=10.97, wpb=581.6, bsz=32, num_updates=4410, lr=2.39846e-05, gnorm=2.923, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=594
2021-12-14 01:55:10 | INFO | train_inner | epoch 045:     64 / 99 loss=2.084, ppl=4.24, wps=7080.3, ups=10.74, wpb=659.2, bsz=32, num_updates=4420, lr=2.39692e-05, gnorm=2.88, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=595
2021-12-14 01:55:11 | INFO | train_inner | epoch 045:     74 / 99 loss=2.595, ppl=6.04, wps=7352.3, ups=11.04, wpb=665.7, bsz=31.5, num_updates=4430, lr=2.39538e-05, gnorm=2.855, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=596
2021-12-14 01:55:12 | INFO | train_inner | epoch 045:     84 / 99 loss=2.724, ppl=6.6, wps=8864.6, ups=11.92, wpb=743.7, bsz=32, num_updates=4440, lr=2.39385e-05, gnorm=2.803, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=597
2021-12-14 01:55:13 | INFO | train_inner | epoch 045:     94 / 99 loss=1.772, ppl=3.42, wps=6025.4, ups=10.37, wpb=581.1, bsz=32, num_updates=4450, lr=2.39231e-05, gnorm=3.06, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=597
2021-12-14 01:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:55:14 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 2.854 | ppl 7.23 | wps 20393.8 | wpb 586.4 | bsz 31.3 | num_updates 4455 | best_loss 2.854
2021-12-14 01:55:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4455 updates
2021-12-14 01:55:14 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:55:17 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:55:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 45 @ 4455 updates, score 2.854) (writing took 3.80724327894859 seconds)
2021-12-14 01:55:18 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2021-12-14 01:55:18 | INFO | train | epoch 045 | loss 2.242 | ppl 4.73 | wps 4581.5 | ups 7.26 | wpb 630.8 | bsz 31.9 | num_updates 4455 | lr 2.39154e-05 | gnorm 2.884 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 603
2021-12-14 01:55:18 | INFO | fairseq.trainer | begin training epoch 46
2021-12-14 01:55:18 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:55:19 | INFO | train_inner | epoch 046:      5 / 99 loss=2.656, ppl=6.3, wps=1177.8, ups=1.69, wpb=697.1, bsz=32, num_updates=4460, lr=2.39077e-05, gnorm=3.015, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=603
2021-12-14 01:55:20 | INFO | train_inner | epoch 046:     15 / 99 loss=2.253, ppl=4.77, wps=7154.3, ups=9.75, wpb=734, bsz=32, num_updates=4470, lr=2.38923e-05, gnorm=2.975, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=604
2021-12-14 01:55:21 | INFO | train_inner | epoch 046:     25 / 99 loss=1.897, ppl=3.73, wps=5750.6, ups=10.38, wpb=554.1, bsz=32, num_updates=4480, lr=2.38769e-05, gnorm=2.984, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=605
2021-12-14 01:55:21 | INFO | train_inner | epoch 046:     35 / 99 loss=2.496, ppl=5.64, wps=9540.3, ups=13.24, wpb=720.7, bsz=32, num_updates=4490, lr=2.38615e-05, gnorm=2.976, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=606
2021-12-14 01:55:22 | INFO | train_inner | epoch 046:     45 / 99 loss=3.014, ppl=8.08, wps=8780.9, ups=12.67, wpb=692.8, bsz=31.5, num_updates=4500, lr=2.38462e-05, gnorm=2.798, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=607
2021-12-14 01:55:23 | INFO | train_inner | epoch 046:     55 / 99 loss=1.981, ppl=3.95, wps=8255.3, ups=13.72, wpb=601.6, bsz=32, num_updates=4510, lr=2.38308e-05, gnorm=3.182, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=608
2021-12-14 01:55:24 | INFO | train_inner | epoch 046:     65 / 99 loss=1.981, ppl=3.95, wps=9154.1, ups=13.27, wpb=690, bsz=32, num_updates=4520, lr=2.38154e-05, gnorm=2.826, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=608
2021-12-14 01:55:24 | INFO | train_inner | epoch 046:     75 / 99 loss=1.654, ppl=3.15, wps=7037.4, ups=13.99, wpb=503, bsz=32, num_updates=4530, lr=2.38e-05, gnorm=3.071, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=609
2021-12-14 01:55:25 | INFO | train_inner | epoch 046:     85 / 99 loss=2.322, ppl=5, wps=6123.3, ups=10.95, wpb=559.1, bsz=32, num_updates=4540, lr=2.37846e-05, gnorm=3.028, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=610
2021-12-14 01:55:26 | INFO | train_inner | epoch 046:     95 / 99 loss=1.734, ppl=3.33, wps=5682.8, ups=10.48, wpb=542.4, bsz=32, num_updates=4550, lr=2.37692e-05, gnorm=2.919, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=611
2021-12-14 01:55:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:55:28 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 2.893 | ppl 7.43 | wps 21508.3 | wpb 586.4 | bsz 31.3 | num_updates 4554 | best_loss 2.854
2021-12-14 01:55:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4554 updates
2021-12-14 01:55:28 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:55:30 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:55:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 46 @ 4554 updates, score 2.893) (writing took 2.6230751171242446 seconds)
2021-12-14 01:55:30 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2021-12-14 01:55:30 | INFO | train | epoch 046 | loss 2.203 | ppl 4.6 | wps 5162.1 | ups 8.18 | wpb 630.8 | bsz 31.9 | num_updates 4554 | lr 2.37631e-05 | gnorm 2.993 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.6 | wall 615
2021-12-14 01:55:30 | INFO | fairseq.trainer | begin training epoch 47
2021-12-14 01:55:30 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:55:31 | INFO | train_inner | epoch 047:      6 / 99 loss=2.138, ppl=4.4, wps=1478.6, ups=2.24, wpb=659.8, bsz=32, num_updates=4560, lr=2.37538e-05, gnorm=2.977, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=616
2021-12-14 01:55:31 | INFO | train_inner | epoch 047:     16 / 99 loss=2.251, ppl=4.76, wps=9850.4, ups=14.72, wpb=669.4, bsz=32, num_updates=4570, lr=2.37385e-05, gnorm=2.802, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=616
2021-12-14 01:55:32 | INFO | train_inner | epoch 047:     26 / 99 loss=2.044, ppl=4.12, wps=8701.3, ups=13.6, wpb=639.6, bsz=32, num_updates=4580, lr=2.37231e-05, gnorm=2.968, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=617
2021-12-14 01:55:33 | INFO | train_inner | epoch 047:     36 / 99 loss=2.573, ppl=5.95, wps=10139.1, ups=12.45, wpb=814.1, bsz=32, num_updates=4590, lr=2.37077e-05, gnorm=2.874, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=618
2021-12-14 01:55:34 | INFO | train_inner | epoch 047:     46 / 99 loss=2.248, ppl=4.75, wps=7598.4, ups=12, wpb=633.1, bsz=32, num_updates=4600, lr=2.36923e-05, gnorm=2.843, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=619
2021-12-14 01:55:35 | INFO | train_inner | epoch 047:     56 / 99 loss=1.765, ppl=3.4, wps=6485.3, ups=13.01, wpb=498.5, bsz=32, num_updates=4610, lr=2.36769e-05, gnorm=2.794, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=619
2021-12-14 01:55:35 | INFO | train_inner | epoch 047:     66 / 99 loss=1.752, ppl=3.37, wps=7225.6, ups=12.96, wpb=557.7, bsz=32, num_updates=4620, lr=2.36615e-05, gnorm=2.782, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=620
2021-12-14 01:55:36 | INFO | train_inner | epoch 047:     76 / 99 loss=2.208, ppl=4.62, wps=9001.8, ups=13.71, wpb=656.4, bsz=32, num_updates=4630, lr=2.36462e-05, gnorm=2.941, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=621
2021-12-14 01:55:37 | INFO | train_inner | epoch 047:     86 / 99 loss=2.792, ppl=6.92, wps=9470.3, ups=12.78, wpb=740.8, bsz=31.5, num_updates=4640, lr=2.36308e-05, gnorm=2.995, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=622
2021-12-14 01:55:38 | INFO | train_inner | epoch 047:     96 / 99 loss=1.733, ppl=3.33, wps=6824.1, ups=12.15, wpb=561.7, bsz=32, num_updates=4650, lr=2.36154e-05, gnorm=3.014, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=622
2021-12-14 01:55:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:55:39 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 2.838 | ppl 7.15 | wps 23834.4 | wpb 586.4 | bsz 31.3 | num_updates 4653 | best_loss 2.838
2021-12-14 01:55:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4653 updates
2021-12-14 01:55:39 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:55:41 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:55:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 47 @ 4653 updates, score 2.838) (writing took 3.887411301024258 seconds)
2021-12-14 01:55:43 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2021-12-14 01:55:43 | INFO | train | epoch 047 | loss 2.166 | ppl 4.49 | wps 5012.8 | ups 7.95 | wpb 630.8 | bsz 31.9 | num_updates 4653 | lr 2.36108e-05 | gnorm 2.876 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 627
2021-12-14 01:55:43 | INFO | fairseq.trainer | begin training epoch 48
2021-12-14 01:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:55:43 | INFO | train_inner | epoch 048:      7 / 99 loss=2.289, ppl=4.89, wps=1138.6, ups=1.8, wpb=633.9, bsz=32, num_updates=4660, lr=2.36e-05, gnorm=2.785, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=628
2021-12-14 01:55:44 | INFO | train_inner | epoch 048:     17 / 99 loss=2.415, ppl=5.33, wps=8576.7, ups=12.41, wpb=691, bsz=31.5, num_updates=4670, lr=2.35846e-05, gnorm=2.771, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=629
2021-12-14 01:55:45 | INFO | train_inner | epoch 048:     27 / 99 loss=2.679, ppl=6.4, wps=10493.9, ups=13.21, wpb=794.2, bsz=32, num_updates=4680, lr=2.35692e-05, gnorm=2.764, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=630
2021-12-14 01:55:46 | INFO | train_inner | epoch 048:     37 / 99 loss=1.65, ppl=3.14, wps=6670.4, ups=12.87, wpb=518.4, bsz=32, num_updates=4690, lr=2.35538e-05, gnorm=2.78, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=630
2021-12-14 01:55:46 | INFO | train_inner | epoch 048:     47 / 99 loss=1.604, ppl=3.04, wps=7882.7, ups=13.78, wpb=571.9, bsz=32, num_updates=4700, lr=2.35385e-05, gnorm=2.67, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=631
2021-12-14 01:55:47 | INFO | train_inner | epoch 048:     57 / 99 loss=2.002, ppl=4.01, wps=8508.9, ups=13.12, wpb=648.5, bsz=32, num_updates=4710, lr=2.35231e-05, gnorm=2.806, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=632
2021-12-14 01:55:48 | INFO | train_inner | epoch 048:     67 / 99 loss=1.654, ppl=3.15, wps=7136.8, ups=14.61, wpb=488.5, bsz=32, num_updates=4720, lr=2.35077e-05, gnorm=2.93, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=633
2021-12-14 01:55:49 | INFO | train_inner | epoch 048:     77 / 99 loss=2.364, ppl=5.15, wps=9360.9, ups=13.63, wpb=686.9, bsz=32, num_updates=4730, lr=2.34923e-05, gnorm=2.857, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=633
2021-12-14 01:55:49 | INFO | train_inner | epoch 048:     87 / 99 loss=2.225, ppl=4.67, wps=7930, ups=13.42, wpb=591, bsz=32, num_updates=4740, lr=2.34769e-05, gnorm=2.832, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=634
2021-12-14 01:55:50 | INFO | train_inner | epoch 048:     97 / 99 loss=1.66, ppl=3.16, wps=6542, ups=11.49, wpb=569.2, bsz=32, num_updates=4750, lr=2.34615e-05, gnorm=2.918, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=635
2021-12-14 01:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:55:51 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 2.839 | ppl 7.16 | wps 19231.4 | wpb 586.4 | bsz 31.3 | num_updates 4752 | best_loss 2.838
2021-12-14 01:55:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4752 updates
2021-12-14 01:55:51 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:55:54 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:55:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 48 @ 4752 updates, score 2.839) (writing took 2.661926826927811 seconds)
2021-12-14 01:55:54 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2021-12-14 01:55:54 | INFO | train | epoch 048 | loss 2.131 | ppl 4.38 | wps 5518 | ups 8.75 | wpb 630.8 | bsz 31.9 | num_updates 4752 | lr 2.34585e-05 | gnorm 2.825 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.4 | wall 639
2021-12-14 01:55:54 | INFO | fairseq.trainer | begin training epoch 49
2021-12-14 01:55:54 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:55:55 | INFO | train_inner | epoch 049:      8 / 99 loss=1.938, ppl=3.83, wps=1367.6, ups=2.25, wpb=608, bsz=32, num_updates=4760, lr=2.34462e-05, gnorm=2.99, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=639
2021-12-14 01:55:55 | INFO | train_inner | epoch 049:     18 / 99 loss=1.696, ppl=3.24, wps=8502.4, ups=14.87, wpb=571.7, bsz=32, num_updates=4770, lr=2.34308e-05, gnorm=2.779, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=640
2021-12-14 01:55:56 | INFO | train_inner | epoch 049:     28 / 99 loss=2.134, ppl=4.39, wps=8945.2, ups=14.5, wpb=616.7, bsz=32, num_updates=4780, lr=2.34154e-05, gnorm=2.675, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=641
2021-12-14 01:55:57 | INFO | train_inner | epoch 049:     38 / 99 loss=2.044, ppl=4.12, wps=6562.4, ups=13.23, wpb=496.2, bsz=32, num_updates=4790, lr=2.34e-05, gnorm=2.738, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=641
2021-12-14 01:55:57 | INFO | train_inner | epoch 049:     48 / 99 loss=1.657, ppl=3.15, wps=8009.9, ups=13.05, wpb=614, bsz=32, num_updates=4800, lr=2.33846e-05, gnorm=2.739, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=642
2021-12-14 01:55:58 | INFO | train_inner | epoch 049:     58 / 99 loss=3.203, ppl=9.21, wps=14066.3, ups=14.01, wpb=1003.7, bsz=31.5, num_updates=4810, lr=2.33692e-05, gnorm=2.7, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=643
2021-12-14 01:55:59 | INFO | train_inner | epoch 049:     68 / 99 loss=1.601, ppl=3.03, wps=7808.1, ups=14.61, wpb=534.4, bsz=32, num_updates=4820, lr=2.33538e-05, gnorm=3.081, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=644
2021-12-14 01:56:00 | INFO | train_inner | epoch 049:     78 / 99 loss=1.829, ppl=3.55, wps=8917.7, ups=14.13, wpb=630.9, bsz=32, num_updates=4830, lr=2.33385e-05, gnorm=2.889, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=644
2021-12-14 01:56:00 | INFO | train_inner | epoch 049:     88 / 99 loss=1.945, ppl=3.85, wps=8639.1, ups=13.31, wpb=649.1, bsz=32, num_updates=4840, lr=2.33231e-05, gnorm=2.816, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=645
2021-12-14 01:56:01 | INFO | train_inner | epoch 049:     98 / 99 loss=2.087, ppl=4.25, wps=6506, ups=10.53, wpb=618.1, bsz=32, num_updates=4850, lr=2.33077e-05, gnorm=2.827, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=646
2021-12-14 01:56:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:56:02 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 2.793 | ppl 6.93 | wps 19757.3 | wpb 586.4 | bsz 31.3 | num_updates 4851 | best_loss 2.793
2021-12-14 01:56:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 4851 updates
2021-12-14 01:56:02 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:56:05 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:56:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 49 @ 4851 updates, score 2.793) (writing took 3.8023207189980894 seconds)
2021-12-14 01:56:06 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2021-12-14 01:56:06 | INFO | train | epoch 049 | loss 2.077 | ppl 4.22 | wps 5116.5 | ups 8.11 | wpb 630.8 | bsz 31.9 | num_updates 4851 | lr 2.33062e-05 | gnorm 2.813 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 651
2021-12-14 01:56:06 | INFO | fairseq.trainer | begin training epoch 50
2021-12-14 01:56:06 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:56:07 | INFO | train_inner | epoch 050:      9 / 99 loss=2.472, ppl=5.55, wps=1321.1, ups=1.77, wpb=744.5, bsz=31.5, num_updates=4860, lr=2.32923e-05, gnorm=2.878, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=652
2021-12-14 01:56:08 | INFO | train_inner | epoch 050:     19 / 99 loss=1.824, ppl=3.54, wps=6804.9, ups=12.27, wpb=554.8, bsz=32, num_updates=4870, lr=2.32769e-05, gnorm=2.991, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=653
2021-12-14 01:56:09 | INFO | train_inner | epoch 050:     29 / 99 loss=2.422, ppl=5.36, wps=6883.9, ups=9.68, wpb=711, bsz=32, num_updates=4880, lr=2.32615e-05, gnorm=2.992, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=654
2021-12-14 01:56:10 | INFO | train_inner | epoch 050:     39 / 99 loss=1.294, ppl=2.45, wps=5024.9, ups=11.27, wpb=446, bsz=32, num_updates=4890, lr=2.32462e-05, gnorm=2.703, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=655
2021-12-14 01:56:11 | INFO | train_inner | epoch 050:     49 / 99 loss=2.438, ppl=5.42, wps=9164.3, ups=11.52, wpb=795.7, bsz=32, num_updates=4900, lr=2.32308e-05, gnorm=3.036, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=655
2021-12-14 01:56:12 | INFO | train_inner | epoch 050:     59 / 99 loss=2.146, ppl=4.43, wps=6890.1, ups=10.88, wpb=633.4, bsz=32, num_updates=4910, lr=2.32154e-05, gnorm=2.471, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=656
2021-12-14 01:56:12 | INFO | train_inner | epoch 050:     69 / 99 loss=2.103, ppl=4.3, wps=7245.3, ups=10.42, wpb=695.4, bsz=32, num_updates=4920, lr=2.32e-05, gnorm=2.686, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=657
2021-12-14 01:56:13 | INFO | train_inner | epoch 050:     79 / 99 loss=1.568, ppl=2.96, wps=5387.8, ups=10.05, wpb=536.3, bsz=32, num_updates=4930, lr=2.31846e-05, gnorm=2.8, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=658
2021-12-14 01:56:14 | INFO | train_inner | epoch 050:     89 / 99 loss=1.646, ppl=3.13, wps=6513.5, ups=11.13, wpb=585.4, bsz=32, num_updates=4940, lr=2.31692e-05, gnorm=3.022, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=659
2021-12-14 01:56:15 | INFO | train_inner | epoch 050:     99 / 99 loss=1.833, ppl=3.56, wps=7374, ups=12.3, wpb=599.7, bsz=32, num_updates=4950, lr=2.31538e-05, gnorm=2.835, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=660
2021-12-14 01:56:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:56:16 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 2.767 | ppl 6.81 | wps 24258.5 | wpb 586.4 | bsz 31.3 | num_updates 4950 | best_loss 2.767
2021-12-14 01:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 4950 updates
2021-12-14 01:56:16 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:56:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 50 @ 4950 updates, score 2.767) (writing took 3.6473057141993195 seconds)
2021-12-14 01:56:20 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2021-12-14 01:56:20 | INFO | train | epoch 050 | loss 2.039 | ppl 4.11 | wps 4619.5 | ups 7.32 | wpb 630.8 | bsz 31.9 | num_updates 4950 | lr 2.31538e-05 | gnorm 2.845 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 664
2021-12-14 01:56:20 | INFO | fairseq.trainer | begin training epoch 51
2021-12-14 01:56:20 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:56:21 | INFO | train_inner | epoch 051:     10 / 99 loss=2.155, ppl=4.45, wps=1254.3, ups=1.84, wpb=681.1, bsz=32, num_updates=4960, lr=2.31385e-05, gnorm=2.747, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=665
2021-12-14 01:56:22 | INFO | train_inner | epoch 051:     20 / 99 loss=2.223, ppl=4.67, wps=7135.3, ups=10.82, wpb=659.5, bsz=32, num_updates=4970, lr=2.31231e-05, gnorm=2.63, clip=100, loss_scale=128, train_wall=1, gb_free=20.3, wall=666
2021-12-14 01:56:22 | INFO | train_inner | epoch 051:     30 / 99 loss=2.028, ppl=4.08, wps=7773.8, ups=11.8, wpb=659, bsz=32, num_updates=4980, lr=2.31077e-05, gnorm=2.839, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=667
2021-12-14 01:56:23 | INFO | train_inner | epoch 051:     40 / 99 loss=2.415, ppl=5.33, wps=6724.2, ups=10.45, wpb=643.6, bsz=31.5, num_updates=4990, lr=2.30923e-05, gnorm=2.882, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=668
2021-12-14 01:56:24 | INFO | train_inner | epoch 051:     50 / 99 loss=2.006, ppl=4.02, wps=6102.4, ups=10.22, wpb=596.9, bsz=32, num_updates=5000, lr=2.30769e-05, gnorm=2.849, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=669
2021-12-14 01:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:56:25 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 2.809 | ppl 7.01 | wps 22495.9 | wpb 586.4 | bsz 31.3 | num_updates 5000 | best_loss 2.767
2021-12-14 01:56:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 5000 updates
2021-12-14 01:56:25 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_51_5000.pt
2021-12-14 01:56:28 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_51_5000.pt
2021-12-14 01:56:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_51_5000.pt (epoch 51 @ 5000 updates, score 2.809) (writing took 3.697571413125843 seconds)
2021-12-14 01:56:30 | INFO | train_inner | epoch 051:     60 / 99 loss=1.754, ppl=3.37, wps=1153.9, ups=1.81, wpb=637, bsz=32, num_updates=5010, lr=2.30615e-05, gnorm=2.896, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=675
2021-12-14 01:56:31 | INFO | train_inner | epoch 051:     70 / 99 loss=1.584, ppl=3, wps=6770.8, ups=11.63, wpb=582, bsz=32, num_updates=5020, lr=2.30462e-05, gnorm=2.769, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=676
2021-12-14 01:56:32 | INFO | train_inner | epoch 051:     80 / 99 loss=1.966, ppl=3.91, wps=6057.6, ups=10.66, wpb=568.4, bsz=32, num_updates=5030, lr=2.30308e-05, gnorm=2.85, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=676
2021-12-14 01:56:33 | INFO | train_inner | epoch 051:     90 / 99 loss=1.884, ppl=3.69, wps=6520.1, ups=10.67, wpb=610.8, bsz=32, num_updates=5040, lr=2.30154e-05, gnorm=2.841, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=677
2021-12-14 01:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:56:34 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 2.719 | ppl 6.59 | wps 19582.9 | wpb 586.4 | bsz 31.3 | num_updates 5049 | best_loss 2.719
2021-12-14 01:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 5049 updates
2021-12-14 01:56:34 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:56:37 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:56:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 51 @ 5049 updates, score 2.719) (writing took 3.804946077056229 seconds)
2021-12-14 01:56:38 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2021-12-14 01:56:38 | INFO | train | epoch 051 | loss 2.008 | ppl 4.02 | wps 3355.4 | ups 5.32 | wpb 630.8 | bsz 31.9 | num_updates 5049 | lr 2.30015e-05 | gnorm 2.811 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 683
2021-12-14 01:56:39 | INFO | fairseq.trainer | begin training epoch 52
2021-12-14 01:56:39 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:56:39 | INFO | train_inner | epoch 052:      1 / 99 loss=1.943, ppl=3.85, wps=1053.9, ups=1.65, wpb=638.3, bsz=32, num_updates=5050, lr=2.3e-05, gnorm=2.851, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=683
2021-12-14 01:56:40 | INFO | train_inner | epoch 052:     11 / 99 loss=2.196, ppl=4.58, wps=5361.2, ups=9.46, wpb=566.7, bsz=31.5, num_updates=5060, lr=2.29846e-05, gnorm=2.527, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=685
2021-12-14 01:56:41 | INFO | train_inner | epoch 052:     21 / 99 loss=1.978, ppl=3.94, wps=7448.4, ups=10.99, wpb=677.8, bsz=32, num_updates=5070, lr=2.29692e-05, gnorm=2.812, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=685
2021-12-14 01:56:42 | INFO | train_inner | epoch 052:     31 / 99 loss=1.84, ppl=3.58, wps=5895.2, ups=9.8, wpb=601.6, bsz=32, num_updates=5080, lr=2.29538e-05, gnorm=2.88, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=686
2021-12-14 01:56:43 | INFO | train_inner | epoch 052:     41 / 99 loss=1.265, ppl=2.4, wps=4537.3, ups=9.42, wpb=481.9, bsz=32, num_updates=5090, lr=2.29385e-05, gnorm=2.594, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=688
2021-12-14 01:56:44 | INFO | train_inner | epoch 052:     51 / 99 loss=2.121, ppl=4.35, wps=7254.7, ups=10.3, wpb=704.6, bsz=32, num_updates=5100, lr=2.29231e-05, gnorm=2.805, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=689
2021-12-14 01:56:45 | INFO | train_inner | epoch 052:     61 / 99 loss=2.151, ppl=4.44, wps=7675.6, ups=10.7, wpb=717.3, bsz=32, num_updates=5110, lr=2.29077e-05, gnorm=2.798, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=689
2021-12-14 01:56:46 | INFO | train_inner | epoch 052:     71 / 99 loss=2.237, ppl=4.72, wps=7019, ups=9.43, wpb=744.4, bsz=32, num_updates=5120, lr=2.28923e-05, gnorm=2.769, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=691
2021-12-14 01:56:47 | INFO | train_inner | epoch 052:     81 / 99 loss=2.264, ppl=4.8, wps=6182.9, ups=9.25, wpb=668.4, bsz=32, num_updates=5130, lr=2.28769e-05, gnorm=2.963, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=692
2021-12-14 01:56:48 | INFO | train_inner | epoch 052:     91 / 99 loss=1.816, ppl=3.52, wps=5732.6, ups=10.16, wpb=564.4, bsz=32, num_updates=5140, lr=2.28615e-05, gnorm=3.128, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=693
2021-12-14 01:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:56:49 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 2.769 | ppl 6.82 | wps 23197.1 | wpb 586.4 | bsz 31.3 | num_updates 5148 | best_loss 2.719
2021-12-14 01:56:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5148 updates
2021-12-14 01:56:49 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:56:52 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:56:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 52 @ 5148 updates, score 2.769) (writing took 2.7579284159000963 seconds)
2021-12-14 01:56:52 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2021-12-14 01:56:52 | INFO | train | epoch 052 | loss 1.982 | ppl 3.95 | wps 4584.1 | ups 7.27 | wpb 630.8 | bsz 31.9 | num_updates 5148 | lr 2.28492e-05 | gnorm 2.82 | clip 100 | loss_scale 128 | train_wall 10 | gb_free 20.8 | wall 697
2021-12-14 01:56:52 | INFO | fairseq.trainer | begin training epoch 53
2021-12-14 01:56:52 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:56:52 | INFO | train_inner | epoch 053:      2 / 99 loss=1.908, ppl=3.75, wps=1476.7, ups=2.19, wpb=673.1, bsz=32, num_updates=5150, lr=2.28462e-05, gnorm=2.86, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=697
2021-12-14 01:56:53 | INFO | train_inner | epoch 053:     12 / 99 loss=1.916, ppl=3.77, wps=7985.6, ups=13.55, wpb=589.3, bsz=32, num_updates=5160, lr=2.28308e-05, gnorm=2.8, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=698
2021-12-14 01:56:54 | INFO | train_inner | epoch 053:     22 / 99 loss=1.427, ppl=2.69, wps=7950.7, ups=13.74, wpb=578.8, bsz=32, num_updates=5170, lr=2.28154e-05, gnorm=2.867, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=699
2021-12-14 01:56:54 | INFO | train_inner | epoch 053:     32 / 99 loss=1.499, ppl=2.83, wps=8226.9, ups=15.13, wpb=543.7, bsz=32, num_updates=5180, lr=2.28e-05, gnorm=2.919, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=699
2021-12-14 01:56:55 | INFO | train_inner | epoch 053:     42 / 99 loss=2.106, ppl=4.31, wps=9749.1, ups=13.15, wpb=741.6, bsz=32, num_updates=5190, lr=2.27846e-05, gnorm=2.567, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=700
2021-12-14 01:56:56 | INFO | train_inner | epoch 053:     52 / 99 loss=1.657, ppl=3.15, wps=8202.9, ups=13.26, wpb=618.5, bsz=32, num_updates=5200, lr=2.27692e-05, gnorm=2.719, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=701
2021-12-14 01:56:57 | INFO | train_inner | epoch 053:     62 / 99 loss=2.298, ppl=4.92, wps=9207.6, ups=13.25, wpb=694.9, bsz=31.5, num_updates=5210, lr=2.27538e-05, gnorm=2.942, clip=100, loss_scale=128, train_wall=1, gb_free=19.1, wall=702
2021-12-14 01:56:57 | INFO | train_inner | epoch 053:     72 / 99 loss=1.483, ppl=2.8, wps=6851, ups=14.09, wpb=486.3, bsz=32, num_updates=5220, lr=2.27385e-05, gnorm=2.689, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=702
2021-12-14 01:56:58 | INFO | train_inner | epoch 053:     82 / 99 loss=2.349, ppl=5.09, wps=10358.2, ups=13.37, wpb=774.8, bsz=32, num_updates=5230, lr=2.27231e-05, gnorm=3.115, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=703
2021-12-14 01:56:59 | INFO | train_inner | epoch 053:     92 / 99 loss=2.432, ppl=5.4, wps=9520.3, ups=12.85, wpb=740.7, bsz=32, num_updates=5240, lr=2.27077e-05, gnorm=2.82, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=704
2021-12-14 01:57:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:57:00 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 2.673 | ppl 6.38 | wps 23564.2 | wpb 586.4 | bsz 31.3 | num_updates 5247 | best_loss 2.673
2021-12-14 01:57:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5247 updates
2021-12-14 01:57:00 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:57:03 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:57:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 53 @ 5247 updates, score 2.673) (writing took 3.667219744063914 seconds)
2021-12-14 01:57:04 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2021-12-14 01:57:04 | INFO | train | epoch 053 | loss 1.937 | ppl 3.83 | wps 5226 | ups 8.29 | wpb 630.8 | bsz 31.9 | num_updates 5247 | lr 2.26969e-05 | gnorm 2.83 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 709
2021-12-14 01:57:04 | INFO | fairseq.trainer | begin training epoch 54
2021-12-14 01:57:04 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:57:04 | INFO | train_inner | epoch 054:      3 / 99 loss=1.211, ppl=2.31, wps=825.2, ups=1.85, wpb=445.2, bsz=32, num_updates=5250, lr=2.26923e-05, gnorm=2.881, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=709
2021-12-14 01:57:05 | INFO | train_inner | epoch 054:     13 / 99 loss=2.824, ppl=7.08, wps=10010.5, ups=12.2, wpb=820.5, bsz=31.5, num_updates=5260, lr=2.26769e-05, gnorm=3.12, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=710
2021-12-14 01:57:06 | INFO | train_inner | epoch 054:     23 / 99 loss=1.341, ppl=2.53, wps=6777.4, ups=13.66, wpb=496, bsz=32, num_updates=5270, lr=2.26615e-05, gnorm=3.054, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=711
2021-12-14 01:57:07 | INFO | train_inner | epoch 054:     33 / 99 loss=1.471, ppl=2.77, wps=7710.7, ups=13.01, wpb=592.8, bsz=32, num_updates=5280, lr=2.26462e-05, gnorm=2.868, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=712
2021-12-14 01:57:08 | INFO | train_inner | epoch 054:     43 / 99 loss=1.741, ppl=3.34, wps=7176.5, ups=12.71, wpb=564.6, bsz=32, num_updates=5290, lr=2.26308e-05, gnorm=2.726, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=712
2021-12-14 01:57:08 | INFO | train_inner | epoch 054:     53 / 99 loss=1.571, ppl=2.97, wps=7866.8, ups=13.54, wpb=581.1, bsz=32, num_updates=5300, lr=2.26154e-05, gnorm=2.673, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=713
2021-12-14 01:57:09 | INFO | train_inner | epoch 054:     63 / 99 loss=2.367, ppl=5.16, wps=9363.2, ups=13.24, wpb=707.3, bsz=32, num_updates=5310, lr=2.26e-05, gnorm=2.588, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=714
2021-12-14 01:57:10 | INFO | train_inner | epoch 054:     73 / 99 loss=2.036, ppl=4.1, wps=10882.4, ups=15.19, wpb=716.6, bsz=32, num_updates=5320, lr=2.25846e-05, gnorm=2.91, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=714
2021-12-14 01:57:10 | INFO | train_inner | epoch 054:     83 / 99 loss=1.621, ppl=3.08, wps=9030.6, ups=15.58, wpb=579.8, bsz=32, num_updates=5330, lr=2.25692e-05, gnorm=2.779, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=715
2021-12-14 01:57:11 | INFO | train_inner | epoch 054:     93 / 99 loss=1.734, ppl=3.33, wps=7669.3, ups=13.27, wpb=578.1, bsz=32, num_updates=5340, lr=2.25538e-05, gnorm=2.773, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=716
2021-12-14 01:57:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:57:13 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 2.705 | ppl 6.52 | wps 19249.8 | wpb 586.4 | bsz 31.3 | num_updates 5346 | best_loss 2.673
2021-12-14 01:57:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5346 updates
2021-12-14 01:57:13 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:57:15 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:57:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 54 @ 5346 updates, score 2.705) (writing took 2.68693191697821 seconds)
2021-12-14 01:57:15 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2021-12-14 01:57:15 | INFO | train | epoch 054 | loss 1.901 | ppl 3.73 | wps 5593 | ups 8.87 | wpb 630.8 | bsz 31.9 | num_updates 5346 | lr 2.25446e-05 | gnorm 2.839 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.6 | wall 720
2021-12-14 01:57:15 | INFO | fairseq.trainer | begin training epoch 55
2021-12-14 01:57:15 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:57:16 | INFO | train_inner | epoch 055:      4 / 99 loss=1.827, ppl=3.55, wps=1650.8, ups=2.19, wpb=755.3, bsz=32, num_updates=5350, lr=2.25385e-05, gnorm=2.889, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=720
2021-12-14 01:57:16 | INFO | train_inner | epoch 055:     14 / 99 loss=1.865, ppl=3.64, wps=7796, ups=12.47, wpb=625, bsz=32, num_updates=5360, lr=2.25231e-05, gnorm=2.833, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=721
2021-12-14 01:57:17 | INFO | train_inner | epoch 055:     24 / 99 loss=1.997, ppl=3.99, wps=7421.8, ups=11.61, wpb=639.5, bsz=32, num_updates=5370, lr=2.25077e-05, gnorm=2.691, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=722
2021-12-14 01:57:18 | INFO | train_inner | epoch 055:     34 / 99 loss=1.415, ppl=2.67, wps=6507.8, ups=12.07, wpb=539, bsz=32, num_updates=5380, lr=2.24923e-05, gnorm=2.725, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=723
2021-12-14 01:57:19 | INFO | train_inner | epoch 055:     44 / 99 loss=1.579, ppl=2.99, wps=7041, ups=12.32, wpb=571.5, bsz=32, num_updates=5390, lr=2.24769e-05, gnorm=2.747, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=724
2021-12-14 01:57:20 | INFO | train_inner | epoch 055:     54 / 99 loss=1.389, ppl=2.62, wps=6250, ups=12.17, wpb=513.6, bsz=32, num_updates=5400, lr=2.24615e-05, gnorm=2.594, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=725
2021-12-14 01:57:21 | INFO | train_inner | epoch 055:     64 / 99 loss=1.792, ppl=3.46, wps=7307.7, ups=13.11, wpb=557.3, bsz=32, num_updates=5410, lr=2.24462e-05, gnorm=2.958, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=725
2021-12-14 01:57:21 | INFO | train_inner | epoch 055:     74 / 99 loss=1.56, ppl=2.95, wps=7309.9, ups=12.61, wpb=579.8, bsz=32, num_updates=5420, lr=2.24308e-05, gnorm=2.831, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=726
2021-12-14 01:57:22 | INFO | train_inner | epoch 055:     84 / 99 loss=2.084, ppl=4.24, wps=8913.9, ups=12.03, wpb=741.2, bsz=32, num_updates=5430, lr=2.24154e-05, gnorm=2.591, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=727
2021-12-14 01:57:23 | INFO | train_inner | epoch 055:     94 / 99 loss=2.665, ppl=6.34, wps=8392.9, ups=10.22, wpb=821.6, bsz=31.5, num_updates=5440, lr=2.24e-05, gnorm=3.055, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=728
2021-12-14 01:57:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:57:25 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 2.657 | ppl 6.31 | wps 19074.1 | wpb 586.4 | bsz 31.3 | num_updates 5445 | best_loss 2.657
2021-12-14 01:57:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5445 updates
2021-12-14 01:57:25 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:57:27 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:57:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 55 @ 5445 updates, score 2.657) (writing took 3.757253276882693 seconds)
2021-12-14 01:57:28 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2021-12-14 01:57:29 | INFO | train | epoch 055 | loss 1.873 | ppl 3.66 | wps 4775.5 | ups 7.57 | wpb 630.8 | bsz 31.9 | num_updates 5445 | lr 2.23923e-05 | gnorm 2.79 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.5 | wall 733
2021-12-14 01:57:29 | INFO | fairseq.trainer | begin training epoch 56
2021-12-14 01:57:29 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:57:29 | INFO | train_inner | epoch 056:      5 / 99 loss=2.065, ppl=4.18, wps=1101.8, ups=1.68, wpb=656.5, bsz=32, num_updates=5450, lr=2.23846e-05, gnorm=2.881, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=734
2021-12-14 01:57:30 | INFO | train_inner | epoch 056:     15 / 99 loss=1.594, ppl=3.02, wps=8307.7, ups=13.81, wpb=601.5, bsz=32, num_updates=5460, lr=2.23692e-05, gnorm=2.627, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=735
2021-12-14 01:57:31 | INFO | train_inner | epoch 056:     25 / 99 loss=1.513, ppl=2.85, wps=8887.2, ups=15.79, wpb=562.8, bsz=32, num_updates=5470, lr=2.23538e-05, gnorm=2.702, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=735
2021-12-14 01:57:31 | INFO | train_inner | epoch 056:     35 / 99 loss=1.337, ppl=2.53, wps=8715.3, ups=15.75, wpb=553.2, bsz=32, num_updates=5480, lr=2.23385e-05, gnorm=2.613, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=736
2021-12-14 01:57:32 | INFO | train_inner | epoch 056:     45 / 99 loss=1.634, ppl=3.1, wps=8101.1, ups=14.46, wpb=560.4, bsz=32, num_updates=5490, lr=2.23231e-05, gnorm=2.959, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=737
2021-12-14 01:57:33 | INFO | train_inner | epoch 056:     55 / 99 loss=2.29, ppl=4.89, wps=9390.8, ups=13.46, wpb=697.7, bsz=31.5, num_updates=5500, lr=2.23077e-05, gnorm=2.688, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=737
2021-12-14 01:57:33 | INFO | train_inner | epoch 056:     65 / 99 loss=2.408, ppl=5.31, wps=8907.5, ups=11.78, wpb=756.4, bsz=32, num_updates=5510, lr=2.22923e-05, gnorm=2.808, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=738
2021-12-14 01:57:34 | INFO | train_inner | epoch 056:     75 / 99 loss=1.334, ppl=2.52, wps=5962.6, ups=10.99, wpb=542.5, bsz=32, num_updates=5520, lr=2.22769e-05, gnorm=2.673, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=739
2021-12-14 01:57:35 | INFO | train_inner | epoch 056:     85 / 99 loss=1.966, ppl=3.91, wps=6995.6, ups=10.71, wpb=652.9, bsz=32, num_updates=5530, lr=2.22615e-05, gnorm=2.696, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=740
2021-12-14 01:57:36 | INFO | train_inner | epoch 056:     95 / 99 loss=1.883, ppl=3.69, wps=7108.6, ups=9.78, wpb=726.7, bsz=32, num_updates=5540, lr=2.22462e-05, gnorm=2.681, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=741
2021-12-14 01:57:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:57:37 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 2.67 | ppl 6.36 | wps 25455.6 | wpb 586.4 | bsz 31.3 | num_updates 5544 | best_loss 2.657
2021-12-14 01:57:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5544 updates
2021-12-14 01:57:37 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 56 @ 5544 updates, score 2.67) (writing took 2.6108304760418832 seconds)
2021-12-14 01:57:40 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2021-12-14 01:57:40 | INFO | train | epoch 056 | loss 1.831 | ppl 3.56 | wps 5493.6 | ups 8.71 | wpb 630.8 | bsz 31.9 | num_updates 5544 | lr 2.224e-05 | gnorm 2.718 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.5 | wall 745
2021-12-14 01:57:40 | INFO | fairseq.trainer | begin training epoch 57
2021-12-14 01:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:57:41 | INFO | train_inner | epoch 057:      6 / 99 loss=1.461, ppl=2.75, wps=1252.9, ups=2.22, wpb=563.4, bsz=32, num_updates=5550, lr=2.22308e-05, gnorm=2.76, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=746
2021-12-14 01:57:42 | INFO | train_inner | epoch 057:     16 / 99 loss=1.287, ppl=2.44, wps=5863.8, ups=11.56, wpb=507.2, bsz=32, num_updates=5560, lr=2.22154e-05, gnorm=2.764, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=746
2021-12-14 01:57:43 | INFO | train_inner | epoch 057:     26 / 99 loss=1.831, ppl=3.56, wps=8596.3, ups=11.94, wpb=720, bsz=32, num_updates=5570, lr=2.22e-05, gnorm=2.7, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=747
2021-12-14 01:57:44 | INFO | train_inner | epoch 057:     36 / 99 loss=2.098, ppl=4.28, wps=6133.2, ups=9.26, wpb=662.6, bsz=32, num_updates=5580, lr=2.21846e-05, gnorm=2.854, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=748
2021-12-14 01:57:45 | INFO | train_inner | epoch 057:     46 / 99 loss=1.895, ppl=3.72, wps=6852.4, ups=10.54, wpb=650.3, bsz=32, num_updates=5590, lr=2.21692e-05, gnorm=2.995, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=749
2021-12-14 01:57:46 | INFO | train_inner | epoch 057:     56 / 99 loss=1.198, ppl=2.29, wps=4962.5, ups=9.14, wpb=543.2, bsz=32, num_updates=5600, lr=2.21538e-05, gnorm=2.532, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=750
2021-12-14 01:57:47 | INFO | train_inner | epoch 057:     66 / 99 loss=2.104, ppl=4.3, wps=6770.8, ups=9.19, wpb=737, bsz=32, num_updates=5610, lr=2.21385e-05, gnorm=2.953, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=752
2021-12-14 01:57:48 | INFO | train_inner | epoch 057:     76 / 99 loss=1.211, ppl=2.32, wps=4618.5, ups=9.14, wpb=505.5, bsz=32, num_updates=5620, lr=2.21231e-05, gnorm=2.854, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=753
2021-12-14 01:57:49 | INFO | train_inner | epoch 057:     86 / 99 loss=1.972, ppl=3.92, wps=5996.9, ups=9.13, wpb=656.5, bsz=32, num_updates=5630, lr=2.21077e-05, gnorm=2.776, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=754
2021-12-14 01:57:50 | INFO | train_inner | epoch 057:     96 / 99 loss=2.498, ppl=5.65, wps=9876.6, ups=11.57, wpb=853.9, bsz=31.5, num_updates=5640, lr=2.20923e-05, gnorm=2.762, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=755
2021-12-14 01:57:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:57:51 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 2.717 | ppl 6.58 | wps 24567.6 | wpb 586.4 | bsz 31.3 | num_updates 5643 | best_loss 2.657
2021-12-14 01:57:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5643 updates
2021-12-14 01:57:51 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:57:53 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:57:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 57 @ 5643 updates, score 2.717) (writing took 2.621653702808544 seconds)
2021-12-14 01:57:53 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2021-12-14 01:57:54 | INFO | train | epoch 057 | loss 1.811 | ppl 3.51 | wps 4656.6 | ups 7.38 | wpb 630.8 | bsz 31.9 | num_updates 5643 | lr 2.20877e-05 | gnorm 2.791 | clip 100 | loss_scale 128 | train_wall 10 | gb_free 20.8 | wall 758
2021-12-14 01:57:54 | INFO | fairseq.trainer | begin training epoch 58
2021-12-14 01:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:57:54 | INFO | train_inner | epoch 058:      7 / 99 loss=1.449, ppl=2.73, wps=1275.4, ups=2.23, wpb=572.5, bsz=32, num_updates=5650, lr=2.20769e-05, gnorm=2.814, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=759
2021-12-14 01:57:55 | INFO | train_inner | epoch 058:     17 / 99 loss=1.647, ppl=3.13, wps=6356.8, ups=10.52, wpb=604, bsz=32, num_updates=5660, lr=2.20615e-05, gnorm=2.902, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=760
2021-12-14 01:57:56 | INFO | train_inner | epoch 058:     27 / 99 loss=1.528, ppl=2.88, wps=6987.3, ups=12.5, wpb=559.1, bsz=32, num_updates=5670, lr=2.20462e-05, gnorm=2.648, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=761
2021-12-14 01:57:57 | INFO | train_inner | epoch 058:     37 / 99 loss=1.45, ppl=2.73, wps=7985.3, ups=13.85, wpb=576.4, bsz=32, num_updates=5680, lr=2.20308e-05, gnorm=2.603, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=762
2021-12-14 01:57:58 | INFO | train_inner | epoch 058:     47 / 99 loss=2.42, ppl=5.35, wps=9024.9, ups=11.97, wpb=753.7, bsz=31.5, num_updates=5690, lr=2.20154e-05, gnorm=2.806, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=762
2021-12-14 01:57:58 | INFO | train_inner | epoch 058:     57 / 99 loss=1.592, ppl=3.01, wps=9121.1, ups=13.63, wpb=669, bsz=32, num_updates=5700, lr=2.2e-05, gnorm=2.693, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=763
2021-12-14 01:57:59 | INFO | train_inner | epoch 058:     67 / 99 loss=2.248, ppl=4.75, wps=9648.8, ups=11.82, wpb=816.4, bsz=32, num_updates=5710, lr=2.19846e-05, gnorm=2.561, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=764
2021-12-14 01:58:00 | INFO | train_inner | epoch 058:     77 / 99 loss=1.859, ppl=3.63, wps=8281.3, ups=13.32, wpb=621.8, bsz=32, num_updates=5720, lr=2.19692e-05, gnorm=2.73, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=765
2021-12-14 01:58:01 | INFO | train_inner | epoch 058:     87 / 99 loss=1.757, ppl=3.38, wps=6488.8, ups=12.46, wpb=520.7, bsz=32, num_updates=5730, lr=2.19538e-05, gnorm=2.519, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=766
2021-12-14 01:58:02 | INFO | train_inner | epoch 058:     97 / 99 loss=1.447, ppl=2.73, wps=7040, ups=11.49, wpb=612.8, bsz=32, num_updates=5740, lr=2.19385e-05, gnorm=2.783, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=766
2021-12-14 01:58:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:58:03 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 2.651 | ppl 6.28 | wps 23146 | wpb 586.4 | bsz 31.3 | num_updates 5742 | best_loss 2.651
2021-12-14 01:58:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5742 updates
2021-12-14 01:58:03 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:58:05 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:58:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 58 @ 5742 updates, score 2.651) (writing took 3.6373636769130826 seconds)
2021-12-14 01:58:06 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2021-12-14 01:58:06 | INFO | train | epoch 058 | loss 1.776 | ppl 3.43 | wps 4918.8 | ups 7.8 | wpb 630.8 | bsz 31.9 | num_updates 5742 | lr 2.19354e-05 | gnorm 2.713 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 771
2021-12-14 01:58:06 | INFO | fairseq.trainer | begin training epoch 59
2021-12-14 01:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:58:07 | INFO | train_inner | epoch 059:      8 / 99 loss=1.372, ppl=2.59, wps=936, ups=1.86, wpb=502.6, bsz=32, num_updates=5750, lr=2.19231e-05, gnorm=2.825, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=772
2021-12-14 01:58:08 | INFO | train_inner | epoch 059:     18 / 99 loss=1.358, ppl=2.56, wps=7699.5, ups=14.2, wpb=542.3, bsz=32, num_updates=5760, lr=2.19077e-05, gnorm=2.686, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=773
2021-12-14 01:58:08 | INFO | train_inner | epoch 059:     28 / 99 loss=1.658, ppl=3.16, wps=9110.2, ups=14.45, wpb=630.3, bsz=32, num_updates=5770, lr=2.18923e-05, gnorm=2.983, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=773
2021-12-14 01:58:09 | INFO | train_inner | epoch 059:     38 / 99 loss=2.384, ppl=5.22, wps=9310.8, ups=13.4, wpb=695, bsz=31.5, num_updates=5780, lr=2.18769e-05, gnorm=2.589, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=774
2021-12-14 01:58:10 | INFO | train_inner | epoch 059:     48 / 99 loss=1.805, ppl=3.5, wps=9151.9, ups=13.56, wpb=674.9, bsz=32, num_updates=5790, lr=2.18615e-05, gnorm=2.554, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=775
2021-12-14 01:58:11 | INFO | train_inner | epoch 059:     58 / 99 loss=1.643, ppl=3.12, wps=9483.2, ups=14.11, wpb=672, bsz=32, num_updates=5800, lr=2.18462e-05, gnorm=2.714, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=775
2021-12-14 01:58:11 | INFO | train_inner | epoch 059:     68 / 99 loss=1.69, ppl=3.23, wps=9037.9, ups=13.8, wpb=655, bsz=32, num_updates=5810, lr=2.18308e-05, gnorm=2.581, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=776
2021-12-14 01:58:12 | INFO | train_inner | epoch 059:     78 / 99 loss=1.369, ppl=2.58, wps=7374.1, ups=14.02, wpb=525.9, bsz=32, num_updates=5820, lr=2.18154e-05, gnorm=2.881, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=777
2021-12-14 01:58:13 | INFO | train_inner | epoch 059:     88 / 99 loss=1.772, ppl=3.42, wps=8470.7, ups=12.98, wpb=652.7, bsz=32, num_updates=5830, lr=2.18e-05, gnorm=2.609, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=778
2021-12-14 01:58:14 | INFO | train_inner | epoch 059:     98 / 99 loss=1.661, ppl=3.16, wps=6593.7, ups=10.49, wpb=628.7, bsz=32, num_updates=5840, lr=2.17846e-05, gnorm=2.782, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=779
2021-12-14 01:58:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:58:15 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 2.594 | ppl 6.04 | wps 21359.4 | wpb 586.4 | bsz 31.3 | num_updates 5841 | best_loss 2.594
2021-12-14 01:58:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 5841 updates
2021-12-14 01:58:15 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:58:17 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:58:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 59 @ 5841 updates, score 2.594) (writing took 3.7676016190089285 seconds)
2021-12-14 01:58:19 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2021-12-14 01:58:19 | INFO | train | epoch 059 | loss 1.744 | ppl 3.35 | wps 5098.8 | ups 8.08 | wpb 630.8 | bsz 31.9 | num_updates 5841 | lr 2.17831e-05 | gnorm 2.721 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.2 | wall 783
2021-12-14 01:58:19 | INFO | fairseq.trainer | begin training epoch 60
2021-12-14 01:58:19 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:58:19 | INFO | train_inner | epoch 060:      9 / 99 loss=2.221, ppl=4.66, wps=1305.5, ups=1.81, wpb=722.9, bsz=32, num_updates=5850, lr=2.17692e-05, gnorm=2.684, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=784
2021-12-14 01:58:20 | INFO | train_inner | epoch 060:     19 / 99 loss=1.365, ppl=2.58, wps=7729, ups=13.27, wpb=582.4, bsz=32, num_updates=5860, lr=2.17538e-05, gnorm=2.563, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=785
2021-12-14 01:58:21 | INFO | train_inner | epoch 060:     29 / 99 loss=1.303, ppl=2.47, wps=7211, ups=13.4, wpb=538.2, bsz=32, num_updates=5870, lr=2.17385e-05, gnorm=2.453, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=786
2021-12-14 01:58:22 | INFO | train_inner | epoch 060:     39 / 99 loss=1.595, ppl=3.02, wps=7893, ups=13.42, wpb=588.3, bsz=32, num_updates=5880, lr=2.17231e-05, gnorm=2.614, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=786
2021-12-14 01:58:22 | INFO | train_inner | epoch 060:     49 / 99 loss=1.502, ppl=2.83, wps=8475.2, ups=13.77, wpb=615.5, bsz=32, num_updates=5890, lr=2.17077e-05, gnorm=2.584, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=787
2021-12-14 01:58:23 | INFO | train_inner | epoch 060:     59 / 99 loss=1.751, ppl=3.37, wps=8527, ups=13.89, wpb=614, bsz=32, num_updates=5900, lr=2.16923e-05, gnorm=2.549, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=788
2021-12-14 01:58:24 | INFO | train_inner | epoch 060:     69 / 99 loss=1.737, ppl=3.33, wps=9267, ups=13.99, wpb=662.5, bsz=32, num_updates=5910, lr=2.16769e-05, gnorm=2.931, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=789
2021-12-14 01:58:25 | INFO | train_inner | epoch 060:     79 / 99 loss=1.535, ppl=2.9, wps=7436.5, ups=11.74, wpb=633.6, bsz=32, num_updates=5920, lr=2.16615e-05, gnorm=2.61, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=789
2021-12-14 01:58:26 | INFO | train_inner | epoch 060:     89 / 99 loss=2.164, ppl=4.48, wps=7708, ups=11.54, wpb=668.2, bsz=31.5, num_updates=5930, lr=2.16462e-05, gnorm=2.703, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=790
2021-12-14 01:58:27 | INFO | train_inner | epoch 060:     99 / 99 loss=2.039, ppl=4.11, wps=7404.2, ups=9.83, wpb=753.2, bsz=32, num_updates=5940, lr=2.16308e-05, gnorm=3.037, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=791
2021-12-14 01:58:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:58:27 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 2.602 | ppl 6.07 | wps 23213.3 | wpb 586.4 | bsz 31.3 | num_updates 5940 | best_loss 2.594
2021-12-14 01:58:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 5940 updates
2021-12-14 01:58:27 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:58:30 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:58:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 60 @ 5940 updates, score 2.602) (writing took 2.6520218830555677 seconds)
2021-12-14 01:58:30 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2021-12-14 01:58:30 | INFO | train | epoch 060 | loss 1.711 | ppl 3.27 | wps 5454.3 | ups 8.65 | wpb 630.8 | bsz 31.9 | num_updates 5940 | lr 2.16308e-05 | gnorm 2.672 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 795
2021-12-14 01:58:30 | INFO | fairseq.trainer | begin training epoch 61
2021-12-14 01:58:30 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:58:31 | INFO | train_inner | epoch 061:     10 / 99 loss=2.326, ppl=5.01, wps=1972.4, ups=2.3, wpb=857, bsz=31.5, num_updates=5950, lr=2.16154e-05, gnorm=2.68, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=796
2021-12-14 01:58:32 | INFO | train_inner | epoch 061:     20 / 99 loss=2.441, ppl=5.43, wps=11696, ups=12.15, wpb=962.8, bsz=32, num_updates=5960, lr=2.16e-05, gnorm=2.788, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=796
2021-12-14 01:58:32 | INFO | train_inner | epoch 061:     30 / 99 loss=1.377, ppl=2.6, wps=7721.1, ups=14.46, wpb=534.1, bsz=32, num_updates=5970, lr=2.15846e-05, gnorm=2.842, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=797
2021-12-14 01:58:33 | INFO | train_inner | epoch 061:     40 / 99 loss=1.611, ppl=3.05, wps=9243.7, ups=14.6, wpb=633.2, bsz=32, num_updates=5980, lr=2.15692e-05, gnorm=3.06, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=798
2021-12-14 01:58:34 | INFO | train_inner | epoch 061:     50 / 99 loss=1.327, ppl=2.51, wps=7940.6, ups=14.51, wpb=547.4, bsz=32, num_updates=5990, lr=2.15538e-05, gnorm=2.868, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=799
2021-12-14 01:58:34 | INFO | train_inner | epoch 061:     60 / 99 loss=1.387, ppl=2.62, wps=9114.3, ups=15.19, wpb=600, bsz=32, num_updates=6000, lr=2.15385e-05, gnorm=2.591, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=799
2021-12-14 01:58:35 | INFO | train_inner | epoch 061:     70 / 99 loss=1.12, ppl=2.17, wps=7342.9, ups=15.59, wpb=471, bsz=32, num_updates=6010, lr=2.15231e-05, gnorm=2.609, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=800
2021-12-14 01:58:36 | INFO | train_inner | epoch 061:     80 / 99 loss=1.317, ppl=2.49, wps=7991.3, ups=14.59, wpb=547.8, bsz=32, num_updates=6020, lr=2.15077e-05, gnorm=2.837, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=801
2021-12-14 01:58:36 | INFO | train_inner | epoch 061:     90 / 99 loss=1.494, ppl=2.82, wps=8260.8, ups=14.14, wpb=584.3, bsz=32, num_updates=6030, lr=2.14923e-05, gnorm=2.774, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=801
2021-12-14 01:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:58:38 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 2.558 | ppl 5.89 | wps 18970.4 | wpb 586.4 | bsz 31.3 | num_updates 6039 | best_loss 2.558
2021-12-14 01:58:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 6039 updates
2021-12-14 01:58:38 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:58:41 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:58:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 61 @ 6039 updates, score 2.558) (writing took 3.7017812281847 seconds)
2021-12-14 01:58:42 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2021-12-14 01:58:42 | INFO | train | epoch 061 | loss 1.684 | ppl 3.21 | wps 5233.4 | ups 8.3 | wpb 630.8 | bsz 31.9 | num_updates 6039 | lr 2.14785e-05 | gnorm 2.773 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 807
2021-12-14 01:58:42 | INFO | fairseq.trainer | begin training epoch 62
2021-12-14 01:58:42 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:58:42 | INFO | train_inner | epoch 062:      1 / 99 loss=1.387, ppl=2.62, wps=971, ups=1.78, wpb=545.4, bsz=32, num_updates=6040, lr=2.14769e-05, gnorm=2.611, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=807
2021-12-14 01:58:43 | INFO | train_inner | epoch 062:     11 / 99 loss=1.469, ppl=2.77, wps=7492.9, ups=12.66, wpb=591.7, bsz=32, num_updates=6050, lr=2.14615e-05, gnorm=3.017, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=808
2021-12-14 01:58:44 | INFO | train_inner | epoch 062:     21 / 99 loss=1.411, ppl=2.66, wps=8466.7, ups=13.78, wpb=614.5, bsz=32, num_updates=6060, lr=2.14462e-05, gnorm=3.117, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=808
2021-12-14 01:58:44 | INFO | train_inner | epoch 062:     31 / 99 loss=1.976, ppl=3.94, wps=7713.7, ups=13.07, wpb=590.2, bsz=32, num_updates=6070, lr=2.14308e-05, gnorm=3.108, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=809
2021-12-14 01:58:45 | INFO | train_inner | epoch 062:     41 / 99 loss=0.987, ppl=1.98, wps=7150.9, ups=14.79, wpb=483.4, bsz=32, num_updates=6080, lr=2.14154e-05, gnorm=2.838, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=810
2021-12-14 01:58:46 | INFO | train_inner | epoch 062:     51 / 99 loss=1.978, ppl=3.94, wps=11595.4, ups=14.99, wpb=773.5, bsz=32, num_updates=6090, lr=2.14e-05, gnorm=2.715, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=811
2021-12-14 01:58:46 | INFO | train_inner | epoch 062:     61 / 99 loss=0.839, ppl=1.79, wps=6553.7, ups=15.6, wpb=420.2, bsz=32, num_updates=6100, lr=2.13846e-05, gnorm=2.44, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=811
2021-12-14 01:58:47 | INFO | train_inner | epoch 062:     71 / 99 loss=2.024, ppl=4.07, wps=11206.6, ups=13.94, wpb=803.7, bsz=32, num_updates=6110, lr=2.13692e-05, gnorm=3.198, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=812
2021-12-14 01:58:48 | INFO | train_inner | epoch 062:     81 / 99 loss=2.118, ppl=4.34, wps=8967.3, ups=12.87, wpb=696.8, bsz=31.5, num_updates=6120, lr=2.13538e-05, gnorm=2.858, clip=100, loss_scale=128, train_wall=1, gb_free=19.1, wall=813
2021-12-14 01:58:49 | INFO | train_inner | epoch 062:     91 / 99 loss=1.913, ppl=3.77, wps=9444.2, ups=12.95, wpb=729, bsz=32, num_updates=6130, lr=2.13385e-05, gnorm=2.562, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=813
2021-12-14 01:58:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:58:50 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 2.515 | ppl 5.72 | wps 24066.3 | wpb 586.4 | bsz 31.3 | num_updates 6138 | best_loss 2.515
2021-12-14 01:58:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 6138 updates
2021-12-14 01:58:50 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:58:53 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:58:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 62 @ 6138 updates, score 2.515) (writing took 3.632004003971815 seconds)
2021-12-14 01:58:54 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2021-12-14 01:58:54 | INFO | train | epoch 062 | loss 1.696 | ppl 3.24 | wps 5299.3 | ups 8.4 | wpb 630.8 | bsz 31.9 | num_updates 6138 | lr 2.13262e-05 | gnorm 2.848 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 819
2021-12-14 01:58:54 | INFO | fairseq.trainer | begin training epoch 63
2021-12-14 01:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:58:54 | INFO | train_inner | epoch 063:      2 / 99 loss=1.503, ppl=2.83, wps=1141.6, ups=1.87, wpb=610.2, bsz=32, num_updates=6140, lr=2.13231e-05, gnorm=2.643, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=819
2021-12-14 01:58:55 | INFO | train_inner | epoch 063:     12 / 99 loss=1.532, ppl=2.89, wps=7157.7, ups=11.41, wpb=627.1, bsz=32, num_updates=6150, lr=2.13077e-05, gnorm=2.472, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=820
2021-12-14 01:58:56 | INFO | train_inner | epoch 063:     22 / 99 loss=1.71, ppl=3.27, wps=7494.8, ups=11.14, wpb=672.6, bsz=32, num_updates=6160, lr=2.12923e-05, gnorm=2.648, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=821
2021-12-14 01:58:57 | INFO | train_inner | epoch 063:     32 / 99 loss=1.731, ppl=3.32, wps=8222.1, ups=11.77, wpb=698.5, bsz=32, num_updates=6170, lr=2.12769e-05, gnorm=2.677, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=821
2021-12-14 01:58:58 | INFO | train_inner | epoch 063:     42 / 99 loss=1.306, ppl=2.47, wps=6321.2, ups=10.91, wpb=579.2, bsz=32, num_updates=6180, lr=2.12615e-05, gnorm=2.476, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=822
2021-12-14 01:58:58 | INFO | train_inner | epoch 063:     52 / 99 loss=1.634, ppl=3.1, wps=7716.3, ups=10.78, wpb=716, bsz=32, num_updates=6190, lr=2.12462e-05, gnorm=2.548, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=823
2021-12-14 01:58:59 | INFO | train_inner | epoch 063:     62 / 99 loss=1.256, ppl=2.39, wps=5005, ups=10.78, wpb=464.5, bsz=32, num_updates=6200, lr=2.12308e-05, gnorm=2.516, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=824
2021-12-14 01:59:00 | INFO | train_inner | epoch 063:     72 / 99 loss=1.175, ppl=2.26, wps=5479.5, ups=10.47, wpb=523.5, bsz=32, num_updates=6210, lr=2.12154e-05, gnorm=2.52, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=825
2021-12-14 01:59:01 | INFO | train_inner | epoch 063:     82 / 99 loss=1.938, ppl=3.83, wps=7548.2, ups=10.42, wpb=724.2, bsz=32, num_updates=6220, lr=2.12e-05, gnorm=2.779, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=826
2021-12-14 01:59:02 | INFO | train_inner | epoch 063:     92 / 99 loss=1.794, ppl=3.47, wps=7040.1, ups=11.22, wpb=627.7, bsz=32, num_updates=6230, lr=2.11846e-05, gnorm=2.529, clip=100, loss_scale=128, train_wall=1, gb_free=20.3, wall=827
2021-12-14 01:59:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:59:04 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 2.524 | ppl 5.75 | wps 23622.7 | wpb 586.4 | bsz 31.3 | num_updates 6237 | best_loss 2.515
2021-12-14 01:59:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6237 updates
2021-12-14 01:59:04 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:59:06 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:59:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 63 @ 6237 updates, score 2.524) (writing took 2.6843497660011053 seconds)
2021-12-14 01:59:06 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2021-12-14 01:59:06 | INFO | train | epoch 063 | loss 1.625 | ppl 3.09 | wps 4942.9 | ups 7.84 | wpb 630.8 | bsz 31.9 | num_updates 6237 | lr 2.11738e-05 | gnorm 2.583 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 831
2021-12-14 01:59:06 | INFO | fairseq.trainer | begin training epoch 64
2021-12-14 01:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:59:07 | INFO | train_inner | epoch 064:      3 / 99 loss=2.231, ppl=4.69, wps=1615, ups=2.21, wpb=732.1, bsz=31.5, num_updates=6240, lr=2.11692e-05, gnorm=2.625, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=832
2021-12-14 01:59:08 | INFO | train_inner | epoch 064:     13 / 99 loss=1.108, ppl=2.16, wps=5419.7, ups=10.92, wpb=496.1, bsz=32, num_updates=6250, lr=2.11538e-05, gnorm=2.439, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=832
2021-12-14 01:59:09 | INFO | train_inner | epoch 064:     23 / 99 loss=1.698, ppl=3.24, wps=8322.6, ups=11.29, wpb=737.2, bsz=32, num_updates=6260, lr=2.11385e-05, gnorm=2.653, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=833
2021-12-14 01:59:09 | INFO | train_inner | epoch 064:     33 / 99 loss=1.844, ppl=3.59, wps=9093, ups=13.28, wpb=684.5, bsz=32, num_updates=6270, lr=2.11231e-05, gnorm=2.529, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=834
2021-12-14 01:59:10 | INFO | train_inner | epoch 064:     43 / 99 loss=1.98, ppl=3.95, wps=9724.8, ups=13.47, wpb=722.2, bsz=31.5, num_updates=6280, lr=2.11077e-05, gnorm=2.6, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=835
2021-12-14 01:59:11 | INFO | train_inner | epoch 064:     53 / 99 loss=1.416, ppl=2.67, wps=7752.6, ups=12.88, wpb=601.8, bsz=32, num_updates=6290, lr=2.10923e-05, gnorm=2.743, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=836
2021-12-14 01:59:12 | INFO | train_inner | epoch 064:     63 / 99 loss=1.253, ppl=2.38, wps=7346.9, ups=12.59, wpb=583.5, bsz=32, num_updates=6300, lr=2.10769e-05, gnorm=2.649, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=836
2021-12-14 01:59:12 | INFO | train_inner | epoch 064:     73 / 99 loss=2.033, ppl=4.09, wps=10467.3, ups=12.63, wpb=828.8, bsz=32, num_updates=6310, lr=2.10615e-05, gnorm=2.813, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=837
2021-12-14 01:59:13 | INFO | train_inner | epoch 064:     83 / 99 loss=0.88, ppl=1.84, wps=5197.5, ups=12.9, wpb=402.8, bsz=32, num_updates=6320, lr=2.10462e-05, gnorm=2.57, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=838
2021-12-14 01:59:14 | INFO | train_inner | epoch 064:     93 / 99 loss=1.425, ppl=2.69, wps=6987.9, ups=11.76, wpb=594.1, bsz=32, num_updates=6330, lr=2.10308e-05, gnorm=2.988, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=839
2021-12-14 01:59:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:59:15 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 2.521 | ppl 5.74 | wps 22491.3 | wpb 586.4 | bsz 31.3 | num_updates 6336 | best_loss 2.515
2021-12-14 01:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6336 updates
2021-12-14 01:59:15 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 64 @ 6336 updates, score 2.521) (writing took 2.563336217077449 seconds)
2021-12-14 01:59:18 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2021-12-14 01:59:18 | INFO | train | epoch 064 | loss 1.605 | ppl 3.04 | wps 5351.4 | ups 8.48 | wpb 630.8 | bsz 31.9 | num_updates 6336 | lr 2.10215e-05 | gnorm 2.663 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.5 | wall 843
2021-12-14 01:59:18 | INFO | fairseq.trainer | begin training epoch 65
2021-12-14 01:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:59:19 | INFO | train_inner | epoch 065:      4 / 99 loss=1.739, ppl=3.34, wps=1512.8, ups=2.23, wpb=679.8, bsz=32, num_updates=6340, lr=2.10154e-05, gnorm=2.716, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=843
2021-12-14 01:59:20 | INFO | train_inner | epoch 065:     14 / 99 loss=2.092, ppl=4.26, wps=7823.7, ups=10.21, wpb=766.3, bsz=32, num_updates=6350, lr=2.1e-05, gnorm=2.931, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=844
2021-12-14 01:59:20 | INFO | train_inner | epoch 065:     24 / 99 loss=1.462, ppl=2.75, wps=7157.6, ups=12.3, wpb=581.9, bsz=32, num_updates=6360, lr=2.09846e-05, gnorm=2.771, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=845
2021-12-14 01:59:21 | INFO | train_inner | epoch 065:     34 / 99 loss=1.239, ppl=2.36, wps=7501.7, ups=12.29, wpb=610.3, bsz=32, num_updates=6370, lr=2.09692e-05, gnorm=2.568, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=846
2021-12-14 01:59:22 | INFO | train_inner | epoch 065:     44 / 99 loss=1.48, ppl=2.79, wps=7854.6, ups=13.08, wpb=600.4, bsz=32, num_updates=6380, lr=2.09538e-05, gnorm=2.612, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=847
2021-12-14 01:59:23 | INFO | train_inner | epoch 065:     54 / 99 loss=1.725, ppl=3.31, wps=8372.6, ups=11.88, wpb=704.6, bsz=32, num_updates=6390, lr=2.09385e-05, gnorm=2.375, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=848
2021-12-14 01:59:24 | INFO | train_inner | epoch 065:     64 / 99 loss=1.329, ppl=2.51, wps=5666.8, ups=10.69, wpb=530.3, bsz=32, num_updates=6400, lr=2.09231e-05, gnorm=2.458, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=849
2021-12-14 01:59:25 | INFO | train_inner | epoch 065:     74 / 99 loss=1.744, ppl=3.35, wps=7081.1, ups=11.6, wpb=610.3, bsz=31.5, num_updates=6410, lr=2.09077e-05, gnorm=2.346, clip=100, loss_scale=128, train_wall=1, gb_free=19.1, wall=849
2021-12-14 01:59:26 | INFO | train_inner | epoch 065:     84 / 99 loss=1.254, ppl=2.39, wps=6469.7, ups=10.7, wpb=604.4, bsz=32, num_updates=6420, lr=2.08923e-05, gnorm=2.667, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=850
2021-12-14 01:59:26 | INFO | train_inner | epoch 065:     94 / 99 loss=1.349, ppl=2.55, wps=6825.4, ups=11.65, wpb=586, bsz=32, num_updates=6430, lr=2.08769e-05, gnorm=2.426, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=851
2021-12-14 01:59:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:59:28 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 2.527 | ppl 5.76 | wps 23195.5 | wpb 586.4 | bsz 31.3 | num_updates 6435 | best_loss 2.515
2021-12-14 01:59:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6435 updates
2021-12-14 01:59:28 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:59:30 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 01:59:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 65 @ 6435 updates, score 2.527) (writing took 2.593502203002572 seconds)
2021-12-14 01:59:30 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2021-12-14 01:59:30 | INFO | train | epoch 065 | loss 1.57 | ppl 2.97 | wps 5122.3 | ups 8.12 | wpb 630.8 | bsz 31.9 | num_updates 6435 | lr 2.08692e-05 | gnorm 2.574 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 855
2021-12-14 01:59:30 | INFO | fairseq.trainer | begin training epoch 66
2021-12-14 01:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:59:31 | INFO | train_inner | epoch 066:      5 / 99 loss=1.319, ppl=2.5, wps=1377.4, ups=2.36, wpb=582.5, bsz=32, num_updates=6440, lr=2.08615e-05, gnorm=2.468, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=855
2021-12-14 01:59:31 | INFO | train_inner | epoch 066:     15 / 99 loss=0.922, ppl=1.89, wps=6656.3, ups=15.27, wpb=435.9, bsz=32, num_updates=6450, lr=2.08462e-05, gnorm=2.417, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=856
2021-12-14 01:59:32 | INFO | train_inner | epoch 066:     25 / 99 loss=1.641, ppl=3.12, wps=10279.3, ups=14.79, wpb=695.2, bsz=32, num_updates=6460, lr=2.08308e-05, gnorm=2.638, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=857
2021-12-14 01:59:33 | INFO | train_inner | epoch 066:     35 / 99 loss=1.818, ppl=3.52, wps=10850.4, ups=14.27, wpb=760.1, bsz=32, num_updates=6470, lr=2.08154e-05, gnorm=2.639, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=857
2021-12-14 01:59:33 | INFO | train_inner | epoch 066:     45 / 99 loss=1.389, ppl=2.62, wps=9042.7, ups=14.75, wpb=612.9, bsz=32, num_updates=6480, lr=2.08e-05, gnorm=2.536, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=858
2021-12-14 01:59:34 | INFO | train_inner | epoch 066:     55 / 99 loss=1.663, ppl=3.17, wps=8723.2, ups=13.07, wpb=667.5, bsz=32, num_updates=6490, lr=2.07846e-05, gnorm=2.448, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=859
2021-12-14 01:59:35 | INFO | train_inner | epoch 066:     65 / 99 loss=1.099, ppl=2.14, wps=7088.9, ups=13.4, wpb=529.2, bsz=32, num_updates=6500, lr=2.07692e-05, gnorm=2.709, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=860
2021-12-14 01:59:36 | INFO | train_inner | epoch 066:     75 / 99 loss=1.986, ppl=3.96, wps=11904.7, ups=14.23, wpb=836.5, bsz=32, num_updates=6510, lr=2.07538e-05, gnorm=2.587, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=860
2021-12-14 01:59:37 | INFO | train_inner | epoch 066:     85 / 99 loss=0.985, ppl=1.98, wps=5209.8, ups=10.22, wpb=509.9, bsz=32, num_updates=6520, lr=2.07385e-05, gnorm=2.436, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=861
2021-12-14 01:59:37 | INFO | train_inner | epoch 066:     95 / 99 loss=2.031, ppl=4.09, wps=7687.9, ups=11.01, wpb=698.2, bsz=31.5, num_updates=6530, lr=2.07231e-05, gnorm=2.652, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=862
2021-12-14 01:59:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:59:39 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 2.515 | ppl 5.72 | wps 23557.4 | wpb 586.4 | bsz 31.3 | num_updates 6534 | best_loss 2.515
2021-12-14 01:59:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6534 updates
2021-12-14 01:59:39 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:59:41 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:59:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 66 @ 6534 updates, score 2.515) (writing took 4.092729601077735 seconds)
2021-12-14 01:59:43 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2021-12-14 01:59:43 | INFO | train | epoch 066 | loss 1.552 | ppl 2.93 | wps 4976.8 | ups 7.89 | wpb 630.8 | bsz 31.9 | num_updates 6534 | lr 2.07169e-05 | gnorm 2.552 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 868
2021-12-14 01:59:43 | INFO | fairseq.trainer | begin training epoch 67
2021-12-14 01:59:43 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:59:43 | INFO | train_inner | epoch 067:      6 / 99 loss=1.387, ppl=2.62, wps=1089.2, ups=1.68, wpb=649.7, bsz=32, num_updates=6540, lr=2.07077e-05, gnorm=2.623, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=868
2021-12-14 01:59:44 | INFO | train_inner | epoch 067:     16 / 99 loss=1.346, ppl=2.54, wps=7083.1, ups=11.76, wpb=602.4, bsz=32, num_updates=6550, lr=2.06923e-05, gnorm=2.802, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=869
2021-12-14 01:59:45 | INFO | train_inner | epoch 067:     26 / 99 loss=1.409, ppl=2.66, wps=7102.8, ups=12.09, wpb=587.6, bsz=32, num_updates=6560, lr=2.06769e-05, gnorm=3.039, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=870
2021-12-14 01:59:46 | INFO | train_inner | epoch 067:     36 / 99 loss=1.876, ppl=3.67, wps=9067.3, ups=12, wpb=755.3, bsz=32, num_updates=6570, lr=2.06615e-05, gnorm=3.371, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=871
2021-12-14 01:59:47 | INFO | train_inner | epoch 067:     46 / 99 loss=1.326, ppl=2.51, wps=6412.2, ups=11.74, wpb=546.2, bsz=32, num_updates=6580, lr=2.06462e-05, gnorm=2.995, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=872
2021-12-14 01:59:48 | INFO | train_inner | epoch 067:     56 / 99 loss=1.599, ppl=3.03, wps=7635.5, ups=11.83, wpb=645.2, bsz=32, num_updates=6590, lr=2.06308e-05, gnorm=2.667, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=872
2021-12-14 01:59:49 | INFO | train_inner | epoch 067:     66 / 99 loss=2.271, ppl=4.83, wps=9297.5, ups=11.82, wpb=786.4, bsz=31.5, num_updates=6600, lr=2.06154e-05, gnorm=2.588, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=873
2021-12-14 01:59:49 | INFO | train_inner | epoch 067:     76 / 99 loss=1.339, ppl=2.53, wps=7407.7, ups=12.21, wpb=606.7, bsz=32, num_updates=6610, lr=2.06e-05, gnorm=2.573, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=874
2021-12-14 01:59:50 | INFO | train_inner | epoch 067:     86 / 99 loss=1.635, ppl=3.11, wps=8400.6, ups=11.88, wpb=707.4, bsz=32, num_updates=6620, lr=2.05846e-05, gnorm=2.625, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=875
2021-12-14 01:59:51 | INFO | train_inner | epoch 067:     96 / 99 loss=1.126, ppl=2.18, wps=6173.6, ups=11.91, wpb=518.5, bsz=32, num_updates=6630, lr=2.05692e-05, gnorm=2.539, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=876
2021-12-14 01:59:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 01:59:52 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 2.506 | ppl 5.68 | wps 22586 | wpb 586.4 | bsz 31.3 | num_updates 6633 | best_loss 2.506
2021-12-14 01:59:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6633 updates
2021-12-14 01:59:52 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:59:55 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 01:59:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 67 @ 6633 updates, score 2.506) (writing took 3.892295388970524 seconds)
2021-12-14 01:59:56 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2021-12-14 01:59:56 | INFO | train | epoch 067 | loss 1.559 | ppl 2.95 | wps 4739.6 | ups 7.51 | wpb 630.8 | bsz 31.9 | num_updates 6633 | lr 2.05646e-05 | gnorm 2.779 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 881
2021-12-14 01:59:56 | INFO | fairseq.trainer | begin training epoch 68
2021-12-14 01:59:56 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 01:59:57 | INFO | train_inner | epoch 068:      7 / 99 loss=1.196, ppl=2.29, wps=957.5, ups=1.79, wpb=533.5, bsz=32, num_updates=6640, lr=2.05538e-05, gnorm=2.486, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=881
2021-12-14 01:59:57 | INFO | train_inner | epoch 068:     17 / 99 loss=1.513, ppl=2.85, wps=7530, ups=13.7, wpb=549.6, bsz=32, num_updates=6650, lr=2.05385e-05, gnorm=2.573, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=882
2021-12-14 01:59:58 | INFO | train_inner | epoch 068:     27 / 99 loss=1.312, ppl=2.48, wps=9943.6, ups=15.54, wpb=639.8, bsz=32, num_updates=6660, lr=2.05231e-05, gnorm=2.726, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=883
2021-12-14 01:59:59 | INFO | train_inner | epoch 068:     37 / 99 loss=1.651, ppl=3.14, wps=10248.7, ups=15.34, wpb=668.2, bsz=32, num_updates=6670, lr=2.05077e-05, gnorm=2.629, clip=100, loss_scale=128, train_wall=1, gb_free=20, wall=883
2021-12-14 01:59:59 | INFO | train_inner | epoch 068:     47 / 99 loss=1.575, ppl=2.98, wps=10789.1, ups=15.31, wpb=704.6, bsz=32, num_updates=6680, lr=2.04923e-05, gnorm=2.448, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=884
2021-12-14 02:00:00 | INFO | train_inner | epoch 068:     57 / 99 loss=1.589, ppl=3.01, wps=10935.9, ups=15.13, wpb=722.8, bsz=32, num_updates=6690, lr=2.04769e-05, gnorm=2.558, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=885
2021-12-14 02:00:01 | INFO | train_inner | epoch 068:     67 / 99 loss=1.334, ppl=2.52, wps=8669.7, ups=15.03, wpb=576.9, bsz=32, num_updates=6700, lr=2.04615e-05, gnorm=2.446, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=885
2021-12-14 02:00:01 | INFO | train_inner | epoch 068:     77 / 99 loss=1.357, ppl=2.56, wps=8948.6, ups=15.05, wpb=594.5, bsz=32, num_updates=6710, lr=2.04462e-05, gnorm=2.579, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=886
2021-12-14 02:00:02 | INFO | train_inner | epoch 068:     87 / 99 loss=1.171, ppl=2.25, wps=7699.5, ups=14.75, wpb=521.9, bsz=32, num_updates=6720, lr=2.04308e-05, gnorm=2.624, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=887
2021-12-14 02:00:03 | INFO | train_inner | epoch 068:     97 / 99 loss=2.051, ppl=4.14, wps=8521.4, ups=11.5, wpb=741, bsz=31.5, num_updates=6730, lr=2.04154e-05, gnorm=2.432, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=888
2021-12-14 02:00:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:00:04 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 2.531 | ppl 5.78 | wps 18420.2 | wpb 586.4 | bsz 31.3 | num_updates 6732 | best_loss 2.506
2021-12-14 02:00:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6732 updates
2021-12-14 02:00:04 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:00:07 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:00:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 68 @ 6732 updates, score 2.531) (writing took 2.716263361973688 seconds)
2021-12-14 02:00:07 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2021-12-14 02:00:07 | INFO | train | epoch 068 | loss 1.507 | ppl 2.84 | wps 5812.1 | ups 9.21 | wpb 630.8 | bsz 31.9 | num_updates 6732 | lr 2.04123e-05 | gnorm 2.567 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 892
2021-12-14 02:00:07 | INFO | fairseq.trainer | begin training epoch 69
2021-12-14 02:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:00:07 | INFO | train_inner | epoch 069:      8 / 99 loss=1.348, ppl=2.55, wps=1330.6, ups=2.21, wpb=603.4, bsz=32, num_updates=6740, lr=2.04e-05, gnorm=2.579, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=892
2021-12-14 02:00:08 | INFO | train_inner | epoch 069:     18 / 99 loss=1.248, ppl=2.38, wps=8136.9, ups=13.68, wpb=594.8, bsz=32, num_updates=6750, lr=2.03846e-05, gnorm=3.005, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=893
2021-12-14 02:00:09 | INFO | train_inner | epoch 069:     28 / 99 loss=1.625, ppl=3.09, wps=10225.7, ups=13.8, wpb=741.1, bsz=32, num_updates=6760, lr=2.03692e-05, gnorm=2.521, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=894
2021-12-14 02:00:10 | INFO | train_inner | epoch 069:     38 / 99 loss=1.282, ppl=2.43, wps=7582.7, ups=14.18, wpb=534.9, bsz=32, num_updates=6770, lr=2.03538e-05, gnorm=2.432, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=894
2021-12-14 02:00:10 | INFO | train_inner | epoch 069:     48 / 99 loss=1.353, ppl=2.55, wps=7534.3, ups=14.18, wpb=531.2, bsz=32, num_updates=6780, lr=2.03385e-05, gnorm=2.542, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=895
2021-12-14 02:00:11 | INFO | train_inner | epoch 069:     58 / 99 loss=1.427, ppl=2.69, wps=9032.1, ups=13.29, wpb=679.8, bsz=32, num_updates=6790, lr=2.03231e-05, gnorm=2.409, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=896
2021-12-14 02:00:12 | INFO | train_inner | epoch 069:     68 / 99 loss=1.377, ppl=2.6, wps=7371.3, ups=13.16, wpb=560.1, bsz=32, num_updates=6800, lr=2.03077e-05, gnorm=2.557, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=897
2021-12-14 02:00:13 | INFO | train_inner | epoch 069:     78 / 99 loss=1.562, ppl=2.95, wps=8289.5, ups=12.49, wpb=663.6, bsz=32, num_updates=6810, lr=2.02923e-05, gnorm=2.665, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=897
2021-12-14 02:00:13 | INFO | train_inner | epoch 069:     88 / 99 loss=0.986, ppl=1.98, wps=5498.1, ups=12.05, wpb=456.4, bsz=32, num_updates=6820, lr=2.02769e-05, gnorm=2.485, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=898
2021-12-14 02:00:14 | INFO | train_inner | epoch 069:     98 / 99 loss=2.118, ppl=4.34, wps=8800.4, ups=10.13, wpb=868.9, bsz=31.5, num_updates=6830, lr=2.02615e-05, gnorm=2.475, clip=100, loss_scale=128, train_wall=1, gb_free=19.1, wall=899
2021-12-14 02:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:00:15 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 2.44 | ppl 5.42 | wps 22441.6 | wpb 586.4 | bsz 31.3 | num_updates 6831 | best_loss 2.44
2021-12-14 02:00:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 6831 updates
2021-12-14 02:00:15 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:00:18 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:00:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 69 @ 6831 updates, score 2.44) (writing took 3.616867803968489 seconds)
2021-12-14 02:00:19 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2021-12-14 02:00:19 | INFO | train | epoch 069 | loss 1.487 | ppl 2.8 | wps 5107.1 | ups 8.1 | wpb 630.8 | bsz 31.9 | num_updates 6831 | lr 2.026e-05 | gnorm 2.555 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.6 | wall 904
2021-12-14 02:00:19 | INFO | fairseq.trainer | begin training epoch 70
2021-12-14 02:00:19 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:00:20 | INFO | train_inner | epoch 070:      9 / 99 loss=1.879, ppl=3.68, wps=1336.9, ups=1.82, wpb=735.9, bsz=31.5, num_updates=6840, lr=2.02462e-05, gnorm=2.756, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=905
2021-12-14 02:00:21 | INFO | train_inner | epoch 070:     19 / 99 loss=1.122, ppl=2.18, wps=6767.7, ups=10.81, wpb=626.2, bsz=32, num_updates=6850, lr=2.02308e-05, gnorm=2.348, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=906
2021-12-14 02:00:22 | INFO | train_inner | epoch 070:     29 / 99 loss=1.984, ppl=3.96, wps=6723.8, ups=9.17, wpb=733.4, bsz=32, num_updates=6860, lr=2.02154e-05, gnorm=2.759, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=907
2021-12-14 02:00:23 | INFO | train_inner | epoch 070:     39 / 99 loss=1.452, ppl=2.74, wps=6888.3, ups=10.06, wpb=684.4, bsz=32, num_updates=6870, lr=2.02e-05, gnorm=2.469, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=908
2021-12-14 02:00:24 | INFO | train_inner | epoch 070:     49 / 99 loss=1.571, ppl=2.97, wps=5874.9, ups=9.57, wpb=614, bsz=32, num_updates=6880, lr=2.01846e-05, gnorm=2.559, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=909
2021-12-14 02:00:25 | INFO | train_inner | epoch 070:     59 / 99 loss=1.398, ppl=2.64, wps=5733.2, ups=9.45, wpb=606.4, bsz=32, num_updates=6890, lr=2.01692e-05, gnorm=2.733, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=910
2021-12-14 02:00:26 | INFO | train_inner | epoch 070:     69 / 99 loss=1.446, ppl=2.72, wps=5312.7, ups=9.07, wpb=585.9, bsz=32, num_updates=6900, lr=2.01538e-05, gnorm=2.725, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=911
2021-12-14 02:00:27 | INFO | train_inner | epoch 070:     79 / 99 loss=1.186, ppl=2.28, wps=5192, ups=9.41, wpb=551.5, bsz=32, num_updates=6910, lr=2.01385e-05, gnorm=2.471, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=912
2021-12-14 02:00:28 | INFO | train_inner | epoch 070:     89 / 99 loss=1.22, ppl=2.33, wps=5703.1, ups=9.55, wpb=597.4, bsz=32, num_updates=6920, lr=2.01231e-05, gnorm=2.509, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=913
2021-12-14 02:00:29 | INFO | train_inner | epoch 070:     99 / 99 loss=1.198, ppl=2.29, wps=6906.2, ups=11.44, wpb=603.7, bsz=32, num_updates=6930, lr=2.01077e-05, gnorm=2.578, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=914
2021-12-14 02:00:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:00:30 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 2.495 | ppl 5.64 | wps 24662.1 | wpb 586.4 | bsz 31.3 | num_updates 6930 | best_loss 2.44
2021-12-14 02:00:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 6930 updates
2021-12-14 02:00:30 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:00:33 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:00:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 70 @ 6930 updates, score 2.495) (writing took 2.696243528975174 seconds)
2021-12-14 02:00:33 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2021-12-14 02:00:33 | INFO | train | epoch 070 | loss 1.468 | ppl 2.77 | wps 4582.7 | ups 7.27 | wpb 630.8 | bsz 31.9 | num_updates 6930 | lr 2.01077e-05 | gnorm 2.594 | clip 100 | loss_scale 128 | train_wall 10 | gb_free 20.8 | wall 917
2021-12-14 02:00:33 | INFO | fairseq.trainer | begin training epoch 71
2021-12-14 02:00:33 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:00:34 | INFO | train_inner | epoch 071:     10 / 99 loss=1.416, ppl=2.67, wps=1501.2, ups=2.21, wpb=678.3, bsz=32, num_updates=6940, lr=2.00923e-05, gnorm=2.372, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=918
2021-12-14 02:00:35 | INFO | train_inner | epoch 071:     20 / 99 loss=1.822, ppl=3.54, wps=8547.8, ups=11.25, wpb=759.7, bsz=31.5, num_updates=6950, lr=2.00769e-05, gnorm=2.513, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=919
2021-12-14 02:00:35 | INFO | train_inner | epoch 071:     30 / 99 loss=1.739, ppl=3.34, wps=8432.8, ups=12.45, wpb=677.5, bsz=32, num_updates=6960, lr=2.00615e-05, gnorm=2.535, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=920
2021-12-14 02:00:36 | INFO | train_inner | epoch 071:     40 / 99 loss=0.829, ppl=1.78, wps=5500.1, ups=11.43, wpb=481, bsz=32, num_updates=6970, lr=2.00462e-05, gnorm=2.331, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=921
2021-12-14 02:00:37 | INFO | train_inner | epoch 071:     50 / 99 loss=1.21, ppl=2.31, wps=7880.3, ups=13.43, wpb=586.9, bsz=32, num_updates=6980, lr=2.00308e-05, gnorm=2.313, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=922
2021-12-14 02:00:38 | INFO | train_inner | epoch 071:     60 / 99 loss=1.053, ppl=2.07, wps=6154.5, ups=11.2, wpb=549.4, bsz=32, num_updates=6990, lr=2.00154e-05, gnorm=2.567, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=923
2021-12-14 02:00:39 | INFO | train_inner | epoch 071:     70 / 99 loss=1.555, ppl=2.94, wps=8049.1, ups=12.54, wpb=642.1, bsz=32, num_updates=7000, lr=2e-05, gnorm=2.53, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=923
2021-12-14 02:00:39 | INFO | train_inner | epoch 071:     80 / 99 loss=1.688, ppl=3.22, wps=10018.8, ups=13.06, wpb=767.4, bsz=32, num_updates=7010, lr=1.99846e-05, gnorm=2.465, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=924
2021-12-14 02:00:40 | INFO | train_inner | epoch 071:     90 / 99 loss=1.327, ppl=2.51, wps=6989.7, ups=12.75, wpb=548.2, bsz=32, num_updates=7020, lr=1.99692e-05, gnorm=2.693, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=925
2021-12-14 02:00:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:00:42 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 2.472 | ppl 5.55 | wps 22575.2 | wpb 586.4 | bsz 31.3 | num_updates 7029 | best_loss 2.44
2021-12-14 02:00:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 7029 updates
2021-12-14 02:00:42 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:00:45 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:00:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 71 @ 7029 updates, score 2.472) (writing took 2.6640866880770773 seconds)
2021-12-14 02:00:45 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2021-12-14 02:00:45 | INFO | train | epoch 071 | loss 1.439 | ppl 2.71 | wps 5236.9 | ups 8.3 | wpb 630.8 | bsz 31.9 | num_updates 7029 | lr 1.99554e-05 | gnorm 2.476 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 929
2021-12-14 02:00:45 | INFO | fairseq.trainer | begin training epoch 72
2021-12-14 02:00:45 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:00:45 | INFO | train_inner | epoch 072:      1 / 99 loss=1.359, ppl=2.57, wps=1372.1, ups=2.23, wpb=614.9, bsz=32, num_updates=7030, lr=1.99538e-05, gnorm=2.501, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=930
2021-12-14 02:00:46 | INFO | train_inner | epoch 072:     11 / 99 loss=1.612, ppl=3.06, wps=8089.2, ups=12.69, wpb=637.2, bsz=32, num_updates=7040, lr=1.99385e-05, gnorm=2.535, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=930
2021-12-14 02:00:46 | INFO | train_inner | epoch 072:     21 / 99 loss=1.227, ppl=2.34, wps=6708, ups=12.82, wpb=523.3, bsz=32, num_updates=7050, lr=1.99231e-05, gnorm=2.359, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=931
2021-12-14 02:00:47 | INFO | train_inner | epoch 072:     31 / 99 loss=1.412, ppl=2.66, wps=9276.1, ups=13.51, wpb=686.4, bsz=32, num_updates=7060, lr=1.99077e-05, gnorm=2.601, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=932
2021-12-14 02:00:48 | INFO | train_inner | epoch 072:     41 / 99 loss=1.284, ppl=2.44, wps=8184.7, ups=13.54, wpb=604.4, bsz=32, num_updates=7070, lr=1.98923e-05, gnorm=2.471, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=933
2021-12-14 02:00:49 | INFO | train_inner | epoch 072:     51 / 99 loss=1.152, ppl=2.22, wps=7000, ups=12.02, wpb=582.5, bsz=32, num_updates=7080, lr=1.98769e-05, gnorm=2.433, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=933
2021-12-14 02:00:49 | INFO | train_inner | epoch 072:     61 / 99 loss=1.109, ppl=2.16, wps=6386.1, ups=11.94, wpb=535, bsz=32, num_updates=7090, lr=1.98615e-05, gnorm=2.568, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=934
2021-12-14 02:00:50 | INFO | train_inner | epoch 072:     71 / 99 loss=1.91, ppl=3.76, wps=8800.8, ups=11.1, wpb=792.7, bsz=31.5, num_updates=7100, lr=1.98462e-05, gnorm=2.709, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=935
2021-12-14 02:00:51 | INFO | train_inner | epoch 072:     81 / 99 loss=1.616, ppl=3.06, wps=8813.9, ups=12.09, wpb=729.2, bsz=32, num_updates=7110, lr=1.98308e-05, gnorm=2.57, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=936
2021-12-14 02:00:52 | INFO | train_inner | epoch 072:     91 / 99 loss=1.129, ppl=2.19, wps=6713.8, ups=11.3, wpb=594.2, bsz=32, num_updates=7120, lr=1.98154e-05, gnorm=2.799, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=937
2021-12-14 02:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:00:54 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 2.446 | ppl 5.45 | wps 23472.8 | wpb 586.4 | bsz 31.3 | num_updates 7128 | best_loss 2.44
2021-12-14 02:00:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 7128 updates
2021-12-14 02:00:54 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 72 @ 7128 updates, score 2.446) (writing took 2.622917369939387 seconds)
2021-12-14 02:00:56 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2021-12-14 02:00:56 | INFO | train | epoch 072 | loss 1.428 | ppl 2.69 | wps 5329.6 | ups 8.45 | wpb 630.8 | bsz 31.9 | num_updates 7128 | lr 1.98031e-05 | gnorm 2.584 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 941
2021-12-14 02:00:56 | INFO | fairseq.trainer | begin training epoch 73
2021-12-14 02:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:00:57 | INFO | train_inner | epoch 073:      2 / 99 loss=1.821, ppl=3.53, wps=1617.1, ups=2.26, wpb=716.3, bsz=32, num_updates=7130, lr=1.98e-05, gnorm=2.741, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=941
2021-12-14 02:00:57 | INFO | train_inner | epoch 073:     12 / 99 loss=1.16, ppl=2.24, wps=6313.9, ups=11.06, wpb=570.9, bsz=32, num_updates=7140, lr=1.97846e-05, gnorm=2.61, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=942
2021-12-14 02:00:58 | INFO | train_inner | epoch 073:     22 / 99 loss=1.168, ppl=2.25, wps=8533, ups=12.57, wpb=679, bsz=32, num_updates=7150, lr=1.97692e-05, gnorm=2.419, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=943
2021-12-14 02:00:59 | INFO | train_inner | epoch 073:     32 / 99 loss=1.012, ppl=2.02, wps=6045.2, ups=11.31, wpb=534.3, bsz=32, num_updates=7160, lr=1.97538e-05, gnorm=2.278, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=944
2021-12-14 02:01:00 | INFO | train_inner | epoch 073:     42 / 99 loss=1.127, ppl=2.18, wps=6751.7, ups=11.38, wpb=593.1, bsz=32, num_updates=7170, lr=1.97385e-05, gnorm=2.363, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=945
2021-12-14 02:01:01 | INFO | train_inner | epoch 073:     52 / 99 loss=1.088, ppl=2.13, wps=6925.4, ups=11.77, wpb=588.4, bsz=32, num_updates=7180, lr=1.97231e-05, gnorm=2.421, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=946
2021-12-14 02:01:02 | INFO | train_inner | epoch 073:     62 / 99 loss=2.039, ppl=4.11, wps=8602.4, ups=11.14, wpb=772.3, bsz=31.5, num_updates=7190, lr=1.97077e-05, gnorm=2.331, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=947
2021-12-14 02:01:03 | INFO | train_inner | epoch 073:     72 / 99 loss=1.378, ppl=2.6, wps=7389.8, ups=10.82, wpb=682.7, bsz=32, num_updates=7200, lr=1.96923e-05, gnorm=2.491, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=947
2021-12-14 02:01:04 | INFO | train_inner | epoch 073:     82 / 99 loss=1.679, ppl=3.2, wps=7155.5, ups=11.01, wpb=650, bsz=32, num_updates=7210, lr=1.96769e-05, gnorm=2.428, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=948
2021-12-14 02:01:04 | INFO | train_inner | epoch 073:     92 / 99 loss=1.416, ppl=2.67, wps=6958.2, ups=11.08, wpb=627.9, bsz=32, num_updates=7220, lr=1.96615e-05, gnorm=2.785, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=949
2021-12-14 02:01:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:01:06 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 2.424 | ppl 5.37 | wps 24029 | wpb 586.4 | bsz 31.3 | num_updates 7227 | best_loss 2.424
2021-12-14 02:01:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7227 updates
2021-12-14 02:01:06 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:01:08 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:01:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 73 @ 7227 updates, score 2.424) (writing took 3.633727257139981 seconds)
2021-12-14 02:01:09 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2021-12-14 02:01:09 | INFO | train | epoch 073 | loss 1.393 | ppl 2.63 | wps 4728.1 | ups 7.5 | wpb 630.8 | bsz 31.9 | num_updates 7227 | lr 1.96508e-05 | gnorm 2.46 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 954
2021-12-14 02:01:10 | INFO | fairseq.trainer | begin training epoch 74
2021-12-14 02:01:10 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:01:10 | INFO | train_inner | epoch 074:      3 / 99 loss=1.074, ppl=2.11, wps=895.3, ups=1.88, wpb=477.4, bsz=32, num_updates=7230, lr=1.96462e-05, gnorm=2.405, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=955
2021-12-14 02:01:11 | INFO | train_inner | epoch 074:     13 / 99 loss=1.586, ppl=3, wps=9027.1, ups=12.68, wpb=711.7, bsz=32, num_updates=7240, lr=1.96308e-05, gnorm=2.339, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=955
2021-12-14 02:01:11 | INFO | train_inner | epoch 074:     23 / 99 loss=1.165, ppl=2.24, wps=7769.7, ups=13.73, wpb=566, bsz=32, num_updates=7250, lr=1.96154e-05, gnorm=2.483, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=956
2021-12-14 02:01:12 | INFO | train_inner | epoch 074:     33 / 99 loss=1.261, ppl=2.4, wps=6801.1, ups=12.73, wpb=534.1, bsz=32, num_updates=7260, lr=1.96e-05, gnorm=2.338, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=957
2021-12-14 02:01:13 | INFO | train_inner | epoch 074:     43 / 99 loss=1.893, ppl=3.71, wps=9733.2, ups=12.83, wpb=758.9, bsz=31.5, num_updates=7270, lr=1.95846e-05, gnorm=2.451, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=958
2021-12-14 02:01:14 | INFO | train_inner | epoch 074:     53 / 99 loss=1.473, ppl=2.78, wps=9595.1, ups=13.76, wpb=697.1, bsz=32, num_updates=7280, lr=1.95692e-05, gnorm=2.493, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=958
2021-12-14 02:01:14 | INFO | train_inner | epoch 074:     63 / 99 loss=1.429, ppl=2.69, wps=9943.2, ups=13.13, wpb=757, bsz=32, num_updates=7290, lr=1.95538e-05, gnorm=2.545, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=959
2021-12-14 02:01:15 | INFO | train_inner | epoch 074:     73 / 99 loss=1.415, ppl=2.67, wps=9388.8, ups=13.41, wpb=700, bsz=32, num_updates=7300, lr=1.95385e-05, gnorm=2.554, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=960
2021-12-14 02:01:16 | INFO | train_inner | epoch 074:     83 / 99 loss=0.926, ppl=1.9, wps=6414.9, ups=12.92, wpb=496.5, bsz=32, num_updates=7310, lr=1.95231e-05, gnorm=2.225, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=961
2021-12-14 02:01:17 | INFO | train_inner | epoch 074:     93 / 99 loss=1.146, ppl=2.21, wps=6382.9, ups=11.31, wpb=564.2, bsz=32, num_updates=7320, lr=1.95077e-05, gnorm=2.394, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=962
2021-12-14 02:01:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:01:18 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 2.466 | ppl 5.52 | wps 19318.3 | wpb 586.4 | bsz 31.3 | num_updates 7326 | best_loss 2.424
2021-12-14 02:01:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7326 updates
2021-12-14 02:01:18 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:01:21 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:01:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 74 @ 7326 updates, score 2.466) (writing took 2.744798473082483 seconds)
2021-12-14 02:01:21 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2021-12-14 02:01:21 | INFO | train | epoch 074 | loss 1.369 | ppl 2.58 | wps 5396.3 | ups 8.56 | wpb 630.8 | bsz 31.9 | num_updates 7326 | lr 1.94985e-05 | gnorm 2.42 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 966
2021-12-14 02:01:21 | INFO | fairseq.trainer | begin training epoch 75
2021-12-14 02:01:21 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:01:21 | INFO | train_inner | epoch 075:      4 / 99 loss=1.024, ppl=2.03, wps=1240.7, ups=2.17, wpb=570.9, bsz=32, num_updates=7330, lr=1.94923e-05, gnorm=2.375, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=966
2021-12-14 02:01:22 | INFO | train_inner | epoch 075:     14 / 99 loss=0.869, ppl=1.83, wps=7218.4, ups=14.87, wpb=485.5, bsz=32, num_updates=7340, lr=1.94769e-05, gnorm=2.256, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=967
2021-12-14 02:01:23 | INFO | train_inner | epoch 075:     24 / 99 loss=1.127, ppl=2.18, wps=8222.7, ups=14.83, wpb=554.6, bsz=32, num_updates=7350, lr=1.94615e-05, gnorm=2.413, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=968
2021-12-14 02:01:24 | INFO | train_inner | epoch 075:     34 / 99 loss=1.521, ppl=2.87, wps=9145.5, ups=13.73, wpb=666.3, bsz=32, num_updates=7360, lr=1.94462e-05, gnorm=2.387, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=968
2021-12-14 02:01:24 | INFO | train_inner | epoch 075:     44 / 99 loss=1.539, ppl=2.91, wps=9340, ups=12.92, wpb=723, bsz=32, num_updates=7370, lr=1.94308e-05, gnorm=2.517, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=969
2021-12-14 02:01:25 | INFO | train_inner | epoch 075:     54 / 99 loss=1.739, ppl=3.34, wps=8742.1, ups=13.54, wpb=645.6, bsz=31.5, num_updates=7380, lr=1.94154e-05, gnorm=2.644, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=970
2021-12-14 02:01:26 | INFO | train_inner | epoch 075:     64 / 99 loss=1.115, ppl=2.17, wps=8690.6, ups=15.47, wpb=561.9, bsz=32, num_updates=7390, lr=1.94e-05, gnorm=2.544, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=970
2021-12-14 02:01:26 | INFO | train_inner | epoch 075:     74 / 99 loss=1.115, ppl=2.17, wps=9208.2, ups=15.41, wpb=597.5, bsz=32, num_updates=7400, lr=1.93846e-05, gnorm=2.555, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=971
2021-12-14 02:01:27 | INFO | train_inner | epoch 075:     84 / 99 loss=1.466, ppl=2.76, wps=11022.1, ups=15.24, wpb=723.3, bsz=32, num_updates=7410, lr=1.93692e-05, gnorm=2.535, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=972
2021-12-14 02:01:28 | INFO | train_inner | epoch 075:     94 / 99 loss=1.144, ppl=2.21, wps=7094.6, ups=12.83, wpb=552.8, bsz=32, num_updates=7420, lr=1.93538e-05, gnorm=2.448, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=973
2021-12-14 02:01:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:01:29 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 2.457 | ppl 5.49 | wps 23709.9 | wpb 586.4 | bsz 31.3 | num_updates 7425 | best_loss 2.424
2021-12-14 02:01:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7425 updates
2021-12-14 02:01:29 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:01:32 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:01:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 75 @ 7425 updates, score 2.457) (writing took 2.623746951809153 seconds)
2021-12-14 02:01:32 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2021-12-14 02:01:32 | INFO | train | epoch 075 | loss 1.355 | ppl 2.56 | wps 5879.6 | ups 9.32 | wpb 630.8 | bsz 31.9 | num_updates 7425 | lr 1.93462e-05 | gnorm 2.469 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.7 | wall 976
2021-12-14 02:01:32 | INFO | fairseq.trainer | begin training epoch 76
2021-12-14 02:01:32 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:01:32 | INFO | train_inner | epoch 076:      5 / 99 loss=1.647, ppl=3.13, wps=1712.7, ups=2.23, wpb=769.5, bsz=32, num_updates=7430, lr=1.93385e-05, gnorm=2.518, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=977
2021-12-14 02:01:33 | INFO | train_inner | epoch 076:     15 / 99 loss=1.102, ppl=2.15, wps=6563.3, ups=11.05, wpb=594.2, bsz=32, num_updates=7440, lr=1.93231e-05, gnorm=2.322, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=978
2021-12-14 02:01:34 | INFO | train_inner | epoch 076:     25 / 99 loss=1.162, ppl=2.24, wps=6217.1, ups=11.73, wpb=530, bsz=32, num_updates=7450, lr=1.93077e-05, gnorm=2.294, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=979
2021-12-14 02:01:35 | INFO | train_inner | epoch 076:     35 / 99 loss=1.133, ppl=2.19, wps=7312.6, ups=12.48, wpb=585.8, bsz=32, num_updates=7460, lr=1.92923e-05, gnorm=2.342, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=980
2021-12-14 02:01:36 | INFO | train_inner | epoch 076:     45 / 99 loss=1.039, ppl=2.06, wps=6912.2, ups=12.57, wpb=550.1, bsz=32, num_updates=7470, lr=1.92769e-05, gnorm=2.481, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=980
2021-12-14 02:01:36 | INFO | train_inner | epoch 076:     55 / 99 loss=1.65, ppl=3.14, wps=8882.6, ups=11.86, wpb=749, bsz=31.5, num_updates=7480, lr=1.92615e-05, gnorm=2.312, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=981
2021-12-14 02:01:37 | INFO | train_inner | epoch 076:     65 / 99 loss=1.615, ppl=3.06, wps=8448.4, ups=11.49, wpb=735.6, bsz=32, num_updates=7490, lr=1.92462e-05, gnorm=2.357, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=982
2021-12-14 02:01:38 | INFO | train_inner | epoch 076:     75 / 99 loss=1.523, ppl=2.87, wps=8857.3, ups=12.3, wpb=720.1, bsz=32, num_updates=7500, lr=1.92308e-05, gnorm=2.683, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=983
2021-12-14 02:01:39 | INFO | train_inner | epoch 076:     85 / 99 loss=1.541, ppl=2.91, wps=9078.4, ups=12.54, wpb=724.1, bsz=32, num_updates=7510, lr=1.92154e-05, gnorm=2.442, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=984
2021-12-14 02:01:40 | INFO | train_inner | epoch 076:     95 / 99 loss=0.976, ppl=1.97, wps=5740.1, ups=10.91, wpb=526.3, bsz=32, num_updates=7520, lr=1.92e-05, gnorm=2.282, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=985
2021-12-14 02:01:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:01:41 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 2.456 | ppl 5.49 | wps 24411.8 | wpb 586.4 | bsz 31.3 | num_updates 7524 | best_loss 2.424
2021-12-14 02:01:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7524 updates
2021-12-14 02:01:41 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:01:44 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:01:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 76 @ 7524 updates, score 2.456) (writing took 2.582185846986249 seconds)
2021-12-14 02:01:44 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2021-12-14 02:01:44 | INFO | train | epoch 076 | loss 1.338 | ppl 2.53 | wps 5248.7 | ups 8.32 | wpb 630.8 | bsz 31.9 | num_updates 7524 | lr 1.91938e-05 | gnorm 2.404 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 988
2021-12-14 02:01:44 | INFO | fairseq.trainer | begin training epoch 77
2021-12-14 02:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:01:44 | INFO | train_inner | epoch 077:      6 / 99 loss=1.132, ppl=2.19, wps=1138.1, ups=2.31, wpb=492.6, bsz=32, num_updates=7530, lr=1.91846e-05, gnorm=2.408, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=989
2021-12-14 02:01:45 | INFO | train_inner | epoch 077:     16 / 99 loss=1.22, ppl=2.33, wps=6872.9, ups=11.12, wpb=618.3, bsz=32, num_updates=7540, lr=1.91692e-05, gnorm=2.465, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=990
2021-12-14 02:01:46 | INFO | train_inner | epoch 077:     26 / 99 loss=1.148, ppl=2.22, wps=7407.6, ups=12.57, wpb=589.5, bsz=32, num_updates=7550, lr=1.91538e-05, gnorm=2.38, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=991
2021-12-14 02:01:47 | INFO | train_inner | epoch 077:     36 / 99 loss=0.714, ppl=1.64, wps=5479, ups=12.56, wpb=436.3, bsz=32, num_updates=7560, lr=1.91385e-05, gnorm=2.214, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=992
2021-12-14 02:01:48 | INFO | train_inner | epoch 077:     46 / 99 loss=1.899, ppl=3.73, wps=9518, ups=11, wpb=865.1, bsz=31.5, num_updates=7570, lr=1.91231e-05, gnorm=2.737, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=992
2021-12-14 02:01:49 | INFO | train_inner | epoch 077:     56 / 99 loss=1.094, ppl=2.13, wps=6732.8, ups=11.27, wpb=597.3, bsz=32, num_updates=7580, lr=1.91077e-05, gnorm=2.32, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=993
2021-12-14 02:01:49 | INFO | train_inner | epoch 077:     66 / 99 loss=1.387, ppl=2.62, wps=7309.8, ups=10.97, wpb=666.3, bsz=32, num_updates=7590, lr=1.90923e-05, gnorm=2.444, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=994
2021-12-14 02:01:50 | INFO | train_inner | epoch 077:     76 / 99 loss=1.251, ppl=2.38, wps=6896.6, ups=10.89, wpb=633.5, bsz=32, num_updates=7600, lr=1.90769e-05, gnorm=2.238, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=995
2021-12-14 02:01:51 | INFO | train_inner | epoch 077:     86 / 99 loss=1.427, ppl=2.69, wps=6933, ups=10.68, wpb=649, bsz=32, num_updates=7610, lr=1.90615e-05, gnorm=2.448, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=996
2021-12-14 02:01:52 | INFO | train_inner | epoch 077:     96 / 99 loss=1.176, ppl=2.26, wps=7669.1, ups=11.77, wpb=651.7, bsz=32, num_updates=7620, lr=1.90462e-05, gnorm=2.469, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=997
2021-12-14 02:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:01:53 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 2.386 | ppl 5.23 | wps 23243.7 | wpb 586.4 | bsz 31.3 | num_updates 7623 | best_loss 2.386
2021-12-14 02:01:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7623 updates
2021-12-14 02:01:53 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:01:56 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:01:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 77 @ 7623 updates, score 2.386) (writing took 3.6790878737811 seconds)
2021-12-14 02:01:57 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2021-12-14 02:01:57 | INFO | train | epoch 077 | loss 1.315 | ppl 2.49 | wps 4687.4 | ups 7.43 | wpb 630.8 | bsz 31.9 | num_updates 7623 | lr 1.90415e-05 | gnorm 2.411 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 1002
2021-12-14 02:01:57 | INFO | fairseq.trainer | begin training epoch 78
2021-12-14 02:01:57 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:01:58 | INFO | train_inner | epoch 078:      7 / 99 loss=1.402, ppl=2.64, wps=1256.6, ups=1.83, wpb=687.8, bsz=32, num_updates=7630, lr=1.90308e-05, gnorm=2.555, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1002
2021-12-14 02:01:58 | INFO | train_inner | epoch 078:     17 / 99 loss=0.997, ppl=2, wps=6287.7, ups=11.82, wpb=531.8, bsz=32, num_updates=7640, lr=1.90154e-05, gnorm=2.229, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1003
2021-12-14 02:01:59 | INFO | train_inner | epoch 078:     27 / 99 loss=1.295, ppl=2.45, wps=8584.1, ups=12.83, wpb=668.9, bsz=32, num_updates=7650, lr=1.9e-05, gnorm=2.503, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=1004
2021-12-14 02:02:00 | INFO | train_inner | epoch 078:     37 / 99 loss=1.311, ppl=2.48, wps=7540.9, ups=11.98, wpb=629.4, bsz=32, num_updates=7660, lr=1.89846e-05, gnorm=2.288, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1005
2021-12-14 02:02:01 | INFO | train_inner | epoch 078:     47 / 99 loss=1.355, ppl=2.56, wps=8429.3, ups=12.01, wpb=701.9, bsz=32, num_updates=7670, lr=1.89692e-05, gnorm=2.411, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1006
2021-12-14 02:02:02 | INFO | train_inner | epoch 078:     57 / 99 loss=1.39, ppl=2.62, wps=7862, ups=12.19, wpb=645.1, bsz=32, num_updates=7680, lr=1.89538e-05, gnorm=2.316, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1007
2021-12-14 02:02:03 | INFO | train_inner | epoch 078:     67 / 99 loss=1.941, ppl=3.84, wps=10223.1, ups=11.09, wpb=921.5, bsz=31.5, num_updates=7690, lr=1.89385e-05, gnorm=2.334, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1007
2021-12-14 02:02:04 | INFO | train_inner | epoch 078:     77 / 99 loss=1.031, ppl=2.04, wps=5754.3, ups=11.26, wpb=510.9, bsz=32, num_updates=7700, lr=1.89231e-05, gnorm=2.444, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1008
2021-12-14 02:02:05 | INFO | train_inner | epoch 078:     87 / 99 loss=1.118, ppl=2.17, wps=5540.9, ups=10.2, wpb=543, bsz=32, num_updates=7710, lr=1.89077e-05, gnorm=2.339, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1009
2021-12-14 02:02:06 | INFO | train_inner | epoch 078:     97 / 99 loss=1.197, ppl=2.29, wps=6441.5, ups=10.48, wpb=614.9, bsz=32, num_updates=7720, lr=1.88923e-05, gnorm=2.381, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1010
2021-12-14 02:02:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:02:07 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 2.394 | ppl 5.26 | wps 20613 | wpb 586.4 | bsz 31.3 | num_updates 7722 | best_loss 2.386
2021-12-14 02:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 7722 updates
2021-12-14 02:02:07 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:02:09 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:02:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 78 @ 7722 updates, score 2.394) (writing took 2.7124380331952125 seconds)
2021-12-14 02:02:09 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2021-12-14 02:02:09 | INFO | train | epoch 078 | loss 1.31 | ppl 2.48 | wps 5027.3 | ups 7.97 | wpb 630.8 | bsz 31.9 | num_updates 7722 | lr 1.88892e-05 | gnorm 2.374 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1014
2021-12-14 02:02:09 | INFO | fairseq.trainer | begin training epoch 79
2021-12-14 02:02:09 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:02:10 | INFO | train_inner | epoch 079:      8 / 99 loss=0.835, ppl=1.78, wps=1067.7, ups=2.2, wpb=486, bsz=32, num_updates=7730, lr=1.88769e-05, gnorm=2.165, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1015
2021-12-14 02:02:11 | INFO | train_inner | epoch 079:     18 / 99 loss=1.653, ppl=3.15, wps=8739.8, ups=12.16, wpb=718.6, bsz=32, num_updates=7740, lr=1.88615e-05, gnorm=2.49, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=1016
2021-12-14 02:02:12 | INFO | train_inner | epoch 079:     28 / 99 loss=0.878, ppl=1.84, wps=6722.1, ups=12.63, wpb=532.4, bsz=32, num_updates=7750, lr=1.88462e-05, gnorm=2.296, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1016
2021-12-14 02:02:13 | INFO | train_inner | epoch 079:     38 / 99 loss=1.486, ppl=2.8, wps=8123.8, ups=11.44, wpb=710.4, bsz=32, num_updates=7760, lr=1.88308e-05, gnorm=2.459, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1017
2021-12-14 02:02:13 | INFO | train_inner | epoch 079:     48 / 99 loss=0.993, ppl=1.99, wps=7115.9, ups=12.38, wpb=574.6, bsz=32, num_updates=7770, lr=1.88154e-05, gnorm=2.356, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1018
2021-12-14 02:02:14 | INFO | train_inner | epoch 079:     58 / 99 loss=1.169, ppl=2.25, wps=8052, ups=12.41, wpb=649, bsz=32, num_updates=7780, lr=1.88e-05, gnorm=2.389, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1019
2021-12-14 02:02:15 | INFO | train_inner | epoch 079:     68 / 99 loss=1.707, ppl=3.26, wps=8628.2, ups=12.57, wpb=686.2, bsz=31.5, num_updates=7790, lr=1.87846e-05, gnorm=2.324, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1020
2021-12-14 02:02:16 | INFO | train_inner | epoch 079:     78 / 99 loss=0.979, ppl=1.97, wps=6709.6, ups=12.19, wpb=550.6, bsz=32, num_updates=7800, lr=1.87692e-05, gnorm=2.277, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1021
2021-12-14 02:02:17 | INFO | train_inner | epoch 079:     88 / 99 loss=1.083, ppl=2.12, wps=7124.7, ups=12.59, wpb=566.1, bsz=32, num_updates=7810, lr=1.87538e-05, gnorm=2.351, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1021
2021-12-14 02:02:17 | INFO | train_inner | epoch 079:     98 / 99 loss=1.502, ppl=2.83, wps=9379.9, ups=12.21, wpb=768.1, bsz=32, num_updates=7820, lr=1.87385e-05, gnorm=2.406, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1022
2021-12-14 02:02:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:02:18 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 2.412 | ppl 5.32 | wps 23948.9 | wpb 586.4 | bsz 31.3 | num_updates 7821 | best_loss 2.386
2021-12-14 02:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 7821 updates
2021-12-14 02:02:18 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:02:21 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:02:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 79 @ 7821 updates, score 2.412) (writing took 2.591290205018595 seconds)
2021-12-14 02:02:21 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2021-12-14 02:02:21 | INFO | train | epoch 079 | loss 1.273 | ppl 2.42 | wps 5409.2 | ups 8.58 | wpb 630.8 | bsz 31.9 | num_updates 7821 | lr 1.87369e-05 | gnorm 2.354 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1026
2021-12-14 02:02:21 | INFO | fairseq.trainer | begin training epoch 80
2021-12-14 02:02:21 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:02:22 | INFO | train_inner | epoch 080:      9 / 99 loss=0.916, ppl=1.89, wps=1428.8, ups=2.41, wpb=592.7, bsz=32, num_updates=7830, lr=1.87231e-05, gnorm=2.205, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1026
2021-12-14 02:02:22 | INFO | train_inner | epoch 080:     19 / 99 loss=0.958, ppl=1.94, wps=6681, ups=12.34, wpb=541.3, bsz=32, num_updates=7840, lr=1.87077e-05, gnorm=2.244, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1027
2021-12-14 02:02:23 | INFO | train_inner | epoch 080:     29 / 99 loss=1.509, ppl=2.85, wps=8242.5, ups=11.21, wpb=735.6, bsz=32, num_updates=7850, lr=1.86923e-05, gnorm=2.513, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=1028
2021-12-14 02:02:24 | INFO | train_inner | epoch 080:     39 / 99 loss=0.958, ppl=1.94, wps=6821, ups=11.85, wpb=575.4, bsz=32, num_updates=7860, lr=1.86769e-05, gnorm=2.382, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1029
2021-12-14 02:02:25 | INFO | train_inner | epoch 080:     49 / 99 loss=1.707, ppl=3.26, wps=9384.1, ups=12.23, wpb=767.3, bsz=31.5, num_updates=7870, lr=1.86615e-05, gnorm=2.465, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1030
2021-12-14 02:02:26 | INFO | train_inner | epoch 080:     59 / 99 loss=1.439, ppl=2.71, wps=7748.5, ups=11.55, wpb=670.7, bsz=32, num_updates=7880, lr=1.86462e-05, gnorm=2.494, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1031
2021-12-14 02:02:27 | INFO | train_inner | epoch 080:     69 / 99 loss=1.06, ppl=2.08, wps=6497.3, ups=11.32, wpb=574, bsz=32, num_updates=7890, lr=1.86308e-05, gnorm=2.422, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1032
2021-12-14 02:02:28 | INFO | train_inner | epoch 080:     79 / 99 loss=1.072, ppl=2.1, wps=6122.3, ups=10.2, wpb=600.4, bsz=32, num_updates=7900, lr=1.86154e-05, gnorm=2.333, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1032
2021-12-14 02:02:29 | INFO | train_inner | epoch 080:     89 / 99 loss=1.319, ppl=2.5, wps=6433.2, ups=10.19, wpb=631.3, bsz=32, num_updates=7910, lr=1.86e-05, gnorm=2.356, clip=100, loss_scale=128, train_wall=1, gb_free=20, wall=1033
2021-12-14 02:02:30 | INFO | train_inner | epoch 080:     99 / 99 loss=1.322, ppl=2.5, wps=6425.7, ups=10.26, wpb=626.3, bsz=32, num_updates=7920, lr=1.85846e-05, gnorm=2.545, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1034
2021-12-14 02:02:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:02:31 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 2.452 | ppl 5.47 | wps 19133.1 | wpb 586.4 | bsz 31.3 | num_updates 7920 | best_loss 2.386
2021-12-14 02:02:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 7920 updates
2021-12-14 02:02:31 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:02:33 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:02:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 80 @ 7920 updates, score 2.452) (writing took 2.707666384987533 seconds)
2021-12-14 02:02:33 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2021-12-14 02:02:33 | INFO | train | epoch 080 | loss 1.256 | ppl 2.39 | wps 5018.5 | ups 7.96 | wpb 630.8 | bsz 31.9 | num_updates 7920 | lr 1.85846e-05 | gnorm 2.396 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1038
2021-12-14 02:02:33 | INFO | fairseq.trainer | begin training epoch 81
2021-12-14 02:02:33 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:02:34 | INFO | train_inner | epoch 081:     10 / 99 loss=1.004, ppl=2.01, wps=1146, ups=2.25, wpb=510.1, bsz=32, num_updates=7930, lr=1.85692e-05, gnorm=2.459, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1039
2021-12-14 02:02:35 | INFO | train_inner | epoch 081:     20 / 99 loss=1.12, ppl=2.17, wps=10219.2, ups=15.01, wpb=680.6, bsz=32, num_updates=7940, lr=1.85538e-05, gnorm=2.261, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1040
2021-12-14 02:02:35 | INFO | train_inner | epoch 081:     30 / 99 loss=1.057, ppl=2.08, wps=8397.7, ups=14.25, wpb=589.3, bsz=32, num_updates=7950, lr=1.85385e-05, gnorm=2.404, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1040
2021-12-14 02:02:36 | INFO | train_inner | epoch 081:     40 / 99 loss=1.574, ppl=2.98, wps=9450.9, ups=12.32, wpb=767.4, bsz=32, num_updates=7960, lr=1.85231e-05, gnorm=2.481, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1041
2021-12-14 02:02:37 | INFO | train_inner | epoch 081:     50 / 99 loss=1.344, ppl=2.54, wps=6727.4, ups=11.24, wpb=598.3, bsz=32, num_updates=7970, lr=1.85077e-05, gnorm=2.435, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1042
2021-12-14 02:02:38 | INFO | train_inner | epoch 081:     60 / 99 loss=0.812, ppl=1.76, wps=6662.3, ups=12.82, wpb=519.5, bsz=32, num_updates=7980, lr=1.84923e-05, gnorm=2.287, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1043
2021-12-14 02:02:39 | INFO | train_inner | epoch 081:     70 / 99 loss=0.9, ppl=1.87, wps=6149.2, ups=12.06, wpb=509.8, bsz=32, num_updates=7990, lr=1.84769e-05, gnorm=2.217, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1044
2021-12-14 02:02:40 | INFO | train_inner | epoch 081:     80 / 99 loss=1.74, ppl=3.34, wps=8138.4, ups=11.58, wpb=702.5, bsz=31.5, num_updates=8000, lr=1.84615e-05, gnorm=2.242, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1044
2021-12-14 02:02:41 | INFO | train_inner | epoch 081:     90 / 99 loss=1.256, ppl=2.39, wps=8539.8, ups=11.96, wpb=713.8, bsz=32, num_updates=8010, lr=1.84462e-05, gnorm=2.41, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1045
2021-12-14 02:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:02:42 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 2.321 | ppl 5 | wps 19501 | wpb 586.4 | bsz 31.3 | num_updates 8019 | best_loss 2.321
2021-12-14 02:02:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 8019 updates
2021-12-14 02:02:42 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:02:45 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:02:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 81 @ 8019 updates, score 2.321) (writing took 3.6366013451479375 seconds)
2021-12-14 02:02:46 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2021-12-14 02:02:46 | INFO | train | epoch 081 | loss 1.235 | ppl 2.35 | wps 5002 | ups 7.93 | wpb 630.8 | bsz 31.9 | num_updates 8019 | lr 1.84323e-05 | gnorm 2.358 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1051
2021-12-14 02:02:46 | INFO | fairseq.trainer | begin training epoch 82
2021-12-14 02:02:46 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:02:46 | INFO | train_inner | epoch 082:      1 / 99 loss=1.228, ppl=2.34, wps=1365.1, ups=1.83, wpb=747.5, bsz=32, num_updates=8020, lr=1.84308e-05, gnorm=2.384, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1051
2021-12-14 02:02:47 | INFO | train_inner | epoch 082:     11 / 99 loss=1.433, ppl=2.7, wps=8542.9, ups=13.33, wpb=641, bsz=32, num_updates=8030, lr=1.84154e-05, gnorm=2.503, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1052
2021-12-14 02:02:47 | INFO | train_inner | epoch 082:     21 / 99 loss=1.307, ppl=2.47, wps=9319, ups=13.31, wpb=700.4, bsz=32, num_updates=8040, lr=1.84e-05, gnorm=2.309, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1052
2021-12-14 02:02:48 | INFO | train_inner | epoch 082:     31 / 99 loss=0.922, ppl=1.89, wps=6389.4, ups=12.63, wpb=505.8, bsz=32, num_updates=8050, lr=1.83846e-05, gnorm=2.328, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1053
2021-12-14 02:02:49 | INFO | train_inner | epoch 082:     41 / 99 loss=0.848, ppl=1.8, wps=7759.3, ups=14.12, wpb=549.4, bsz=32, num_updates=8060, lr=1.83692e-05, gnorm=2.245, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1054
2021-12-14 02:02:50 | INFO | train_inner | epoch 082:     51 / 99 loss=1.305, ppl=2.47, wps=11059.7, ups=15.3, wpb=722.9, bsz=32, num_updates=8070, lr=1.83538e-05, gnorm=2.551, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1054
2021-12-14 02:02:50 | INFO | train_inner | epoch 082:     61 / 99 loss=1.086, ppl=2.12, wps=8333.3, ups=15.36, wpb=542.7, bsz=32, num_updates=8080, lr=1.83385e-05, gnorm=2.229, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1055
2021-12-14 02:02:51 | INFO | train_inner | epoch 082:     71 / 99 loss=1.008, ppl=2.01, wps=7730.7, ups=13.65, wpb=566.4, bsz=32, num_updates=8090, lr=1.83231e-05, gnorm=2.657, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1056
2021-12-14 02:02:52 | INFO | train_inner | epoch 082:     81 / 99 loss=1.214, ppl=2.32, wps=6700, ups=10.25, wpb=653.5, bsz=32, num_updates=8100, lr=1.83077e-05, gnorm=2.317, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1057
2021-12-14 02:02:53 | INFO | train_inner | epoch 082:     91 / 99 loss=1.816, ppl=3.52, wps=9553.2, ups=11.23, wpb=850.7, bsz=31.5, num_updates=8110, lr=1.82923e-05, gnorm=2.471, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=1058
2021-12-14 02:02:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:02:55 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 2.342 | ppl 5.07 | wps 23300.7 | wpb 586.4 | bsz 31.3 | num_updates 8118 | best_loss 2.321
2021-12-14 02:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 8118 updates
2021-12-14 02:02:55 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:02:57 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 82 @ 8118 updates, score 2.342) (writing took 3.010668087983504 seconds)
2021-12-14 02:02:58 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2021-12-14 02:02:58 | INFO | train | epoch 082 | loss 1.226 | ppl 2.34 | wps 5336 | ups 8.46 | wpb 630.8 | bsz 31.9 | num_updates 8118 | lr 1.828e-05 | gnorm 2.396 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.7 | wall 1062
2021-12-14 02:02:58 | INFO | fairseq.trainer | begin training epoch 83
2021-12-14 02:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:02:59 | INFO | train_inner | epoch 083:      2 / 99 loss=0.804, ppl=1.75, wps=891.5, ups=1.75, wpb=510.3, bsz=32, num_updates=8120, lr=1.82769e-05, gnorm=2.273, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1063
2021-12-14 02:02:59 | INFO | train_inner | epoch 083:     12 / 99 loss=1.101, ppl=2.15, wps=7389.8, ups=11.88, wpb=622.1, bsz=32, num_updates=8130, lr=1.82615e-05, gnorm=2.364, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1064
2021-12-14 02:03:00 | INFO | train_inner | epoch 083:     22 / 99 loss=1.815, ppl=3.52, wps=8397.4, ups=10.34, wpb=812.3, bsz=31.5, num_updates=8140, lr=1.82462e-05, gnorm=2.262, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1065
2021-12-14 02:03:01 | INFO | train_inner | epoch 083:     32 / 99 loss=1.343, ppl=2.54, wps=9319, ups=13.1, wpb=711.6, bsz=32, num_updates=8150, lr=1.82308e-05, gnorm=2.464, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1066
2021-12-14 02:03:02 | INFO | train_inner | epoch 083:     42 / 99 loss=1.386, ppl=2.61, wps=8025.8, ups=12.54, wpb=639.8, bsz=32, num_updates=8160, lr=1.82154e-05, gnorm=2.762, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1067
2021-12-14 02:03:03 | INFO | train_inner | epoch 083:     52 / 99 loss=1.001, ppl=2, wps=7533.8, ups=12.79, wpb=588.9, bsz=32, num_updates=8170, lr=1.82e-05, gnorm=2.426, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1068
2021-12-14 02:03:04 | INFO | train_inner | epoch 083:     62 / 99 loss=1.302, ppl=2.47, wps=7938.8, ups=13.06, wpb=607.8, bsz=32, num_updates=8180, lr=1.81846e-05, gnorm=2.334, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1068
2021-12-14 02:03:04 | INFO | train_inner | epoch 083:     72 / 99 loss=0.767, ppl=1.7, wps=5928.3, ups=11.35, wpb=522.3, bsz=32, num_updates=8190, lr=1.81692e-05, gnorm=2.115, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1069
2021-12-14 02:03:05 | INFO | train_inner | epoch 083:     82 / 99 loss=0.959, ppl=1.94, wps=6672.2, ups=12.27, wpb=543.6, bsz=32, num_updates=8200, lr=1.81538e-05, gnorm=2.312, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1070
2021-12-14 02:03:06 | INFO | train_inner | epoch 083:     92 / 99 loss=1.154, ppl=2.23, wps=6991.8, ups=11.94, wpb=585.6, bsz=32, num_updates=8210, lr=1.81385e-05, gnorm=2.523, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1071
2021-12-14 02:03:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:03:08 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 2.34 | ppl 5.06 | wps 24175.4 | wpb 586.4 | bsz 31.3 | num_updates 8217 | best_loss 2.321
2021-12-14 02:03:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 8217 updates
2021-12-14 02:03:08 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:03:10 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:03:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 83 @ 8217 updates, score 2.34) (writing took 2.8394607480149716 seconds)
2021-12-14 02:03:10 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2021-12-14 02:03:10 | INFO | train | epoch 083 | loss 1.223 | ppl 2.33 | wps 5196.2 | ups 8.24 | wpb 630.8 | bsz 31.9 | num_updates 8217 | lr 1.81277e-05 | gnorm 2.379 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1075
2021-12-14 02:03:10 | INFO | fairseq.trainer | begin training epoch 84
2021-12-14 02:03:10 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:03:11 | INFO | train_inner | epoch 084:      3 / 99 loss=0.999, ppl=2, wps=1424.9, ups=2.18, wpb=653.2, bsz=32, num_updates=8220, lr=1.81231e-05, gnorm=2.312, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1076
2021-12-14 02:03:12 | INFO | train_inner | epoch 084:     13 / 99 loss=1.491, ppl=2.81, wps=7184.8, ups=10.99, wpb=653.6, bsz=31.5, num_updates=8230, lr=1.81077e-05, gnorm=2.381, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1076
2021-12-14 02:03:12 | INFO | train_inner | epoch 084:     23 / 99 loss=1.52, ppl=2.87, wps=9632.7, ups=12.7, wpb=758.7, bsz=32, num_updates=8240, lr=1.80923e-05, gnorm=2.341, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=1077
2021-12-14 02:03:13 | INFO | train_inner | epoch 084:     33 / 99 loss=0.943, ppl=1.92, wps=6318.5, ups=11.75, wpb=537.6, bsz=32, num_updates=8250, lr=1.80769e-05, gnorm=2.441, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1078
2021-12-14 02:03:14 | INFO | train_inner | epoch 084:     43 / 99 loss=1.146, ppl=2.21, wps=7216.7, ups=11.28, wpb=639.8, bsz=32, num_updates=8260, lr=1.80615e-05, gnorm=2.15, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1079
2021-12-14 02:03:15 | INFO | train_inner | epoch 084:     53 / 99 loss=1.052, ppl=2.07, wps=5975.6, ups=10.44, wpb=572.5, bsz=32, num_updates=8270, lr=1.80462e-05, gnorm=2.224, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1080
2021-12-14 02:03:16 | INFO | train_inner | epoch 084:     63 / 99 loss=0.923, ppl=1.9, wps=6567.9, ups=10.92, wpb=601.7, bsz=32, num_updates=8280, lr=1.80308e-05, gnorm=2.293, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=1081
2021-12-14 02:03:17 | INFO | train_inner | epoch 084:     73 / 99 loss=1.019, ppl=2.03, wps=5959.8, ups=10.68, wpb=558, bsz=32, num_updates=8290, lr=1.80154e-05, gnorm=2.427, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1082
2021-12-14 02:03:18 | INFO | train_inner | epoch 084:     83 / 99 loss=1.569, ppl=2.97, wps=8729.2, ups=10.88, wpb=802.5, bsz=32, num_updates=8300, lr=1.8e-05, gnorm=2.391, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1083
2021-12-14 02:03:19 | INFO | train_inner | epoch 084:     93 / 99 loss=1.065, ppl=2.09, wps=6825.3, ups=11.04, wpb=618.5, bsz=32, num_updates=8310, lr=1.79846e-05, gnorm=2.548, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1084
2021-12-14 02:03:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:03:20 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 2.341 | ppl 5.07 | wps 24308 | wpb 586.4 | bsz 31.3 | num_updates 8316 | best_loss 2.321
2021-12-14 02:03:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8316 updates
2021-12-14 02:03:20 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:03:23 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:03:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 84 @ 8316 updates, score 2.341) (writing took 2.575938685098663 seconds)
2021-12-14 02:03:23 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2021-12-14 02:03:23 | INFO | train | epoch 084 | loss 1.198 | ppl 2.29 | wps 5054.1 | ups 8.01 | wpb 630.8 | bsz 31.9 | num_updates 8316 | lr 1.79754e-05 | gnorm 2.355 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 1088
2021-12-14 02:03:23 | INFO | fairseq.trainer | begin training epoch 85
2021-12-14 02:03:23 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:03:23 | INFO | train_inner | epoch 085:      4 / 99 loss=0.911, ppl=1.88, wps=1259, ups=2.28, wpb=552, bsz=32, num_updates=8320, lr=1.79692e-05, gnorm=2.261, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1088
2021-12-14 02:03:24 | INFO | train_inner | epoch 085:     14 / 99 loss=0.952, ppl=1.94, wps=6320.4, ups=12.75, wpb=495.6, bsz=32, num_updates=8330, lr=1.79538e-05, gnorm=2.414, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1089
2021-12-14 02:03:25 | INFO | train_inner | epoch 085:     24 / 99 loss=1.315, ppl=2.49, wps=8387.1, ups=12.12, wpb=692.2, bsz=32, num_updates=8340, lr=1.79385e-05, gnorm=2.298, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1090
2021-12-14 02:03:26 | INFO | train_inner | epoch 085:     34 / 99 loss=1.341, ppl=2.53, wps=8608, ups=11.29, wpb=762.2, bsz=32, num_updates=8350, lr=1.79231e-05, gnorm=2.287, clip=100, loss_scale=128, train_wall=1, gb_free=20.3, wall=1091
2021-12-14 02:03:27 | INFO | train_inner | epoch 085:     44 / 99 loss=1.239, ppl=2.36, wps=8771.1, ups=12.45, wpb=704.5, bsz=32, num_updates=8360, lr=1.79077e-05, gnorm=2.609, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1091
2021-12-14 02:03:27 | INFO | train_inner | epoch 085:     54 / 99 loss=1.526, ppl=2.88, wps=9001.1, ups=12.51, wpb=719.3, bsz=32, num_updates=8370, lr=1.78923e-05, gnorm=2.427, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1092
2021-12-14 02:03:28 | INFO | train_inner | epoch 085:     64 / 99 loss=0.893, ppl=1.86, wps=5593.9, ups=10.94, wpb=511.1, bsz=32, num_updates=8380, lr=1.78769e-05, gnorm=2.34, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1093
2021-12-14 02:03:29 | INFO | train_inner | epoch 085:     74 / 99 loss=1.463, ppl=2.76, wps=8173.8, ups=11.93, wpb=685.1, bsz=31.5, num_updates=8390, lr=1.78615e-05, gnorm=2.276, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1094
2021-12-14 02:03:30 | INFO | train_inner | epoch 085:     84 / 99 loss=1.139, ppl=2.2, wps=7925.2, ups=12.04, wpb=658, bsz=32, num_updates=8400, lr=1.78462e-05, gnorm=2.56, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=1095
2021-12-14 02:03:31 | INFO | train_inner | epoch 085:     94 / 99 loss=0.608, ppl=1.52, wps=4532, ups=9.96, wpb=454.9, bsz=32, num_updates=8410, lr=1.78308e-05, gnorm=2.226, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1096
2021-12-14 02:03:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:03:32 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 2.347 | ppl 5.09 | wps 22283.7 | wpb 586.4 | bsz 31.3 | num_updates 8415 | best_loss 2.321
2021-12-14 02:03:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8415 updates
2021-12-14 02:03:32 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:03:35 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:03:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 85 @ 8415 updates, score 2.347) (writing took 2.8313221300486475 seconds)
2021-12-14 02:03:35 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2021-12-14 02:03:35 | INFO | train | epoch 085 | loss 1.182 | ppl 2.27 | wps 5066.1 | ups 8.03 | wpb 630.8 | bsz 31.9 | num_updates 8415 | lr 1.78231e-05 | gnorm 2.37 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1100
2021-12-14 02:03:35 | INFO | fairseq.trainer | begin training epoch 86
2021-12-14 02:03:35 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:03:36 | INFO | train_inner | epoch 086:      5 / 99 loss=1.066, ppl=2.09, wps=1486.3, ups=2.15, wpb=690.1, bsz=32, num_updates=8420, lr=1.78154e-05, gnorm=2.338, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1100
2021-12-14 02:03:36 | INFO | train_inner | epoch 086:     15 / 99 loss=1.24, ppl=2.36, wps=7435.4, ups=13.11, wpb=567, bsz=32, num_updates=8430, lr=1.78e-05, gnorm=2.323, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1101
2021-12-14 02:03:37 | INFO | train_inner | epoch 086:     25 / 99 loss=1.166, ppl=2.24, wps=8436.4, ups=12.81, wpb=658.4, bsz=32, num_updates=8440, lr=1.77846e-05, gnorm=2.34, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1102
2021-12-14 02:03:38 | INFO | train_inner | epoch 086:     35 / 99 loss=1.089, ppl=2.13, wps=7884.3, ups=11.76, wpb=670.5, bsz=32, num_updates=8450, lr=1.77692e-05, gnorm=2.287, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1103
2021-12-14 02:03:39 | INFO | train_inner | epoch 086:     45 / 99 loss=1.34, ppl=2.53, wps=8730.6, ups=12.27, wpb=711.8, bsz=32, num_updates=8460, lr=1.77538e-05, gnorm=2.287, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1104
2021-12-14 02:03:40 | INFO | train_inner | epoch 086:     55 / 99 loss=1.404, ppl=2.65, wps=8526.2, ups=12.28, wpb=694.2, bsz=32, num_updates=8470, lr=1.77385e-05, gnorm=2.463, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1104
2021-12-14 02:03:40 | INFO | train_inner | epoch 086:     65 / 99 loss=0.805, ppl=1.75, wps=7468.1, ups=13.44, wpb=555.5, bsz=32, num_updates=8480, lr=1.77231e-05, gnorm=2.301, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1105
2021-12-14 02:03:41 | INFO | train_inner | epoch 086:     75 / 99 loss=0.957, ppl=1.94, wps=8188, ups=14.05, wpb=582.6, bsz=32, num_updates=8490, lr=1.77077e-05, gnorm=2.217, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=1106
2021-12-14 02:03:42 | INFO | train_inner | epoch 086:     85 / 99 loss=1.023, ppl=2.03, wps=6340.5, ups=12.64, wpb=501.6, bsz=32, num_updates=8500, lr=1.76923e-05, gnorm=2.577, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1107
2021-12-14 02:03:43 | INFO | train_inner | epoch 086:     95 / 99 loss=0.884, ppl=1.85, wps=7477.7, ups=12.33, wpb=606.4, bsz=32, num_updates=8510, lr=1.76769e-05, gnorm=2.309, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1107
2021-12-14 02:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:03:44 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 2.375 | ppl 5.19 | wps 23250 | wpb 586.4 | bsz 31.3 | num_updates 8514 | best_loss 2.321
2021-12-14 02:03:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8514 updates
2021-12-14 02:03:44 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:03:47 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:03:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 86 @ 8514 updates, score 2.375) (writing took 2.729171282844618 seconds)
2021-12-14 02:03:47 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2021-12-14 02:03:47 | INFO | train | epoch 086 | loss 1.174 | ppl 2.26 | wps 5432.9 | ups 8.61 | wpb 630.8 | bsz 31.9 | num_updates 8514 | lr 1.76708e-05 | gnorm 2.354 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.7 | wall 1111
2021-12-14 02:03:47 | INFO | fairseq.trainer | begin training epoch 87
2021-12-14 02:03:47 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:03:47 | INFO | train_inner | epoch 087:      6 / 99 loss=1.539, ppl=2.9, wps=1701.8, ups=2.24, wpb=759.8, bsz=31.5, num_updates=8520, lr=1.76615e-05, gnorm=2.427, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1112
2021-12-14 02:03:48 | INFO | train_inner | epoch 087:     16 / 99 loss=1.46, ppl=2.75, wps=9354.4, ups=12.87, wpb=726.8, bsz=32, num_updates=8530, lr=1.76462e-05, gnorm=2.224, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1113
2021-12-14 02:03:49 | INFO | train_inner | epoch 087:     26 / 99 loss=0.944, ppl=1.92, wps=7508.6, ups=13.32, wpb=563.9, bsz=32, num_updates=8540, lr=1.76308e-05, gnorm=2.197, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1113
2021-12-14 02:03:49 | INFO | train_inner | epoch 087:     36 / 99 loss=1.061, ppl=2.09, wps=8444.1, ups=13.5, wpb=625.7, bsz=32, num_updates=8550, lr=1.76154e-05, gnorm=2.088, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=1114
2021-12-14 02:03:50 | INFO | train_inner | epoch 087:     46 / 99 loss=0.872, ppl=1.83, wps=6544.8, ups=13.11, wpb=499.2, bsz=32, num_updates=8560, lr=1.76e-05, gnorm=2.013, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1115
2021-12-14 02:03:51 | INFO | train_inner | epoch 087:     56 / 99 loss=0.855, ppl=1.81, wps=7146.1, ups=13.37, wpb=534.4, bsz=32, num_updates=8570, lr=1.75846e-05, gnorm=2.273, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1116
2021-12-14 02:03:52 | INFO | train_inner | epoch 087:     66 / 99 loss=0.953, ppl=1.94, wps=8529.8, ups=13.65, wpb=624.8, bsz=32, num_updates=8580, lr=1.75692e-05, gnorm=2.376, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1116
2021-12-14 02:03:52 | INFO | train_inner | epoch 087:     76 / 99 loss=1.623, ppl=3.08, wps=10539.6, ups=13.36, wpb=789.1, bsz=31.5, num_updates=8590, lr=1.75538e-05, gnorm=2.362, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=1117
2021-12-14 02:03:53 | INFO | train_inner | epoch 087:     86 / 99 loss=0.892, ppl=1.86, wps=8003.5, ups=13.51, wpb=592.5, bsz=32, num_updates=8600, lr=1.75385e-05, gnorm=2.303, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1118
2021-12-14 02:03:54 | INFO | train_inner | epoch 087:     96 / 99 loss=1.155, ppl=2.23, wps=7124.6, ups=10.82, wpb=658.4, bsz=32, num_updates=8610, lr=1.75231e-05, gnorm=2.53, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1119
2021-12-14 02:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:03:55 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 2.331 | ppl 5.03 | wps 20126.3 | wpb 586.4 | bsz 31.3 | num_updates 8613 | best_loss 2.321
2021-12-14 02:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8613 updates
2021-12-14 02:03:55 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:03:58 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:03:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 87 @ 8613 updates, score 2.331) (writing took 2.702915756031871 seconds)
2021-12-14 02:03:58 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2021-12-14 02:03:58 | INFO | train | epoch 087 | loss 1.133 | ppl 2.19 | wps 5450.4 | ups 8.64 | wpb 630.8 | bsz 31.9 | num_updates 8613 | lr 1.75185e-05 | gnorm 2.276 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.2 | wall 1123
2021-12-14 02:03:58 | INFO | fairseq.trainer | begin training epoch 88
2021-12-14 02:03:58 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:03:59 | INFO | train_inner | epoch 088:      7 / 99 loss=1.393, ppl=2.63, wps=1472, ups=2.23, wpb=659.4, bsz=32, num_updates=8620, lr=1.75077e-05, gnorm=2.255, clip=100, loss_scale=128, train_wall=1, gb_free=20, wall=1123
2021-12-14 02:03:59 | INFO | train_inner | epoch 088:     17 / 99 loss=1.137, ppl=2.2, wps=10706.6, ups=14.05, wpb=762.1, bsz=32, num_updates=8630, lr=1.74923e-05, gnorm=2.255, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1124
2021-12-14 02:04:00 | INFO | train_inner | epoch 088:     27 / 99 loss=1.519, ppl=2.87, wps=10712.4, ups=14.35, wpb=746.6, bsz=31.5, num_updates=8640, lr=1.74769e-05, gnorm=2.308, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1125
2021-12-14 02:04:01 | INFO | train_inner | epoch 088:     37 / 99 loss=1.056, ppl=2.08, wps=8461.4, ups=12.79, wpb=661.8, bsz=32, num_updates=8650, lr=1.74615e-05, gnorm=2.32, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1126
2021-12-14 02:04:02 | INFO | train_inner | epoch 088:     47 / 99 loss=1.309, ppl=2.48, wps=9316.4, ups=12.69, wpb=734.1, bsz=32, num_updates=8660, lr=1.74462e-05, gnorm=2.408, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=1126
2021-12-14 02:04:02 | INFO | train_inner | epoch 088:     57 / 99 loss=0.839, ppl=1.79, wps=7322.9, ups=12.66, wpb=578.3, bsz=32, num_updates=8670, lr=1.74308e-05, gnorm=2.196, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1127
2021-12-14 02:04:03 | INFO | train_inner | epoch 088:     67 / 99 loss=0.618, ppl=1.54, wps=4875.9, ups=11.46, wpb=425.3, bsz=32, num_updates=8680, lr=1.74154e-05, gnorm=2.2, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1128
2021-12-14 02:04:04 | INFO | train_inner | epoch 088:     77 / 99 loss=1.282, ppl=2.43, wps=9175.7, ups=13.06, wpb=702.4, bsz=32, num_updates=8690, lr=1.74e-05, gnorm=2.33, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1129
2021-12-14 02:04:05 | INFO | train_inner | epoch 088:     87 / 99 loss=0.862, ppl=1.82, wps=7099.1, ups=13.96, wpb=508.5, bsz=32, num_updates=8700, lr=1.73846e-05, gnorm=2.521, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1130
2021-12-14 02:04:06 | INFO | train_inner | epoch 088:     97 / 99 loss=1.165, ppl=2.24, wps=7100.9, ups=11.23, wpb=632.3, bsz=32, num_updates=8710, lr=1.73692e-05, gnorm=2.345, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1130
2021-12-14 02:04:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:04:07 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 2.406 | ppl 5.3 | wps 21027 | wpb 586.4 | bsz 31.3 | num_updates 8712 | best_loss 2.321
2021-12-14 02:04:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 8712 updates
2021-12-14 02:04:07 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:04:09 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:04:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 88 @ 8712 updates, score 2.406) (writing took 2.6855487471912056 seconds)
2021-12-14 02:04:09 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2021-12-14 02:04:09 | INFO | train | epoch 088 | loss 1.126 | ppl 2.18 | wps 5496.1 | ups 8.71 | wpb 630.8 | bsz 31.9 | num_updates 8712 | lr 1.73662e-05 | gnorm 2.304 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 1134
2021-12-14 02:04:09 | INFO | fairseq.trainer | begin training epoch 89
2021-12-14 02:04:09 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:04:10 | INFO | train_inner | epoch 089:      8 / 99 loss=0.84, ppl=1.79, wps=1112, ups=2.15, wpb=517.1, bsz=32, num_updates=8720, lr=1.73538e-05, gnorm=2.424, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1135
2021-12-14 02:04:11 | INFO | train_inner | epoch 089:     18 / 99 loss=1.618, ppl=3.07, wps=7906.8, ups=10.76, wpb=735, bsz=31.5, num_updates=8730, lr=1.73385e-05, gnorm=2.329, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1136
2021-12-14 02:04:12 | INFO | train_inner | epoch 089:     28 / 99 loss=1.034, ppl=2.05, wps=8685.2, ups=12.34, wpb=703.6, bsz=32, num_updates=8740, lr=1.73231e-05, gnorm=2.258, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1137
2021-12-14 02:04:13 | INFO | train_inner | epoch 089:     38 / 99 loss=1.156, ppl=2.23, wps=6689.5, ups=10.63, wpb=629.6, bsz=32, num_updates=8750, lr=1.73077e-05, gnorm=2.208, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1138
2021-12-14 02:04:14 | INFO | train_inner | epoch 089:     48 / 99 loss=1.502, ppl=2.83, wps=8640.4, ups=12.21, wpb=707.9, bsz=32, num_updates=8760, lr=1.72923e-05, gnorm=2.458, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1139
2021-12-14 02:04:15 | INFO | train_inner | epoch 089:     58 / 99 loss=0.737, ppl=1.67, wps=4805.7, ups=10.25, wpb=468.7, bsz=32, num_updates=8770, lr=1.72769e-05, gnorm=2.225, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1140
2021-12-14 02:04:16 | INFO | train_inner | epoch 089:     68 / 99 loss=1.096, ppl=2.14, wps=6846.7, ups=10.6, wpb=645.8, bsz=32, num_updates=8780, lr=1.72615e-05, gnorm=2.327, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=1141
2021-12-14 02:04:17 | INFO | train_inner | epoch 089:     78 / 99 loss=1.013, ppl=2.02, wps=6844, ups=9.82, wpb=696.7, bsz=32, num_updates=8790, lr=1.72462e-05, gnorm=2.358, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1142
2021-12-14 02:04:18 | INFO | train_inner | epoch 089:     88 / 99 loss=0.869, ppl=1.83, wps=6282.2, ups=10.84, wpb=579.8, bsz=32, num_updates=8800, lr=1.72308e-05, gnorm=2.267, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1142
2021-12-14 02:04:19 | INFO | train_inner | epoch 089:     98 / 99 loss=0.813, ppl=1.76, wps=5269.7, ups=10.13, wpb=520.3, bsz=32, num_updates=8810, lr=1.72154e-05, gnorm=2.169, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1143
2021-12-14 02:04:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:04:20 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 2.31 | ppl 4.96 | wps 19464.7 | wpb 586.4 | bsz 31.3 | num_updates 8811 | best_loss 2.31
2021-12-14 02:04:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 8811 updates
2021-12-14 02:04:20 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:04:22 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:04:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 89 @ 8811 updates, score 2.31) (writing took 5.167377511039376 seconds)
2021-12-14 02:04:25 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2021-12-14 02:04:27 | INFO | train | epoch 089 | loss 1.127 | ppl 2.18 | wps 4034.1 | ups 6.4 | wpb 630.8 | bsz 31.9 | num_updates 8811 | lr 1.72138e-05 | gnorm 2.308 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.2 | wall 1150
2021-12-14 02:04:27 | INFO | fairseq.trainer | begin training epoch 90
2021-12-14 02:04:27 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:04:27 | INFO | train_inner | epoch 090:      9 / 99 loss=1.392, ppl=2.62, wps=790.2, ups=1.14, wpb=695, bsz=32, num_updates=8820, lr=1.72e-05, gnorm=2.214, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1152
2021-12-14 02:04:28 | INFO | train_inner | epoch 090:     19 / 99 loss=0.944, ppl=1.92, wps=8735.6, ups=13.63, wpb=641, bsz=32, num_updates=8830, lr=1.71846e-05, gnorm=2.142, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1153
2021-12-14 02:04:29 | INFO | train_inner | epoch 090:     29 / 99 loss=1.115, ppl=2.17, wps=6586.7, ups=13.26, wpb=496.8, bsz=32, num_updates=8840, lr=1.71692e-05, gnorm=2.215, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1154
2021-12-14 02:04:30 | INFO | train_inner | epoch 090:     39 / 99 loss=0.704, ppl=1.63, wps=6717.8, ups=13.38, wpb=502, bsz=32, num_updates=8850, lr=1.71538e-05, gnorm=2.214, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1154
2021-12-14 02:04:30 | INFO | train_inner | epoch 090:     49 / 99 loss=0.956, ppl=1.94, wps=8484.4, ups=13.41, wpb=632.7, bsz=32, num_updates=8860, lr=1.71385e-05, gnorm=2.446, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1155
2021-12-14 02:04:31 | INFO | train_inner | epoch 090:     59 / 99 loss=0.87, ppl=1.83, wps=8384.3, ups=13.42, wpb=624.7, bsz=32, num_updates=8870, lr=1.71231e-05, gnorm=2.282, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1156
2021-12-14 02:04:32 | INFO | train_inner | epoch 090:     69 / 99 loss=1.424, ppl=2.68, wps=8714.8, ups=12.8, wpb=680.7, bsz=31.5, num_updates=8880, lr=1.71077e-05, gnorm=2.198, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1157
2021-12-14 02:04:33 | INFO | train_inner | epoch 090:     79 / 99 loss=1.198, ppl=2.29, wps=7730.2, ups=12.18, wpb=634.9, bsz=32, num_updates=8890, lr=1.70923e-05, gnorm=2.193, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1158
2021-12-14 02:04:34 | INFO | train_inner | epoch 090:     89 / 99 loss=1.128, ppl=2.19, wps=9440.4, ups=12.59, wpb=749.7, bsz=32, num_updates=8900, lr=1.70769e-05, gnorm=2.262, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1158
2021-12-14 02:04:35 | INFO | train_inner | epoch 090:     99 / 99 loss=1.3, ppl=2.46, wps=6984.3, ups=9.79, wpb=713.6, bsz=32, num_updates=8910, lr=1.70615e-05, gnorm=2.465, clip=100, loss_scale=128, train_wall=1, gb_free=19.8, wall=1159
2021-12-14 02:04:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:04:35 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 2.333 | ppl 5.04 | wps 23093.3 | wpb 586.4 | bsz 31.3 | num_updates 8910 | best_loss 2.31
2021-12-14 02:04:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 8910 updates
2021-12-14 02:04:35 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:04:38 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:04:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 90 @ 8910 updates, score 2.333) (writing took 2.702603739919141 seconds)
2021-12-14 02:04:38 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2021-12-14 02:04:38 | INFO | train | epoch 090 | loss 1.1 | ppl 2.14 | wps 5389.8 | ups 8.54 | wpb 630.8 | bsz 31.9 | num_updates 8910 | lr 1.70615e-05 | gnorm 2.259 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 19.8 | wall 1163
2021-12-14 02:04:38 | INFO | fairseq.trainer | begin training epoch 91
2021-12-14 02:04:38 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:04:39 | INFO | train_inner | epoch 091:     10 / 99 loss=1.002, ppl=2, wps=1351.8, ups=2.26, wpb=598.2, bsz=32, num_updates=8920, lr=1.70462e-05, gnorm=2.14, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1164
2021-12-14 02:04:40 | INFO | train_inner | epoch 091:     20 / 99 loss=1.115, ppl=2.17, wps=9719.2, ups=13.08, wpb=742.9, bsz=32, num_updates=8930, lr=1.70308e-05, gnorm=2.285, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1165
2021-12-14 02:04:41 | INFO | train_inner | epoch 091:     30 / 99 loss=1.457, ppl=2.74, wps=8170, ups=12.2, wpb=669.6, bsz=31.5, num_updates=8940, lr=1.70154e-05, gnorm=2.137, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=1165
2021-12-14 02:04:41 | INFO | train_inner | epoch 091:     40 / 99 loss=0.827, ppl=1.77, wps=6954.2, ups=13.28, wpb=523.6, bsz=32, num_updates=8950, lr=1.7e-05, gnorm=2.097, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1166
2021-12-14 02:04:42 | INFO | train_inner | epoch 091:     50 / 99 loss=1.342, ppl=2.54, wps=10099.4, ups=13.41, wpb=753.2, bsz=32, num_updates=8960, lr=1.69846e-05, gnorm=2.408, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1167
2021-12-14 02:04:43 | INFO | train_inner | epoch 091:     60 / 99 loss=0.857, ppl=1.81, wps=7394.1, ups=14.44, wpb=512, bsz=32, num_updates=8970, lr=1.69692e-05, gnorm=2.237, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1168
2021-12-14 02:04:44 | INFO | train_inner | epoch 091:     70 / 99 loss=0.892, ppl=1.86, wps=7724.3, ups=13.49, wpb=572.4, bsz=32, num_updates=8980, lr=1.69538e-05, gnorm=2.383, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1168
2021-12-14 02:04:44 | INFO | train_inner | epoch 091:     80 / 99 loss=1.296, ppl=2.46, wps=11011.2, ups=14.57, wpb=755.5, bsz=32, num_updates=8990, lr=1.69385e-05, gnorm=2.34, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1169
2021-12-14 02:04:45 | INFO | train_inner | epoch 091:     90 / 99 loss=1.009, ppl=2.01, wps=8241.7, ups=13.18, wpb=625.4, bsz=32, num_updates=9000, lr=1.69231e-05, gnorm=2.325, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1170
2021-12-14 02:04:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:04:47 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 2.295 | ppl 4.91 | wps 22746 | wpb 586.4 | bsz 31.3 | num_updates 9009 | best_loss 2.295
2021-12-14 02:04:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 9009 updates
2021-12-14 02:04:47 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:04:49 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:04:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 91 @ 9009 updates, score 2.295) (writing took 3.6215011519379914 seconds)
2021-12-14 02:04:50 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2021-12-14 02:04:50 | INFO | train | epoch 091 | loss 1.089 | ppl 2.13 | wps 5146.5 | ups 8.16 | wpb 630.8 | bsz 31.9 | num_updates 9009 | lr 1.69092e-05 | gnorm 2.253 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 1175
2021-12-14 02:04:50 | INFO | fairseq.trainer | begin training epoch 92
2021-12-14 02:04:50 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:04:50 | INFO | train_inner | epoch 092:      1 / 99 loss=0.773, ppl=1.71, wps=996.6, ups=1.84, wpb=543, bsz=32, num_updates=9010, lr=1.69077e-05, gnorm=2.125, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1175
2021-12-14 02:04:51 | INFO | train_inner | epoch 092:     11 / 99 loss=1.337, ppl=2.53, wps=9183.5, ups=12.46, wpb=736.8, bsz=31.5, num_updates=9020, lr=1.68923e-05, gnorm=2.251, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1176
2021-12-14 02:04:52 | INFO | train_inner | epoch 092:     21 / 99 loss=0.963, ppl=1.95, wps=8515.9, ups=12.54, wpb=679, bsz=32, num_updates=9030, lr=1.68769e-05, gnorm=2.295, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1177
2021-12-14 02:04:53 | INFO | train_inner | epoch 092:     31 / 99 loss=0.821, ppl=1.77, wps=7445.5, ups=12.62, wpb=590.1, bsz=32, num_updates=9040, lr=1.68615e-05, gnorm=2.101, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1178
2021-12-14 02:04:54 | INFO | train_inner | epoch 092:     41 / 99 loss=0.832, ppl=1.78, wps=7197.1, ups=12.18, wpb=590.8, bsz=32, num_updates=9050, lr=1.68462e-05, gnorm=2.194, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1179
2021-12-14 02:04:55 | INFO | train_inner | epoch 092:     51 / 99 loss=1.398, ppl=2.64, wps=8067.5, ups=12.26, wpb=657.8, bsz=32, num_updates=9060, lr=1.68308e-05, gnorm=2.321, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1179
2021-12-14 02:04:55 | INFO | train_inner | epoch 092:     61 / 99 loss=0.927, ppl=1.9, wps=7862.2, ups=12.71, wpb=618.6, bsz=32, num_updates=9070, lr=1.68154e-05, gnorm=2.279, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1180
2021-12-14 02:04:56 | INFO | train_inner | epoch 092:     71 / 99 loss=0.957, ppl=1.94, wps=7133.7, ups=12.16, wpb=586.7, bsz=32, num_updates=9080, lr=1.68e-05, gnorm=2.349, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1181
2021-12-14 02:04:57 | INFO | train_inner | epoch 092:     81 / 99 loss=1.025, ppl=2.03, wps=6921.2, ups=12.31, wpb=562.2, bsz=32, num_updates=9090, lr=1.67846e-05, gnorm=2.357, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1182
2021-12-14 02:04:58 | INFO | train_inner | epoch 092:     91 / 99 loss=1.01, ppl=2.01, wps=6677.8, ups=11.7, wpb=570.6, bsz=32, num_updates=9100, lr=1.67692e-05, gnorm=2.458, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1183
2021-12-14 02:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:04:59 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 2.304 | ppl 4.94 | wps 23511.1 | wpb 586.4 | bsz 31.3 | num_updates 9108 | best_loss 2.295
2021-12-14 02:04:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 9108 updates
2021-12-14 02:04:59 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:05:02 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:05:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 92 @ 9108 updates, score 2.304) (writing took 2.7277842671610415 seconds)
2021-12-14 02:05:02 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2021-12-14 02:05:02 | INFO | train | epoch 092 | loss 1.071 | ppl 2.1 | wps 5282.4 | ups 8.37 | wpb 630.8 | bsz 31.9 | num_updates 9108 | lr 1.67569e-05 | gnorm 2.288 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1187
2021-12-14 02:05:02 | INFO | fairseq.trainer | begin training epoch 93
2021-12-14 02:05:02 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:05:02 | INFO | train_inner | epoch 093:      2 / 99 loss=1.288, ppl=2.44, wps=1496.6, ups=2.18, wpb=686.7, bsz=32, num_updates=9110, lr=1.67538e-05, gnorm=2.312, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1187
2021-12-14 02:05:03 | INFO | train_inner | epoch 093:     12 / 99 loss=1.245, ppl=2.37, wps=7473.5, ups=11.06, wpb=675.9, bsz=32, num_updates=9120, lr=1.67385e-05, gnorm=2.167, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1188
2021-12-14 02:05:04 | INFO | train_inner | epoch 093:     22 / 99 loss=0.678, ppl=1.6, wps=6364, ups=13.02, wpb=488.7, bsz=32, num_updates=9130, lr=1.67231e-05, gnorm=2.238, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1189
2021-12-14 02:05:05 | INFO | train_inner | epoch 093:     32 / 99 loss=0.578, ppl=1.49, wps=6491.6, ups=12.05, wpb=538.6, bsz=32, num_updates=9140, lr=1.67077e-05, gnorm=1.944, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1190
2021-12-14 02:05:06 | INFO | train_inner | epoch 093:     42 / 99 loss=0.828, ppl=1.78, wps=6506.8, ups=11.69, wpb=556.8, bsz=32, num_updates=9150, lr=1.66923e-05, gnorm=2.237, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1191
2021-12-14 02:05:07 | INFO | train_inner | epoch 093:     52 / 99 loss=1.675, ppl=3.19, wps=12021.7, ups=12.39, wpb=970.2, bsz=31.5, num_updates=9160, lr=1.66769e-05, gnorm=2.369, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1191
2021-12-14 02:05:07 | INFO | train_inner | epoch 093:     62 / 99 loss=1.04, ppl=2.06, wps=10354.4, ups=14.79, wpb=700, bsz=32, num_updates=9170, lr=1.66615e-05, gnorm=2.338, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1192
2021-12-14 02:05:08 | INFO | train_inner | epoch 093:     72 / 99 loss=0.847, ppl=1.8, wps=8649.8, ups=15.62, wpb=553.7, bsz=32, num_updates=9180, lr=1.66462e-05, gnorm=2.253, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1193
2021-12-14 02:05:09 | INFO | train_inner | epoch 093:     82 / 99 loss=1.268, ppl=2.41, wps=10261.5, ups=15.05, wpb=682, bsz=32, num_updates=9190, lr=1.66308e-05, gnorm=2.148, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1193
2021-12-14 02:05:10 | INFO | train_inner | epoch 093:     92 / 99 loss=0.78, ppl=1.72, wps=5641.4, ups=10.84, wpb=520.2, bsz=32, num_updates=9200, lr=1.66154e-05, gnorm=2.138, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1194
2021-12-14 02:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:05:11 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 2.273 | ppl 4.83 | wps 19204.6 | wpb 586.4 | bsz 31.3 | num_updates 9207 | best_loss 2.273
2021-12-14 02:05:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 9207 updates
2021-12-14 02:05:11 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:05:14 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:05:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 93 @ 9207 updates, score 2.273) (writing took 5.3204851150512695 seconds)
2021-12-14 02:05:16 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2021-12-14 02:05:16 | INFO | train | epoch 093 | loss 1.059 | ppl 2.08 | wps 4355.2 | ups 6.9 | wpb 630.8 | bsz 31.9 | num_updates 9207 | lr 1.66046e-05 | gnorm 2.221 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1201
2021-12-14 02:05:16 | INFO | fairseq.trainer | begin training epoch 94
2021-12-14 02:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:05:17 | INFO | train_inner | epoch 094:      3 / 99 loss=1.027, ppl=2.04, wps=930, ups=1.37, wpb=678.2, bsz=32, num_updates=9210, lr=1.66e-05, gnorm=2.353, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1202
2021-12-14 02:05:17 | INFO | train_inner | epoch 094:     13 / 99 loss=1.275, ppl=2.42, wps=10865.1, ups=14.8, wpb=734, bsz=32, num_updates=9220, lr=1.65846e-05, gnorm=2.227, clip=100, loss_scale=128, train_wall=1, gb_free=20, wall=1202
2021-12-14 02:05:18 | INFO | train_inner | epoch 094:     23 / 99 loss=1.337, ppl=2.53, wps=10239.8, ups=14.62, wpb=700.5, bsz=31.5, num_updates=9230, lr=1.65692e-05, gnorm=2.163, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=1203
2021-12-14 02:05:19 | INFO | train_inner | epoch 094:     33 / 99 loss=0.978, ppl=1.97, wps=9974.2, ups=15.12, wpb=659.8, bsz=32, num_updates=9240, lr=1.65538e-05, gnorm=2.282, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1204
2021-12-14 02:05:20 | INFO | train_inner | epoch 094:     43 / 99 loss=0.921, ppl=1.89, wps=8593, ups=14.84, wpb=579, bsz=32, num_updates=9250, lr=1.65385e-05, gnorm=2.096, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1204
2021-12-14 02:05:20 | INFO | train_inner | epoch 094:     53 / 99 loss=0.757, ppl=1.69, wps=8231.2, ups=15.42, wpb=533.9, bsz=32, num_updates=9260, lr=1.65231e-05, gnorm=2.197, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1205
2021-12-14 02:05:21 | INFO | train_inner | epoch 094:     63 / 99 loss=1.312, ppl=2.48, wps=11653.4, ups=15.17, wpb=768.2, bsz=32, num_updates=9270, lr=1.65077e-05, gnorm=2.399, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1206
2021-12-14 02:05:21 | INFO | train_inner | epoch 094:     73 / 99 loss=0.998, ppl=2, wps=9007.5, ups=15.49, wpb=581.4, bsz=32, num_updates=9280, lr=1.64923e-05, gnorm=2.396, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1206
2021-12-14 02:05:22 | INFO | train_inner | epoch 094:     83 / 99 loss=0.722, ppl=1.65, wps=7878.3, ups=15.44, wpb=510.4, bsz=32, num_updates=9290, lr=1.64769e-05, gnorm=2.216, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1207
2021-12-14 02:05:23 | INFO | train_inner | epoch 094:     93 / 99 loss=0.836, ppl=1.79, wps=6266.4, ups=11.28, wpb=555.7, bsz=32, num_updates=9300, lr=1.64615e-05, gnorm=2.409, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1208
2021-12-14 02:05:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:05:24 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 2.293 | ppl 4.9 | wps 24395.3 | wpb 586.4 | bsz 31.3 | num_updates 9306 | best_loss 2.273
2021-12-14 02:05:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9306 updates
2021-12-14 02:05:24 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:05:27 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:05:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 94 @ 9306 updates, score 2.293) (writing took 2.6528625928331167 seconds)
2021-12-14 02:05:27 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2021-12-14 02:05:27 | INFO | train | epoch 094 | loss 1.053 | ppl 2.07 | wps 5926.5 | ups 9.4 | wpb 630.8 | bsz 31.9 | num_updates 9306 | lr 1.64523e-05 | gnorm 2.268 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.2 | wall 1212
2021-12-14 02:05:27 | INFO | fairseq.trainer | begin training epoch 95
2021-12-14 02:05:27 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:05:28 | INFO | train_inner | epoch 095:      4 / 99 loss=1.244, ppl=2.37, wps=1737, ups=2.21, wpb=786.1, bsz=32, num_updates=9310, lr=1.64462e-05, gnorm=2.318, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1212
2021-12-14 02:05:28 | INFO | train_inner | epoch 095:     14 / 99 loss=1.41, ppl=2.66, wps=7876.6, ups=11.43, wpb=689.3, bsz=31.5, num_updates=9320, lr=1.64308e-05, gnorm=2.467, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=1213
2021-12-14 02:05:29 | INFO | train_inner | epoch 095:     24 / 99 loss=0.731, ppl=1.66, wps=6594.3, ups=13.11, wpb=503, bsz=32, num_updates=9330, lr=1.64154e-05, gnorm=2.157, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1214
2021-12-14 02:05:30 | INFO | train_inner | epoch 095:     34 / 99 loss=0.847, ppl=1.8, wps=6316.5, ups=11.41, wpb=553.6, bsz=32, num_updates=9340, lr=1.64e-05, gnorm=2.172, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1215
2021-12-14 02:05:31 | INFO | train_inner | epoch 095:     44 / 99 loss=0.736, ppl=1.67, wps=6238.8, ups=10.95, wpb=569.5, bsz=32, num_updates=9350, lr=1.63846e-05, gnorm=2.168, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1216
2021-12-14 02:05:32 | INFO | train_inner | epoch 095:     54 / 99 loss=0.808, ppl=1.75, wps=6619.2, ups=11.92, wpb=555.2, bsz=32, num_updates=9360, lr=1.63692e-05, gnorm=2.119, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1217
2021-12-14 02:05:33 | INFO | train_inner | epoch 095:     64 / 99 loss=1.062, ppl=2.09, wps=7156.2, ups=11.67, wpb=613.3, bsz=32, num_updates=9370, lr=1.63538e-05, gnorm=2.227, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1217
2021-12-14 02:05:34 | INFO | train_inner | epoch 095:     74 / 99 loss=1.351, ppl=2.55, wps=8018.2, ups=11.03, wpb=726.7, bsz=32, num_updates=9380, lr=1.63385e-05, gnorm=2.211, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1218
2021-12-14 02:05:34 | INFO | train_inner | epoch 095:     84 / 99 loss=1.103, ppl=2.15, wps=9208.6, ups=12.15, wpb=758, bsz=32, num_updates=9390, lr=1.63231e-05, gnorm=2.28, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1219
2021-12-14 02:05:35 | INFO | train_inner | epoch 095:     94 / 99 loss=0.728, ppl=1.66, wps=6491.1, ups=12.22, wpb=531, bsz=32, num_updates=9400, lr=1.63077e-05, gnorm=2.161, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1220
2021-12-14 02:05:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:05:37 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 2.271 | ppl 4.83 | wps 22554.2 | wpb 586.4 | bsz 31.3 | num_updates 9405 | best_loss 2.271
2021-12-14 02:05:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9405 updates
2021-12-14 02:05:37 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:05:39 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:05:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 95 @ 9405 updates, score 2.271) (writing took 3.6807999031152576 seconds)
2021-12-14 02:05:40 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2021-12-14 02:05:40 | INFO | train | epoch 095 | loss 1.033 | ppl 2.05 | wps 4733 | ups 7.5 | wpb 630.8 | bsz 31.9 | num_updates 9405 | lr 1.63e-05 | gnorm 2.225 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.2 | wall 1225
2021-12-14 02:05:40 | INFO | fairseq.trainer | begin training epoch 96
2021-12-14 02:05:40 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:05:41 | INFO | train_inner | epoch 096:      5 / 99 loss=1.15, ppl=2.22, wps=1280.9, ups=1.82, wpb=701.9, bsz=32, num_updates=9410, lr=1.62923e-05, gnorm=2.259, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1226
2021-12-14 02:05:42 | INFO | train_inner | epoch 096:     15 / 99 loss=1.097, ppl=2.14, wps=7414.1, ups=11, wpb=674.3, bsz=32, num_updates=9420, lr=1.62769e-05, gnorm=2.167, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1226
2021-12-14 02:05:42 | INFO | train_inner | epoch 096:     25 / 99 loss=0.88, ppl=1.84, wps=8284.4, ups=12.55, wpb=659.9, bsz=32, num_updates=9430, lr=1.62615e-05, gnorm=2.161, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1227
2021-12-14 02:05:43 | INFO | train_inner | epoch 096:     35 / 99 loss=1.269, ppl=2.41, wps=7452, ups=12.98, wpb=574.3, bsz=31.5, num_updates=9440, lr=1.62462e-05, gnorm=2.05, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1228
2021-12-14 02:05:44 | INFO | train_inner | epoch 096:     45 / 99 loss=0.797, ppl=1.74, wps=7343.1, ups=13.6, wpb=539.9, bsz=32, num_updates=9450, lr=1.62308e-05, gnorm=2.299, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1229
2021-12-14 02:05:45 | INFO | train_inner | epoch 096:     55 / 99 loss=0.882, ppl=1.84, wps=7363.3, ups=13.44, wpb=548, bsz=32, num_updates=9460, lr=1.62154e-05, gnorm=2.171, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1229
2021-12-14 02:05:45 | INFO | train_inner | epoch 096:     65 / 99 loss=0.689, ppl=1.61, wps=7968.7, ups=13.41, wpb=594.1, bsz=32, num_updates=9470, lr=1.62e-05, gnorm=2.068, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1230
2021-12-14 02:05:46 | INFO | train_inner | epoch 096:     75 / 99 loss=1.369, ppl=2.58, wps=8220.2, ups=11.81, wpb=696, bsz=32, num_updates=9480, lr=1.61846e-05, gnorm=2.247, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1231
2021-12-14 02:05:47 | INFO | train_inner | epoch 096:     85 / 99 loss=1.142, ppl=2.21, wps=7960.6, ups=10.84, wpb=734.2, bsz=32, num_updates=9490, lr=1.61692e-05, gnorm=2.312, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1232
2021-12-14 02:05:48 | INFO | train_inner | epoch 096:     95 / 99 loss=1.07, ppl=2.1, wps=6612.8, ups=10.07, wpb=657, bsz=32, num_updates=9500, lr=1.61538e-05, gnorm=2.283, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1233
2021-12-14 02:05:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:05:49 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 2.327 | ppl 5.02 | wps 22303.8 | wpb 586.4 | bsz 31.3 | num_updates 9504 | best_loss 2.271
2021-12-14 02:05:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9504 updates
2021-12-14 02:05:49 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:05:52 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:05:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 96 @ 9504 updates, score 2.327) (writing took 2.636757040163502 seconds)
2021-12-14 02:05:52 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2021-12-14 02:05:52 | INFO | train | epoch 096 | loss 1.027 | ppl 2.04 | wps 5257.9 | ups 8.34 | wpb 630.8 | bsz 31.9 | num_updates 9504 | lr 1.61477e-05 | gnorm 2.207 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1237
2021-12-14 02:05:52 | INFO | fairseq.trainer | begin training epoch 97
2021-12-14 02:05:52 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:05:53 | INFO | train_inner | epoch 097:      6 / 99 loss=0.706, ppl=1.63, wps=1175.2, ups=2.17, wpb=541.8, bsz=32, num_updates=9510, lr=1.61385e-05, gnorm=2.33, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1238
2021-12-14 02:05:54 | INFO | train_inner | epoch 097:     16 / 99 loss=0.929, ppl=1.9, wps=6015.4, ups=9.24, wpb=651.3, bsz=32, num_updates=9520, lr=1.61231e-05, gnorm=2.167, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1239
2021-12-14 02:05:55 | INFO | train_inner | epoch 097:     26 / 99 loss=1.418, ppl=2.67, wps=9532.6, ups=11.38, wpb=837.3, bsz=32, num_updates=9530, lr=1.61077e-05, gnorm=2.332, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1240
2021-12-14 02:05:56 | INFO | train_inner | epoch 097:     36 / 99 loss=0.797, ppl=1.74, wps=7694.9, ups=13.26, wpb=580.3, bsz=32, num_updates=9540, lr=1.60923e-05, gnorm=2.275, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1240
2021-12-14 02:05:56 | INFO | train_inner | epoch 097:     46 / 99 loss=0.716, ppl=1.64, wps=7652.7, ups=12.62, wpb=606.6, bsz=32, num_updates=9550, lr=1.60769e-05, gnorm=2.267, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1241
2021-12-14 02:05:57 | INFO | train_inner | epoch 097:     56 / 99 loss=0.745, ppl=1.68, wps=5953.4, ups=13.76, wpb=432.5, bsz=32, num_updates=9560, lr=1.60615e-05, gnorm=2.168, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1242
2021-12-14 02:05:58 | INFO | train_inner | epoch 097:     66 / 99 loss=0.966, ppl=1.95, wps=9504.1, ups=15, wpb=633.8, bsz=32, num_updates=9570, lr=1.60462e-05, gnorm=2.19, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1243
2021-12-14 02:05:59 | INFO | train_inner | epoch 097:     76 / 99 loss=1.235, ppl=2.35, wps=9559.9, ups=13.07, wpb=731.5, bsz=32, num_updates=9580, lr=1.60308e-05, gnorm=2.289, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1243
2021-12-14 02:05:59 | INFO | train_inner | epoch 097:     86 / 99 loss=0.9, ppl=1.87, wps=8716.5, ups=13.58, wpb=641.9, bsz=32, num_updates=9590, lr=1.60154e-05, gnorm=2.228, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1244
2021-12-14 02:06:00 | INFO | train_inner | epoch 097:     96 / 99 loss=1.299, ppl=2.46, wps=7380.1, ups=10.81, wpb=683, bsz=31.5, num_updates=9600, lr=1.6e-05, gnorm=2.158, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1245
2021-12-14 02:06:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:06:01 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 2.298 | ppl 4.92 | wps 23826.1 | wpb 586.4 | bsz 31.3 | num_updates 9603 | best_loss 2.271
2021-12-14 02:06:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9603 updates
2021-12-14 02:06:01 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:06:04 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:06:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 97 @ 9603 updates, score 2.298) (writing took 2.629103943007067 seconds)
2021-12-14 02:06:04 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2021-12-14 02:06:04 | INFO | train | epoch 097 | loss 1.005 | ppl 2.01 | wps 5280.5 | ups 8.37 | wpb 630.8 | bsz 31.9 | num_updates 9603 | lr 1.59954e-05 | gnorm 2.217 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1249
2021-12-14 02:06:04 | INFO | fairseq.trainer | begin training epoch 98
2021-12-14 02:06:04 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:06:05 | INFO | train_inner | epoch 098:      7 / 99 loss=1.065, ppl=2.09, wps=1358.1, ups=2.28, wpb=595.8, bsz=32, num_updates=9610, lr=1.59846e-05, gnorm=2.056, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1249
2021-12-14 02:06:05 | INFO | train_inner | epoch 098:     17 / 99 loss=0.85, ppl=1.8, wps=7502.4, ups=12.49, wpb=600.6, bsz=32, num_updates=9620, lr=1.59692e-05, gnorm=2.147, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1250
2021-12-14 02:06:06 | INFO | train_inner | epoch 098:     27 / 99 loss=1.12, ppl=2.17, wps=8077.2, ups=12.47, wpb=647.6, bsz=32, num_updates=9630, lr=1.59538e-05, gnorm=2.211, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1251
2021-12-14 02:06:07 | INFO | train_inner | epoch 098:     37 / 99 loss=0.834, ppl=1.78, wps=5433.1, ups=10.39, wpb=522.9, bsz=32, num_updates=9640, lr=1.59385e-05, gnorm=2.159, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1252
2021-12-14 02:06:08 | INFO | train_inner | epoch 098:     47 / 99 loss=0.818, ppl=1.76, wps=7317.6, ups=11.64, wpb=628.4, bsz=32, num_updates=9650, lr=1.59231e-05, gnorm=1.952, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1253
2021-12-14 02:06:09 | INFO | train_inner | epoch 098:     57 / 99 loss=1.333, ppl=2.52, wps=9790, ups=13.31, wpb=735.8, bsz=31.5, num_updates=9660, lr=1.59077e-05, gnorm=2.225, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1254
2021-12-14 02:06:10 | INFO | train_inner | epoch 098:     67 / 99 loss=1.214, ppl=2.32, wps=10589.7, ups=13.1, wpb=808.4, bsz=32, num_updates=9670, lr=1.58923e-05, gnorm=2.436, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1254
2021-12-14 02:06:10 | INFO | train_inner | epoch 098:     77 / 99 loss=0.933, ppl=1.91, wps=8943.4, ups=13.18, wpb=678.7, bsz=32, num_updates=9680, lr=1.58769e-05, gnorm=2.238, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1255
2021-12-14 02:06:11 | INFO | train_inner | epoch 098:     87 / 99 loss=0.898, ppl=1.86, wps=6914.1, ups=12.94, wpb=534.2, bsz=32, num_updates=9690, lr=1.58615e-05, gnorm=2.121, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1256
2021-12-14 02:06:12 | INFO | train_inner | epoch 098:     97 / 99 loss=0.809, ppl=1.75, wps=6289.9, ups=11.46, wpb=548.8, bsz=32, num_updates=9700, lr=1.58462e-05, gnorm=2.48, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1257
2021-12-14 02:06:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:06:13 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 2.253 | ppl 4.77 | wps 23682.1 | wpb 586.4 | bsz 31.3 | num_updates 9702 | best_loss 2.253
2021-12-14 02:06:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 9702 updates
2021-12-14 02:06:13 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:06:16 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:06:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 98 @ 9702 updates, score 2.253) (writing took 4.023265908006579 seconds)
2021-12-14 02:06:17 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2021-12-14 02:06:17 | INFO | train | epoch 098 | loss 1.002 | ppl 2 | wps 4792.5 | ups 7.6 | wpb 630.8 | bsz 31.9 | num_updates 9702 | lr 1.58431e-05 | gnorm 2.209 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1262
2021-12-14 02:06:17 | INFO | fairseq.trainer | begin training epoch 99
2021-12-14 02:06:17 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:06:18 | INFO | train_inner | epoch 099:      8 / 99 loss=1.033, ppl=2.05, wps=1042.9, ups=1.76, wpb=592.9, bsz=32, num_updates=9710, lr=1.58308e-05, gnorm=2.244, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1262
2021-12-14 02:06:18 | INFO | train_inner | epoch 099:     18 / 99 loss=0.631, ppl=1.55, wps=7004.7, ups=13.6, wpb=515.2, bsz=32, num_updates=9720, lr=1.58154e-05, gnorm=2.069, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1263
2021-12-14 02:06:19 | INFO | train_inner | epoch 099:     28 / 99 loss=1.186, ppl=2.28, wps=9586.8, ups=11.82, wpb=810.8, bsz=32, num_updates=9730, lr=1.58e-05, gnorm=2.297, clip=100, loss_scale=128, train_wall=1, gb_free=20.3, wall=1264
2021-12-14 02:06:20 | INFO | train_inner | epoch 099:     38 / 99 loss=0.982, ppl=1.98, wps=8694.5, ups=13.59, wpb=639.6, bsz=32, num_updates=9740, lr=1.57846e-05, gnorm=2.04, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1265
2021-12-14 02:06:21 | INFO | train_inner | epoch 099:     48 / 99 loss=1.01, ppl=2.01, wps=8996.3, ups=12.94, wpb=695, bsz=32, num_updates=9750, lr=1.57692e-05, gnorm=2.274, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=1266
2021-12-14 02:06:21 | INFO | train_inner | epoch 099:     58 / 99 loss=0.698, ppl=1.62, wps=6733.2, ups=13.67, wpb=492.6, bsz=32, num_updates=9760, lr=1.57538e-05, gnorm=2.14, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1266
2021-12-14 02:06:22 | INFO | train_inner | epoch 099:     68 / 99 loss=1.132, ppl=2.19, wps=10839.8, ups=15.23, wpb=711.6, bsz=32, num_updates=9770, lr=1.57385e-05, gnorm=2.254, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=1267
2021-12-14 02:06:23 | INFO | train_inner | epoch 099:     78 / 99 loss=0.882, ppl=1.84, wps=9429.7, ups=15.5, wpb=608.4, bsz=32, num_updates=9780, lr=1.57231e-05, gnorm=2.116, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1268
2021-12-14 02:06:24 | INFO | train_inner | epoch 099:     88 / 99 loss=1.278, ppl=2.43, wps=8534.2, ups=13.74, wpb=621.2, bsz=31.5, num_updates=9790, lr=1.57077e-05, gnorm=2.163, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1268
2021-12-14 02:06:24 | INFO | train_inner | epoch 099:     98 / 99 loss=0.71, ppl=1.64, wps=6051.9, ups=10.3, wpb=587.7, bsz=32, num_updates=9800, lr=1.56923e-05, gnorm=2.109, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1269
2021-12-14 02:06:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:06:26 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 2.286 | ppl 4.88 | wps 18998 | wpb 586.4 | bsz 31.3 | num_updates 9801 | best_loss 2.253
2021-12-14 02:06:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 9801 updates
2021-12-14 02:06:26 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:06:28 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:06:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 99 @ 9801 updates, score 2.286) (writing took 2.689693896099925 seconds)
2021-12-14 02:06:28 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2021-12-14 02:06:28 | INFO | train | epoch 099 | loss 0.981 | ppl 1.97 | wps 5531.9 | ups 8.77 | wpb 630.8 | bsz 31.9 | num_updates 9801 | lr 1.56908e-05 | gnorm 2.172 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 1273
2021-12-14 02:06:28 | INFO | fairseq.trainer | begin training epoch 100
2021-12-14 02:06:28 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:06:29 | INFO | train_inner | epoch 100:      9 / 99 loss=0.82, ppl=1.77, wps=1281.7, ups=2.24, wpb=572.9, bsz=32, num_updates=9810, lr=1.56769e-05, gnorm=2.118, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1274
2021-12-14 02:06:30 | INFO | train_inner | epoch 100:     19 / 99 loss=0.881, ppl=1.84, wps=9198, ups=14.53, wpb=633, bsz=32, num_updates=9820, lr=1.56615e-05, gnorm=2.316, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1274
2021-12-14 02:06:31 | INFO | train_inner | epoch 100:     29 / 99 loss=0.869, ppl=1.83, wps=5006.2, ups=9.44, wpb=530.4, bsz=32, num_updates=9830, lr=1.56462e-05, gnorm=2.241, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1276
2021-12-14 02:06:31 | INFO | train_inner | epoch 100:     39 / 99 loss=1.118, ppl=2.17, wps=10447, ups=13.34, wpb=783, bsz=32, num_updates=9840, lr=1.56308e-05, gnorm=2.246, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1276
2021-12-14 02:06:32 | INFO | train_inner | epoch 100:     49 / 99 loss=1.058, ppl=2.08, wps=7581, ups=10.93, wpb=693.3, bsz=32, num_updates=9850, lr=1.56154e-05, gnorm=2.082, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1277
2021-12-14 02:06:33 | INFO | train_inner | epoch 100:     59 / 99 loss=1.006, ppl=2.01, wps=7331.1, ups=10.8, wpb=679, bsz=32, num_updates=9860, lr=1.56e-05, gnorm=2.158, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1278
2021-12-14 02:06:34 | INFO | train_inner | epoch 100:     69 / 99 loss=0.778, ppl=1.71, wps=7131, ups=10.76, wpb=662.8, bsz=32, num_updates=9870, lr=1.55846e-05, gnorm=2.08, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1279
2021-12-14 02:06:35 | INFO | train_inner | epoch 100:     79 / 99 loss=0.592, ppl=1.51, wps=4013.7, ups=9.68, wpb=414.7, bsz=32, num_updates=9880, lr=1.55692e-05, gnorm=1.911, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1280
2021-12-14 02:06:36 | INFO | train_inner | epoch 100:     89 / 99 loss=1.492, ppl=2.81, wps=8540, ups=10.35, wpb=825.5, bsz=31.5, num_updates=9890, lr=1.55538e-05, gnorm=2.354, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=1281
2021-12-14 02:06:37 | INFO | train_inner | epoch 100:     99 / 99 loss=0.645, ppl=1.56, wps=5238.3, ups=10.32, wpb=507.6, bsz=32, num_updates=9900, lr=1.55385e-05, gnorm=2.159, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1282
2021-12-14 02:06:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:06:38 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 2.27 | ppl 4.82 | wps 21109.1 | wpb 586.4 | bsz 31.3 | num_updates 9900 | best_loss 2.253
2021-12-14 02:06:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 9900 updates
2021-12-14 02:06:38 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:06:41 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:06:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 100 @ 9900 updates, score 2.27) (writing took 2.679271260043606 seconds)
2021-12-14 02:06:41 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2021-12-14 02:06:41 | INFO | train | epoch 100 | loss 0.971 | ppl 1.96 | wps 4981.3 | ups 7.9 | wpb 630.8 | bsz 31.9 | num_updates 9900 | lr 1.55385e-05 | gnorm 2.168 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 1286
2021-12-14 02:06:41 | INFO | fairseq.trainer | begin training epoch 101
2021-12-14 02:06:41 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:06:42 | INFO | train_inner | epoch 101:     10 / 99 loss=1.227, ppl=2.34, wps=1520.2, ups=2.22, wpb=685.6, bsz=31.5, num_updates=9910, lr=1.55231e-05, gnorm=2.254, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1287
2021-12-14 02:06:42 | INFO | train_inner | epoch 101:     20 / 99 loss=0.747, ppl=1.68, wps=8267, ups=13.73, wpb=602, bsz=32, num_updates=9920, lr=1.55077e-05, gnorm=1.976, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1287
2021-12-14 02:06:43 | INFO | train_inner | epoch 101:     30 / 99 loss=0.753, ppl=1.68, wps=7367.2, ups=12.68, wpb=581.1, bsz=32, num_updates=9930, lr=1.54923e-05, gnorm=2.035, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1288
2021-12-14 02:06:44 | INFO | train_inner | epoch 101:     40 / 99 loss=1.137, ppl=2.2, wps=8049.4, ups=11.13, wpb=723.4, bsz=32, num_updates=9940, lr=1.54769e-05, gnorm=2.291, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1289
2021-12-14 02:06:45 | INFO | train_inner | epoch 101:     50 / 99 loss=0.973, ppl=1.96, wps=8764, ups=12.52, wpb=700, bsz=32, num_updates=9950, lr=1.54615e-05, gnorm=2.211, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1290
2021-12-14 02:06:46 | INFO | train_inner | epoch 101:     60 / 99 loss=1.068, ppl=2.1, wps=7707, ups=11.32, wpb=681, bsz=32, num_updates=9960, lr=1.54462e-05, gnorm=2.399, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1291
2021-12-14 02:06:47 | INFO | train_inner | epoch 101:     70 / 99 loss=1.089, ppl=2.13, wps=7851.6, ups=12.36, wpb=635.2, bsz=32, num_updates=9970, lr=1.54308e-05, gnorm=1.878, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1291
2021-12-14 02:06:48 | INFO | train_inner | epoch 101:     80 / 99 loss=1.039, ppl=2.05, wps=7667.7, ups=11.75, wpb=652.6, bsz=32, num_updates=9980, lr=1.54154e-05, gnorm=2.357, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1292
2021-12-14 02:06:48 | INFO | train_inner | epoch 101:     90 / 99 loss=0.632, ppl=1.55, wps=5379.4, ups=12.2, wpb=440.8, bsz=32, num_updates=9990, lr=1.54e-05, gnorm=1.992, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1293
2021-12-14 02:06:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:06:50 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 2.251 | ppl 4.76 | wps 23872 | wpb 586.4 | bsz 31.3 | num_updates 9999 | best_loss 2.251
2021-12-14 02:06:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 9999 updates
2021-12-14 02:06:50 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:06:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 101 @ 9999 updates, score 2.251) (writing took 3.6864938761573285 seconds)
2021-12-14 02:06:54 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2021-12-14 02:06:54 | INFO | train | epoch 101 | loss 0.963 | ppl 1.95 | wps 4878.4 | ups 7.73 | wpb 630.8 | bsz 31.9 | num_updates 9999 | lr 1.53862e-05 | gnorm 2.142 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.7 | wall 1298
2021-12-14 02:06:54 | INFO | fairseq.trainer | begin training epoch 102
2021-12-14 02:06:54 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:06:54 | INFO | train_inner | epoch 102:      1 / 99 loss=0.76, ppl=1.69, wps=1107.7, ups=1.84, wpb=600.5, bsz=32, num_updates=10000, lr=1.53846e-05, gnorm=2.063, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1299
2021-12-14 02:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:06:55 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 2.266 | ppl 4.81 | wps 23897.6 | wpb 586.4 | bsz 31.3 | num_updates 10000 | best_loss 2.251
2021-12-14 02:06:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 10000 updates
2021-12-14 02:06:55 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_102_10000.pt
2021-12-14 02:06:59 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_102_10000.pt
2021-12-14 02:07:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_102_10000.pt (epoch 102 @ 10000 updates, score 2.266) (writing took 5.716496401000768 seconds)
2021-12-14 02:07:01 | INFO | train_inner | epoch 102:     11 / 99 loss=0.794, ppl=1.73, wps=881.8, ups=1.37, wpb=643.5, bsz=32, num_updates=10010, lr=1.53692e-05, gnorm=1.993, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1306
2021-12-14 02:07:02 | INFO | train_inner | epoch 102:     21 / 99 loss=0.856, ppl=1.81, wps=8038.9, ups=12.48, wpb=643.9, bsz=32, num_updates=10020, lr=1.53538e-05, gnorm=2.187, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1307
2021-12-14 02:07:03 | INFO | train_inner | epoch 102:     31 / 99 loss=0.873, ppl=1.83, wps=7294.1, ups=11.39, wpb=640.6, bsz=32, num_updates=10030, lr=1.53385e-05, gnorm=2.204, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1308
2021-12-14 02:07:04 | INFO | train_inner | epoch 102:     41 / 99 loss=0.791, ppl=1.73, wps=7210, ups=13.34, wpb=540.5, bsz=32, num_updates=10040, lr=1.53231e-05, gnorm=1.98, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1308
2021-12-14 02:07:04 | INFO | train_inner | epoch 102:     51 / 99 loss=1.04, ppl=2.06, wps=9752.2, ups=13.96, wpb=698.4, bsz=32, num_updates=10050, lr=1.53077e-05, gnorm=2.259, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1309
2021-12-14 02:07:05 | INFO | train_inner | epoch 102:     61 / 99 loss=1.465, ppl=2.76, wps=8313, ups=12.04, wpb=690.2, bsz=31.5, num_updates=10060, lr=1.52923e-05, gnorm=2.106, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=1310
2021-12-14 02:07:06 | INFO | train_inner | epoch 102:     71 / 99 loss=1.009, ppl=2.01, wps=8203.5, ups=12.78, wpb=642.1, bsz=32, num_updates=10070, lr=1.52769e-05, gnorm=2.209, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1311
2021-12-14 02:07:07 | INFO | train_inner | epoch 102:     81 / 99 loss=0.49, ppl=1.4, wps=6083.9, ups=12.82, wpb=474.5, bsz=32, num_updates=10080, lr=1.52615e-05, gnorm=1.929, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1311
2021-12-14 02:07:07 | INFO | train_inner | epoch 102:     91 / 99 loss=1.12, ppl=2.17, wps=8680.9, ups=12.24, wpb=709.1, bsz=32, num_updates=10090, lr=1.52462e-05, gnorm=2.305, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1312
2021-12-14 02:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:07:09 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 2.302 | ppl 4.93 | wps 22818.9 | wpb 586.4 | bsz 31.3 | num_updates 10098 | best_loss 2.251
2021-12-14 02:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 10098 updates
2021-12-14 02:07:09 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 102 @ 10098 updates, score 2.302) (writing took 2.677705109817907 seconds)
2021-12-14 02:07:12 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2021-12-14 02:07:12 | INFO | train | epoch 102 | loss 0.947 | ppl 1.93 | wps 3441.9 | ups 5.46 | wpb 630.8 | bsz 31.9 | num_updates 10098 | lr 1.52338e-05 | gnorm 2.12 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1317
2021-12-14 02:07:12 | INFO | fairseq.trainer | begin training epoch 103
2021-12-14 02:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:07:12 | INFO | train_inner | epoch 103:      2 / 99 loss=0.835, ppl=1.78, wps=1425.2, ups=2.18, wpb=654.6, bsz=32, num_updates=10100, lr=1.52308e-05, gnorm=2.053, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1317
2021-12-14 02:07:13 | INFO | train_inner | epoch 103:     12 / 99 loss=0.72, ppl=1.65, wps=7598, ups=13.01, wpb=584.2, bsz=32, num_updates=10110, lr=1.52154e-05, gnorm=2.203, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1318
2021-12-14 02:07:14 | INFO | train_inner | epoch 103:     22 / 99 loss=0.618, ppl=1.53, wps=6167.4, ups=12.99, wpb=474.7, bsz=32, num_updates=10120, lr=1.52e-05, gnorm=2.034, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1318
2021-12-14 02:07:15 | INFO | train_inner | epoch 103:     32 / 99 loss=0.974, ppl=1.96, wps=5618.6, ups=10.26, wpb=547.5, bsz=32, num_updates=10130, lr=1.51846e-05, gnorm=2.083, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1319
2021-12-14 02:07:15 | INFO | train_inner | epoch 103:     42 / 99 loss=1.006, ppl=2.01, wps=8231.2, ups=12.45, wpb=661.3, bsz=32, num_updates=10140, lr=1.51692e-05, gnorm=2.229, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1320
2021-12-14 02:07:16 | INFO | train_inner | epoch 103:     52 / 99 loss=1.215, ppl=2.32, wps=9084, ups=12.01, wpb=756.6, bsz=32, num_updates=10150, lr=1.51538e-05, gnorm=2.27, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1321
2021-12-14 02:07:17 | INFO | train_inner | epoch 103:     62 / 99 loss=0.825, ppl=1.77, wps=8552.8, ups=13.1, wpb=652.7, bsz=32, num_updates=10160, lr=1.51385e-05, gnorm=2.076, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1322
2021-12-14 02:07:18 | INFO | train_inner | epoch 103:     72 / 99 loss=1.144, ppl=2.21, wps=9290.2, ups=12.8, wpb=725.6, bsz=31.5, num_updates=10170, lr=1.51231e-05, gnorm=1.988, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1323
2021-12-14 02:07:19 | INFO | train_inner | epoch 103:     82 / 99 loss=0.739, ppl=1.67, wps=6892.4, ups=12.66, wpb=544.5, bsz=32, num_updates=10180, lr=1.51077e-05, gnorm=2.13, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1323
2021-12-14 02:07:19 | INFO | train_inner | epoch 103:     92 / 99 loss=0.986, ppl=1.98, wps=7020.5, ups=10.72, wpb=654.6, bsz=32, num_updates=10190, lr=1.50923e-05, gnorm=2.305, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1324
2021-12-14 02:07:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:07:21 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 2.228 | ppl 4.69 | wps 22557.9 | wpb 586.4 | bsz 31.3 | num_updates 10197 | best_loss 2.228
2021-12-14 02:07:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 10197 updates
2021-12-14 02:07:21 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:07:24 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:07:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 103 @ 10197 updates, score 2.228) (writing took 5.061839802889153 seconds)
2021-12-14 02:07:26 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2021-12-14 02:07:26 | INFO | train | epoch 103 | loss 0.944 | ppl 1.92 | wps 4349.2 | ups 6.9 | wpb 630.8 | bsz 31.9 | num_updates 10197 | lr 1.50815e-05 | gnorm 2.164 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1331
2021-12-14 02:07:26 | INFO | fairseq.trainer | begin training epoch 104
2021-12-14 02:07:26 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:07:26 | INFO | train_inner | epoch 104:      3 / 99 loss=1.029, ppl=2.04, wps=1014.9, ups=1.44, wpb=702.7, bsz=32, num_updates=10200, lr=1.50769e-05, gnorm=2.221, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1331
2021-12-14 02:07:27 | INFO | train_inner | epoch 104:     13 / 99 loss=0.891, ppl=1.85, wps=9747.4, ups=13.52, wpb=721.1, bsz=32, num_updates=10210, lr=1.50615e-05, gnorm=2.382, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1332
2021-12-14 02:07:28 | INFO | train_inner | epoch 104:     23 / 99 loss=1.254, ppl=2.39, wps=9460.2, ups=11.12, wpb=850.7, bsz=32, num_updates=10220, lr=1.50462e-05, gnorm=2.088, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1333
2021-12-14 02:07:29 | INFO | train_inner | epoch 104:     33 / 99 loss=1.283, ppl=2.43, wps=9811.1, ups=13.16, wpb=745.8, bsz=32, num_updates=10230, lr=1.50308e-05, gnorm=2.281, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1334
2021-12-14 02:07:30 | INFO | train_inner | epoch 104:     43 / 99 loss=0.696, ppl=1.62, wps=7031.4, ups=13.2, wpb=532.6, bsz=32, num_updates=10240, lr=1.50154e-05, gnorm=2.036, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1334
2021-12-14 02:07:30 | INFO | train_inner | epoch 104:     53 / 99 loss=0.634, ppl=1.55, wps=6881.8, ups=12.09, wpb=569.1, bsz=32, num_updates=10250, lr=1.5e-05, gnorm=2.093, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1335
2021-12-14 02:07:31 | INFO | train_inner | epoch 104:     63 / 99 loss=0.635, ppl=1.55, wps=7050.6, ups=12.62, wpb=558.9, bsz=32, num_updates=10260, lr=1.49846e-05, gnorm=2.185, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1336
2021-12-14 02:07:32 | INFO | train_inner | epoch 104:     73 / 99 loss=0.749, ppl=1.68, wps=7233.8, ups=12.64, wpb=572.2, bsz=32, num_updates=10270, lr=1.49692e-05, gnorm=2.16, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1337
2021-12-14 02:07:33 | INFO | train_inner | epoch 104:     83 / 99 loss=0.682, ppl=1.6, wps=6933, ups=12.47, wpb=555.8, bsz=32, num_updates=10280, lr=1.49538e-05, gnorm=2.101, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1338
2021-12-14 02:07:34 | INFO | train_inner | epoch 104:     93 / 99 loss=1.325, ppl=2.51, wps=7459.8, ups=11.87, wpb=628.3, bsz=31.5, num_updates=10290, lr=1.49385e-05, gnorm=2.044, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1338
2021-12-14 02:07:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:07:35 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 2.195 | ppl 4.58 | wps 23048.1 | wpb 586.4 | bsz 31.3 | num_updates 10296 | best_loss 2.195
2021-12-14 02:07:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10296 updates
2021-12-14 02:07:35 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:07:38 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_best.pt
2021-12-14 02:07:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_best.pt (epoch 104 @ 10296 updates, score 2.195) (writing took 4.083969003986567 seconds)
2021-12-14 02:07:39 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2021-12-14 02:07:40 | INFO | train | epoch 104 | loss 0.934 | ppl 1.91 | wps 4810.7 | ups 7.63 | wpb 630.8 | bsz 31.9 | num_updates 10296 | lr 1.49292e-05 | gnorm 2.152 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1344
2021-12-14 02:07:40 | INFO | fairseq.trainer | begin training epoch 105
2021-12-14 02:07:40 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:07:40 | INFO | train_inner | epoch 105:      4 / 99 loss=0.667, ppl=1.59, wps=712.3, ups=1.46, wpb=487.5, bsz=32, num_updates=10300, lr=1.49231e-05, gnorm=2.159, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1345
2021-12-14 02:07:41 | INFO | train_inner | epoch 105:     14 / 99 loss=0.528, ppl=1.44, wps=6394, ups=13.62, wpb=469.3, bsz=32, num_updates=10310, lr=1.49077e-05, gnorm=1.911, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1346
2021-12-14 02:07:42 | INFO | train_inner | epoch 105:     24 / 99 loss=0.73, ppl=1.66, wps=8724.6, ups=12.94, wpb=674.4, bsz=32, num_updates=10320, lr=1.48923e-05, gnorm=2.088, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1347
2021-12-14 02:07:43 | INFO | train_inner | epoch 105:     34 / 99 loss=0.97, ppl=1.96, wps=8847.5, ups=13.44, wpb=658.5, bsz=32, num_updates=10330, lr=1.48769e-05, gnorm=2.152, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1348
2021-12-14 02:07:44 | INFO | train_inner | epoch 105:     44 / 99 loss=1.193, ppl=2.29, wps=10979, ups=13.53, wpb=811.5, bsz=32, num_updates=10340, lr=1.48615e-05, gnorm=2.266, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1348
2021-12-14 02:07:44 | INFO | train_inner | epoch 105:     54 / 99 loss=1.381, ppl=2.6, wps=8973, ups=12.34, wpb=727.2, bsz=31.5, num_updates=10350, lr=1.48462e-05, gnorm=2.125, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1349
2021-12-14 02:07:45 | INFO | train_inner | epoch 105:     64 / 99 loss=0.882, ppl=1.84, wps=8384, ups=15.12, wpb=554.5, bsz=32, num_updates=10360, lr=1.48308e-05, gnorm=2.133, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1350
2021-12-14 02:07:46 | INFO | train_inner | epoch 105:     74 / 99 loss=0.89, ppl=1.85, wps=9298.3, ups=15.66, wpb=593.7, bsz=32, num_updates=10370, lr=1.48154e-05, gnorm=2.225, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1350
2021-12-14 02:07:46 | INFO | train_inner | epoch 105:     84 / 99 loss=0.834, ppl=1.78, wps=8927.7, ups=13.83, wpb=645.4, bsz=32, num_updates=10380, lr=1.48e-05, gnorm=2.094, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1351
2021-12-14 02:07:47 | INFO | train_inner | epoch 105:     94 / 99 loss=0.837, ppl=1.79, wps=5795.9, ups=10.4, wpb=557.3, bsz=32, num_updates=10390, lr=1.47846e-05, gnorm=2.007, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1352
2021-12-14 02:07:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:07:49 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 2.246 | ppl 4.74 | wps 22846.9 | wpb 586.4 | bsz 31.3 | num_updates 10395 | best_loss 2.195
2021-12-14 02:07:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10395 updates
2021-12-14 02:07:49 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:07:51 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:07:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 105 @ 10395 updates, score 2.246) (writing took 2.789581170072779 seconds)
2021-12-14 02:07:51 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2021-12-14 02:07:51 | INFO | train | epoch 105 | loss 0.931 | ppl 1.91 | wps 5543 | ups 8.79 | wpb 630.8 | bsz 31.9 | num_updates 10395 | lr 1.47769e-05 | gnorm 2.107 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.6 | wall 1356
2021-12-14 02:07:51 | INFO | fairseq.trainer | begin training epoch 106
2021-12-14 02:07:51 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:07:52 | INFO | train_inner | epoch 106:      5 / 99 loss=0.893, ppl=1.86, wps=1559.5, ups=2.2, wpb=709.1, bsz=32, num_updates=10400, lr=1.47692e-05, gnorm=2.096, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1357
2021-12-14 02:07:53 | INFO | train_inner | epoch 106:     15 / 99 loss=0.718, ppl=1.64, wps=6740.5, ups=13.69, wpb=492.5, bsz=32, num_updates=10410, lr=1.47538e-05, gnorm=2.244, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1357
2021-12-14 02:07:53 | INFO | train_inner | epoch 106:     25 / 99 loss=1.048, ppl=2.07, wps=9444.9, ups=14.13, wpb=668.4, bsz=32, num_updates=10420, lr=1.47385e-05, gnorm=2.083, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1358
2021-12-14 02:07:54 | INFO | train_inner | epoch 106:     35 / 99 loss=0.789, ppl=1.73, wps=9179.7, ups=14.64, wpb=627, bsz=32, num_updates=10430, lr=1.47231e-05, gnorm=2.112, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1359
2021-12-14 02:07:55 | INFO | train_inner | epoch 106:     45 / 99 loss=0.631, ppl=1.55, wps=8345.8, ups=15.56, wpb=536.3, bsz=32, num_updates=10440, lr=1.47077e-05, gnorm=2.092, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1359
2021-12-14 02:07:55 | INFO | train_inner | epoch 106:     55 / 99 loss=0.944, ppl=1.92, wps=9755.7, ups=14.55, wpb=670.6, bsz=32, num_updates=10450, lr=1.46923e-05, gnorm=2.075, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1360
2021-12-14 02:07:56 | INFO | train_inner | epoch 106:     65 / 99 loss=1.139, ppl=2.2, wps=9938.4, ups=15.25, wpb=651.8, bsz=32, num_updates=10460, lr=1.46769e-05, gnorm=2.037, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1361
2021-12-14 02:07:57 | INFO | train_inner | epoch 106:     75 / 99 loss=0.84, ppl=1.79, wps=8632.7, ups=15.53, wpb=555.9, bsz=32, num_updates=10470, lr=1.46615e-05, gnorm=2.032, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1361
2021-12-14 02:07:57 | INFO | train_inner | epoch 106:     85 / 99 loss=1.153, ppl=2.22, wps=9011.4, ups=13.92, wpb=647.5, bsz=31.5, num_updates=10480, lr=1.46462e-05, gnorm=2.149, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1362
2021-12-14 02:07:58 | INFO | train_inner | epoch 106:     95 / 99 loss=0.842, ppl=1.79, wps=8183.5, ups=11.09, wpb=738.1, bsz=32, num_updates=10490, lr=1.46308e-05, gnorm=2.217, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1363
2021-12-14 02:07:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:08:00 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 2.225 | ppl 4.68 | wps 18884.8 | wpb 586.4 | bsz 31.3 | num_updates 10494 | best_loss 2.195
2021-12-14 02:08:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10494 updates
2021-12-14 02:08:00 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:08:02 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:08:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 106 @ 10494 updates, score 2.225) (writing took 2.6754082541447133 seconds)
2021-12-14 02:08:02 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2021-12-14 02:08:02 | INFO | train | epoch 106 | loss 0.925 | ppl 1.9 | wps 5718.1 | ups 9.07 | wpb 630.8 | bsz 31.9 | num_updates 10494 | lr 1.46246e-05 | gnorm 2.125 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.7 | wall 1367
2021-12-14 02:08:02 | INFO | fairseq.trainer | begin training epoch 107
2021-12-14 02:08:02 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:08:03 | INFO | train_inner | epoch 107:      6 / 99 loss=1.002, ppl=2, wps=1477.6, ups=2.2, wpb=671, bsz=32, num_updates=10500, lr=1.46154e-05, gnorm=2.303, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1368
2021-12-14 02:08:04 | INFO | train_inner | epoch 107:     16 / 99 loss=0.686, ppl=1.61, wps=7666.2, ups=13.92, wpb=550.9, bsz=32, num_updates=10510, lr=1.46e-05, gnorm=2.119, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1368
2021-12-14 02:08:04 | INFO | train_inner | epoch 107:     26 / 99 loss=0.743, ppl=1.67, wps=7489.5, ups=12.8, wpb=584.9, bsz=32, num_updates=10520, lr=1.45846e-05, gnorm=2.215, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1369
2021-12-14 02:08:05 | INFO | train_inner | epoch 107:     36 / 99 loss=1.08, ppl=2.11, wps=8261.3, ups=11.72, wpb=704.7, bsz=32, num_updates=10530, lr=1.45692e-05, gnorm=2.216, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1370
2021-12-14 02:08:06 | INFO | train_inner | epoch 107:     46 / 99 loss=1.193, ppl=2.29, wps=8034, ups=10.61, wpb=757.2, bsz=31.5, num_updates=10540, lr=1.45538e-05, gnorm=2.098, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1371
2021-12-14 02:08:07 | INFO | train_inner | epoch 107:     56 / 99 loss=0.763, ppl=1.7, wps=5605.6, ups=8.9, wpb=630, bsz=32, num_updates=10550, lr=1.45385e-05, gnorm=1.998, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=1372
2021-12-14 02:08:08 | INFO | train_inner | epoch 107:     66 / 99 loss=1.225, ppl=2.34, wps=8184, ups=9.6, wpb=852.7, bsz=32, num_updates=10560, lr=1.45231e-05, gnorm=2.234, clip=100, loss_scale=128, train_wall=1, gb_free=20.3, wall=1373
2021-12-14 02:08:09 | INFO | train_inner | epoch 107:     76 / 99 loss=1, ppl=2, wps=6659.3, ups=9.55, wpb=697, bsz=32, num_updates=10570, lr=1.45077e-05, gnorm=2.106, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1374
2021-12-14 02:08:10 | INFO | train_inner | epoch 107:     86 / 99 loss=0.59, ppl=1.51, wps=4408.9, ups=9.64, wpb=457.3, bsz=32, num_updates=10580, lr=1.44923e-05, gnorm=2.029, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1375
2021-12-14 02:08:11 | INFO | train_inner | epoch 107:     96 / 99 loss=0.642, ppl=1.56, wps=5161.6, ups=10.39, wpb=497, bsz=32, num_updates=10590, lr=1.44769e-05, gnorm=2.011, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1376
2021-12-14 02:08:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:08:12 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 2.2 | ppl 4.59 | wps 23384.9 | wpb 586.4 | bsz 31.3 | num_updates 10593 | best_loss 2.195
2021-12-14 02:08:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 10593 updates
2021-12-14 02:08:12 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:08:15 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:08:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 107 @ 10593 updates, score 2.2) (writing took 2.571014943998307 seconds)
2021-12-14 02:08:15 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2021-12-14 02:08:15 | INFO | train | epoch 107 | loss 0.904 | ppl 1.87 | wps 4910.8 | ups 7.79 | wpb 630.8 | bsz 31.9 | num_updates 10593 | lr 1.44723e-05 | gnorm 2.114 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 1380
2021-12-14 02:08:15 | INFO | fairseq.trainer | begin training epoch 108
2021-12-14 02:08:15 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:08:16 | INFO | train_inner | epoch 108:      7 / 99 loss=0.504, ppl=1.42, wps=1225.3, ups=2.21, wpb=553.3, bsz=32, num_updates=10600, lr=1.44615e-05, gnorm=1.821, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1381
2021-12-14 02:08:17 | INFO | train_inner | epoch 108:     17 / 99 loss=0.941, ppl=1.92, wps=6809.6, ups=9.29, wpb=733.2, bsz=32, num_updates=10610, lr=1.44462e-05, gnorm=2.196, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1382
2021-12-14 02:08:18 | INFO | train_inner | epoch 108:     27 / 99 loss=0.833, ppl=1.78, wps=6322.5, ups=10.5, wpb=602.1, bsz=32, num_updates=10620, lr=1.44308e-05, gnorm=2.103, clip=100, loss_scale=128, train_wall=1, gb_free=20.3, wall=1383
2021-12-14 02:08:19 | INFO | train_inner | epoch 108:     37 / 99 loss=0.71, ppl=1.64, wps=7237.1, ups=11.06, wpb=654.1, bsz=32, num_updates=10630, lr=1.44154e-05, gnorm=2.06, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1384
2021-12-14 02:08:20 | INFO | train_inner | epoch 108:     47 / 99 loss=1.303, ppl=2.47, wps=9023.9, ups=12.25, wpb=736.4, bsz=31.5, num_updates=10640, lr=1.44e-05, gnorm=2.204, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1384
2021-12-14 02:08:20 | INFO | train_inner | epoch 108:     57 / 99 loss=0.917, ppl=1.89, wps=7248.1, ups=13.07, wpb=554.6, bsz=32, num_updates=10650, lr=1.43846e-05, gnorm=2.04, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1385
2021-12-14 02:08:21 | INFO | train_inner | epoch 108:     67 / 99 loss=0.994, ppl=1.99, wps=8071.2, ups=13.08, wpb=616.9, bsz=32, num_updates=10660, lr=1.43692e-05, gnorm=2.105, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1386
2021-12-14 02:08:22 | INFO | train_inner | epoch 108:     77 / 99 loss=0.595, ppl=1.51, wps=7711.7, ups=13.27, wpb=581.3, bsz=32, num_updates=10670, lr=1.43538e-05, gnorm=1.957, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1387
2021-12-14 02:08:23 | INFO | train_inner | epoch 108:     87 / 99 loss=0.907, ppl=1.88, wps=8488.2, ups=12.77, wpb=664.6, bsz=32, num_updates=10680, lr=1.43385e-05, gnorm=2.101, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1387
2021-12-14 02:08:24 | INFO | train_inner | epoch 108:     97 / 99 loss=0.954, ppl=1.94, wps=6923.1, ups=11.6, wpb=597, bsz=32, num_updates=10690, lr=1.43231e-05, gnorm=2.151, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1388
2021-12-14 02:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:08:25 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 2.231 | ppl 4.69 | wps 20268.7 | wpb 586.4 | bsz 31.3 | num_updates 10692 | best_loss 2.195
2021-12-14 02:08:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 10692 updates
2021-12-14 02:08:25 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:08:27 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:08:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 108 @ 10692 updates, score 2.231) (writing took 2.7455444869119674 seconds)
2021-12-14 02:08:27 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2021-12-14 02:08:27 | INFO | train | epoch 108 | loss 0.886 | ppl 1.85 | wps 5040.1 | ups 7.99 | wpb 630.8 | bsz 31.9 | num_updates 10692 | lr 1.432e-05 | gnorm 2.083 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1392
2021-12-14 02:08:27 | INFO | fairseq.trainer | begin training epoch 109
2021-12-14 02:08:27 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:08:28 | INFO | train_inner | epoch 109:      8 / 99 loss=0.687, ppl=1.61, wps=1255.2, ups=2.17, wpb=577.2, bsz=32, num_updates=10700, lr=1.43077e-05, gnorm=1.999, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1393
2021-12-14 02:08:29 | INFO | train_inner | epoch 109:     18 / 99 loss=0.894, ppl=1.86, wps=5269.3, ups=9.13, wpb=577.4, bsz=32, num_updates=10710, lr=1.42923e-05, gnorm=2.063, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1394
2021-12-14 02:08:30 | INFO | train_inner | epoch 109:     28 / 99 loss=1.209, ppl=2.31, wps=7229, ups=9.84, wpb=734.5, bsz=31.5, num_updates=10720, lr=1.42769e-05, gnorm=2.106, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1395
2021-12-14 02:08:31 | INFO | train_inner | epoch 109:     38 / 99 loss=0.671, ppl=1.59, wps=6173.3, ups=11.33, wpb=545, bsz=32, num_updates=10730, lr=1.42615e-05, gnorm=2.045, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1396
2021-12-14 02:08:32 | INFO | train_inner | epoch 109:     48 / 99 loss=0.639, ppl=1.56, wps=5706.8, ups=10.28, wpb=554.9, bsz=32, num_updates=10740, lr=1.42462e-05, gnorm=1.932, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1397
2021-12-14 02:08:33 | INFO | train_inner | epoch 109:     58 / 99 loss=0.455, ppl=1.37, wps=4996.2, ups=10.66, wpb=468.8, bsz=32, num_updates=10750, lr=1.42308e-05, gnorm=1.958, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1398
2021-12-14 02:08:34 | INFO | train_inner | epoch 109:     68 / 99 loss=0.85, ppl=1.8, wps=6915.8, ups=10.68, wpb=647.3, bsz=32, num_updates=10760, lr=1.42154e-05, gnorm=2.131, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1399
2021-12-14 02:08:35 | INFO | train_inner | epoch 109:     78 / 99 loss=1.042, ppl=2.06, wps=6758, ups=10.49, wpb=644.5, bsz=32, num_updates=10770, lr=1.42e-05, gnorm=2.091, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1400
2021-12-14 02:08:36 | INFO | train_inner | epoch 109:     88 / 99 loss=1.058, ppl=2.08, wps=8988.7, ups=11.34, wpb=792.9, bsz=32, num_updates=10780, lr=1.41846e-05, gnorm=2.153, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=1401
2021-12-14 02:08:37 | INFO | train_inner | epoch 109:     98 / 99 loss=1.002, ppl=2, wps=9278.9, ups=12.1, wpb=766.6, bsz=32, num_updates=10790, lr=1.41692e-05, gnorm=2.315, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=1401
2021-12-14 02:08:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:08:38 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 2.233 | ppl 4.7 | wps 19688.5 | wpb 586.4 | bsz 31.3 | num_updates 10791 | best_loss 2.195
2021-12-14 02:08:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 10791 updates
2021-12-14 02:08:38 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:08:40 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:08:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 109 @ 10791 updates, score 2.233) (writing took 2.7838559770025313 seconds)
2021-12-14 02:08:41 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2021-12-14 02:08:41 | INFO | train | epoch 109 | loss 0.882 | ppl 1.84 | wps 4758.1 | ups 7.54 | wpb 630.8 | bsz 31.9 | num_updates 10791 | lr 1.41677e-05 | gnorm 2.074 | clip 100 | loss_scale 128 | train_wall 9 | gb_free 20.8 | wall 1405
2021-12-14 02:08:41 | INFO | fairseq.trainer | begin training epoch 110
2021-12-14 02:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:08:41 | INFO | train_inner | epoch 110:      9 / 99 loss=0.594, ppl=1.51, wps=1150.7, ups=2.14, wpb=536.7, bsz=32, num_updates=10800, lr=1.41538e-05, gnorm=1.913, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1406
2021-12-14 02:08:42 | INFO | train_inner | epoch 110:     19 / 99 loss=1.07, ppl=2.1, wps=9264.3, ups=12.5, wpb=741.4, bsz=32, num_updates=10810, lr=1.41385e-05, gnorm=2.213, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1407
2021-12-14 02:08:43 | INFO | train_inner | epoch 110:     29 / 99 loss=1.211, ppl=2.31, wps=9016.9, ups=11.13, wpb=810.2, bsz=31.5, num_updates=10820, lr=1.41231e-05, gnorm=2.321, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1408
2021-12-14 02:08:44 | INFO | train_inner | epoch 110:     39 / 99 loss=0.939, ppl=1.92, wps=7983.6, ups=12.21, wpb=654, bsz=32, num_updates=10830, lr=1.41077e-05, gnorm=1.921, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1409
2021-12-14 02:08:45 | INFO | train_inner | epoch 110:     49 / 99 loss=0.559, ppl=1.47, wps=5321.4, ups=11.92, wpb=446.3, bsz=32, num_updates=10840, lr=1.40923e-05, gnorm=1.933, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1410
2021-12-14 02:08:45 | INFO | train_inner | epoch 110:     59 / 99 loss=0.516, ppl=1.43, wps=6532.6, ups=13.23, wpb=493.6, bsz=32, num_updates=10850, lr=1.40769e-05, gnorm=1.929, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1410
2021-12-14 02:08:46 | INFO | train_inner | epoch 110:     69 / 99 loss=0.72, ppl=1.65, wps=7823.5, ups=12.87, wpb=608, bsz=32, num_updates=10860, lr=1.40615e-05, gnorm=1.983, clip=100, loss_scale=128, train_wall=1, gb_free=20.5, wall=1411
2021-12-14 02:08:47 | INFO | train_inner | epoch 110:     79 / 99 loss=0.857, ppl=1.81, wps=8814.4, ups=13.42, wpb=656.7, bsz=32, num_updates=10870, lr=1.40462e-05, gnorm=2.122, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1412
2021-12-14 02:08:48 | INFO | train_inner | epoch 110:     89 / 99 loss=0.853, ppl=1.81, wps=8471.1, ups=12.78, wpb=662.9, bsz=32, num_updates=10880, lr=1.40308e-05, gnorm=2.148, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1413
2021-12-14 02:08:49 | INFO | train_inner | epoch 110:     99 / 99 loss=1.03, ppl=2.04, wps=7979.3, ups=11.81, wpb=675.9, bsz=32, num_updates=10890, lr=1.40154e-05, gnorm=2.165, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=1413
2021-12-14 02:08:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:08:49 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 2.236 | ppl 4.71 | wps 23704.5 | wpb 586.4 | bsz 31.3 | num_updates 10890 | best_loss 2.195
2021-12-14 02:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 10890 updates
2021-12-14 02:08:49 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:08:52 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:08:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 110 @ 10890 updates, score 2.236) (writing took 2.581606838153675 seconds)
2021-12-14 02:08:52 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2021-12-14 02:08:52 | INFO | train | epoch 110 | loss 0.875 | ppl 1.83 | wps 5430.5 | ups 8.61 | wpb 630.8 | bsz 31.9 | num_updates 10890 | lr 1.40154e-05 | gnorm 2.071 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.4 | wall 1417
2021-12-14 02:08:52 | INFO | fairseq.trainer | begin training epoch 111
2021-12-14 02:08:52 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:08:53 | INFO | train_inner | epoch 111:     10 / 99 loss=0.883, ppl=1.84, wps=1533.7, ups=2.36, wpb=650.5, bsz=32, num_updates=10900, lr=1.4e-05, gnorm=2.151, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1418
2021-12-14 02:08:54 | INFO | train_inner | epoch 111:     20 / 99 loss=0.656, ppl=1.58, wps=7002.5, ups=12.64, wpb=554.1, bsz=32, num_updates=10910, lr=1.39846e-05, gnorm=2.082, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1418
2021-12-14 02:08:54 | INFO | train_inner | epoch 111:     30 / 99 loss=1.168, ppl=2.25, wps=9816.2, ups=12.92, wpb=759.8, bsz=31.5, num_updates=10920, lr=1.39692e-05, gnorm=1.967, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1419
2021-12-14 02:08:55 | INFO | train_inner | epoch 111:     40 / 99 loss=1.022, ppl=2.03, wps=9315.6, ups=12.3, wpb=757.4, bsz=32, num_updates=10930, lr=1.39538e-05, gnorm=1.996, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1420
2021-12-14 02:08:56 | INFO | train_inner | epoch 111:     50 / 99 loss=0.552, ppl=1.47, wps=6204.6, ups=12.56, wpb=493.9, bsz=32, num_updates=10940, lr=1.39385e-05, gnorm=1.807, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1421
2021-12-14 02:08:57 | INFO | train_inner | epoch 111:     60 / 99 loss=0.939, ppl=1.92, wps=8061.6, ups=11.68, wpb=690.1, bsz=32, num_updates=10950, lr=1.39231e-05, gnorm=2.083, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1422
2021-12-14 02:08:58 | INFO | train_inner | epoch 111:     70 / 99 loss=0.643, ppl=1.56, wps=6238.1, ups=12.53, wpb=498, bsz=32, num_updates=10960, lr=1.39077e-05, gnorm=2.029, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1423
2021-12-14 02:08:58 | INFO | train_inner | epoch 111:     80 / 99 loss=0.609, ppl=1.53, wps=8284, ups=15.15, wpb=546.7, bsz=32, num_updates=10970, lr=1.38923e-05, gnorm=2.028, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1423
2021-12-14 02:08:59 | INFO | train_inner | epoch 111:     90 / 99 loss=0.662, ppl=1.58, wps=7266.2, ups=11.82, wpb=614.8, bsz=32, num_updates=10980, lr=1.38769e-05, gnorm=2.017, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1424
2021-12-14 02:09:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:09:01 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 2.266 | ppl 4.81 | wps 23004.5 | wpb 586.4 | bsz 31.3 | num_updates 10989 | best_loss 2.195
2021-12-14 02:09:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 10989 updates
2021-12-14 02:09:01 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:09:04 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:09:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 111 @ 10989 updates, score 2.266) (writing took 2.6298305159434676 seconds)
2021-12-14 02:09:04 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2021-12-14 02:09:04 | INFO | train | epoch 111 | loss 0.86 | ppl 1.81 | wps 5416.1 | ups 8.59 | wpb 630.8 | bsz 31.9 | num_updates 10989 | lr 1.38631e-05 | gnorm 2.034 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.2 | wall 1428
2021-12-14 02:09:04 | INFO | fairseq.trainer | begin training epoch 112
2021-12-14 02:09:04 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:09:04 | INFO | train_inner | epoch 112:      1 / 99 loss=1.124, ppl=2.18, wps=1566.1, ups=2.22, wpb=704.9, bsz=32, num_updates=10990, lr=1.38615e-05, gnorm=2.133, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1429
2021-12-14 02:09:05 | INFO | train_inner | epoch 112:     11 / 99 loss=0.763, ppl=1.7, wps=7319.1, ups=11.65, wpb=628.5, bsz=32, num_updates=11000, lr=1.38462e-05, gnorm=2.154, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1429
2021-12-14 02:09:05 | INFO | train_inner | epoch 112:     21 / 99 loss=0.949, ppl=1.93, wps=9207.3, ups=13.71, wpb=671.4, bsz=32, num_updates=11010, lr=1.38308e-05, gnorm=2.007, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1430
2021-12-14 02:09:06 | INFO | train_inner | epoch 112:     31 / 99 loss=0.565, ppl=1.48, wps=7257.5, ups=13.43, wpb=540.2, bsz=32, num_updates=11020, lr=1.38154e-05, gnorm=2.011, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1431
2021-12-14 02:09:07 | INFO | train_inner | epoch 112:     41 / 99 loss=1.063, ppl=2.09, wps=8943.4, ups=12.16, wpb=735.6, bsz=32, num_updates=11030, lr=1.38e-05, gnorm=2.192, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1432
2021-12-14 02:09:08 | INFO | train_inner | epoch 112:     51 / 99 loss=0.99, ppl=1.99, wps=7290.8, ups=10.34, wpb=705.3, bsz=32, num_updates=11040, lr=1.37846e-05, gnorm=1.952, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=1433
2021-12-14 02:09:09 | INFO | train_inner | epoch 112:     61 / 99 loss=0.617, ppl=1.53, wps=6625.2, ups=13.08, wpb=506.5, bsz=32, num_updates=11050, lr=1.37692e-05, gnorm=2.066, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1433
2021-12-14 02:09:09 | INFO | train_inner | epoch 112:     71 / 99 loss=0.851, ppl=1.8, wps=8811.9, ups=14.3, wpb=616.1, bsz=32, num_updates=11060, lr=1.37538e-05, gnorm=2.148, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1434
2021-12-14 02:09:10 | INFO | train_inner | epoch 112:     81 / 99 loss=1.19, ppl=2.28, wps=10420.4, ups=14.79, wpb=704.4, bsz=31.5, num_updates=11070, lr=1.37385e-05, gnorm=2.138, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1435
2021-12-14 02:09:11 | INFO | train_inner | epoch 112:     91 / 99 loss=0.59, ppl=1.5, wps=7501.8, ups=13.08, wpb=573.4, bsz=32, num_updates=11080, lr=1.37231e-05, gnorm=2.046, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1436
2021-12-14 02:09:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:09:13 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 2.209 | ppl 4.62 | wps 18665.4 | wpb 586.4 | bsz 31.3 | num_updates 11088 | best_loss 2.195
2021-12-14 02:09:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 11088 updates
2021-12-14 02:09:13 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:09:15 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:09:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 112 @ 11088 updates, score 2.209) (writing took 2.692618717905134 seconds)
2021-12-14 02:09:15 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2021-12-14 02:09:15 | INFO | train | epoch 112 | loss 0.862 | ppl 1.82 | wps 5351.7 | ups 8.48 | wpb 630.8 | bsz 31.9 | num_updates 11088 | lr 1.37108e-05 | gnorm 2.083 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1440
2021-12-14 02:09:15 | INFO | fairseq.trainer | begin training epoch 113
2021-12-14 02:09:15 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:09:16 | INFO | train_inner | epoch 113:      2 / 99 loss=0.801, ppl=1.74, wps=1446.9, ups=2.14, wpb=677.2, bsz=32, num_updates=11090, lr=1.37077e-05, gnorm=2.099, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1440
2021-12-14 02:09:16 | INFO | train_inner | epoch 113:     12 / 99 loss=0.67, ppl=1.59, wps=9030.1, ups=15.43, wpb=585.2, bsz=32, num_updates=11100, lr=1.36923e-05, gnorm=1.962, clip=100, loss_scale=128, train_wall=1, gb_free=20.6, wall=1441
2021-12-14 02:09:17 | INFO | train_inner | epoch 113:     22 / 99 loss=0.926, ppl=1.9, wps=9506.9, ups=14.35, wpb=662.7, bsz=32, num_updates=11110, lr=1.36769e-05, gnorm=2.106, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1442
2021-12-14 02:09:18 | INFO | train_inner | epoch 113:     32 / 99 loss=0.564, ppl=1.48, wps=7647.3, ups=14.12, wpb=541.4, bsz=32, num_updates=11120, lr=1.36615e-05, gnorm=1.933, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1442
2021-12-14 02:09:18 | INFO | train_inner | epoch 113:     42 / 99 loss=0.688, ppl=1.61, wps=6317, ups=12.56, wpb=503, bsz=32, num_updates=11130, lr=1.36462e-05, gnorm=2.111, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1443
2021-12-14 02:09:19 | INFO | train_inner | epoch 113:     52 / 99 loss=1.082, ppl=2.12, wps=11396, ups=13.48, wpb=845.5, bsz=32, num_updates=11140, lr=1.36308e-05, gnorm=2.158, clip=100, loss_scale=128, train_wall=1, gb_free=20.4, wall=1444
2021-12-14 02:09:20 | INFO | train_inner | epoch 113:     62 / 99 loss=0.582, ppl=1.5, wps=6123.2, ups=12.6, wpb=486.1, bsz=32, num_updates=11150, lr=1.36154e-05, gnorm=2.04, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1445
2021-12-14 02:09:21 | INFO | train_inner | epoch 113:     72 / 99 loss=0.726, ppl=1.65, wps=7425.2, ups=12.3, wpb=603.9, bsz=32, num_updates=11160, lr=1.36e-05, gnorm=2.098, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1446
2021-12-14 02:09:21 | INFO | train_inner | epoch 113:     82 / 99 loss=0.877, ppl=1.84, wps=10213.4, ups=15.35, wpb=665.3, bsz=32, num_updates=11170, lr=1.35846e-05, gnorm=2.069, clip=100, loss_scale=128, train_wall=1, gb_free=20.2, wall=1446
2021-12-14 02:09:22 | INFO | train_inner | epoch 113:     92 / 99 loss=0.773, ppl=1.71, wps=6995.5, ups=12.59, wpb=555.7, bsz=32, num_updates=11180, lr=1.35692e-05, gnorm=2.128, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1447
2021-12-14 02:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:09:24 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 2.225 | ppl 4.68 | wps 22422 | wpb 586.4 | bsz 31.3 | num_updates 11187 | best_loss 2.195
2021-12-14 02:09:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 11187 updates
2021-12-14 02:09:24 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:09:26 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:09:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 113 @ 11187 updates, score 2.225) (writing took 2.7077514661941677 seconds)
2021-12-14 02:09:26 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2021-12-14 02:09:26 | INFO | train | epoch 113 | loss 0.846 | ppl 1.8 | wps 5593.7 | ups 8.87 | wpb 630.8 | bsz 31.9 | num_updates 11187 | lr 1.35585e-05 | gnorm 2.056 | clip 100 | loss_scale 128 | train_wall 7 | gb_free 20.8 | wall 1451
2021-12-14 02:09:26 | INFO | fairseq.trainer | begin training epoch 114
2021-12-14 02:09:26 | INFO | fairseq_cli.train | Start iterating over samples
2021-12-14 02:09:27 | INFO | train_inner | epoch 114:      3 / 99 loss=1.4, ppl=2.64, wps=1956.5, ups=2.18, wpb=898.4, bsz=31.5, num_updates=11190, lr=1.35538e-05, gnorm=2.158, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1452
2021-12-14 02:09:28 | INFO | train_inner | epoch 114:     13 / 99 loss=1.026, ppl=2.04, wps=9141.6, ups=11.99, wpb=762.2, bsz=31.5, num_updates=11200, lr=1.35385e-05, gnorm=2.034, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1452
2021-12-14 02:09:28 | INFO | train_inner | epoch 114:     23 / 99 loss=0.959, ppl=1.94, wps=8304.1, ups=13.08, wpb=635.1, bsz=32, num_updates=11210, lr=1.35231e-05, gnorm=2.02, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1453
2021-12-14 02:09:29 | INFO | train_inner | epoch 114:     33 / 99 loss=0.683, ppl=1.61, wps=7747.9, ups=13.62, wpb=568.9, bsz=32, num_updates=11220, lr=1.35077e-05, gnorm=2.012, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1454
2021-12-14 02:09:30 | INFO | train_inner | epoch 114:     43 / 99 loss=0.764, ppl=1.7, wps=7248.6, ups=13.12, wpb=552.3, bsz=32, num_updates=11230, lr=1.34923e-05, gnorm=2.081, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1455
2021-12-14 02:09:31 | INFO | train_inner | epoch 114:     53 / 99 loss=0.685, ppl=1.61, wps=7845.4, ups=13.53, wpb=579.7, bsz=32, num_updates=11240, lr=1.34769e-05, gnorm=2.006, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1455
2021-12-14 02:09:31 | INFO | train_inner | epoch 114:     63 / 99 loss=0.749, ppl=1.68, wps=8407.7, ups=13.57, wpb=619.4, bsz=32, num_updates=11250, lr=1.34615e-05, gnorm=2.164, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1456
2021-12-14 02:09:32 | INFO | train_inner | epoch 114:     73 / 99 loss=0.55, ppl=1.46, wps=7560.7, ups=13.6, wpb=556.1, bsz=32, num_updates=11260, lr=1.34462e-05, gnorm=1.986, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1457
2021-12-14 02:09:33 | INFO | train_inner | epoch 114:     83 / 99 loss=0.892, ppl=1.86, wps=8810.6, ups=12.5, wpb=704.7, bsz=32, num_updates=11270, lr=1.34308e-05, gnorm=2.23, clip=100, loss_scale=128, train_wall=1, gb_free=20.8, wall=1458
2021-12-14 02:09:34 | INFO | train_inner | epoch 114:     93 / 99 loss=0.977, ppl=1.97, wps=6999, ups=10.13, wpb=690.9, bsz=32, num_updates=11280, lr=1.34154e-05, gnorm=2.177, clip=100, loss_scale=128, train_wall=1, gb_free=20.7, wall=1459
2021-12-14 02:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-12-14 02:09:35 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 2.228 | ppl 4.69 | wps 24078.2 | wpb 586.4 | bsz 31.3 | num_updates 11286 | best_loss 2.195
2021-12-14 02:09:35 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 10 runs
2021-12-14 02:09:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 11286 updates
2021-12-14 02:09:35 | INFO | fairseq.trainer | Saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:09:38 | INFO | fairseq.trainer | Finished saving checkpoint to bartabst/checkpoints/bart.abst/checkpoint_last.pt
2021-12-14 02:09:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint bartabst/checkpoints/bart.abst/checkpoint_last.pt (epoch 114 @ 11286 updates, score 2.228) (writing took 2.6545417380984873 seconds)
2021-12-14 02:09:38 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2021-12-14 02:09:38 | INFO | train | epoch 114 | loss 0.833 | ppl 1.78 | wps 5435.7 | ups 8.62 | wpb 630.8 | bsz 31.9 | num_updates 11286 | lr 1.34062e-05 | gnorm 2.079 | clip 100 | loss_scale 128 | train_wall 8 | gb_free 20.8 | wall 1463
2021-12-14 02:09:38 | INFO | fairseq_cli.train | done training in 1459.9 seconds
